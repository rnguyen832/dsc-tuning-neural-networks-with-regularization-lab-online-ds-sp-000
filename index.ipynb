{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there high bias? yes/no\n",
    "- Is there high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition as well as a validation set to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "#Your code here; import some packages/modules you plan to use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(123)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59995</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>In XXXX, I defaulted on a credit card with XXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59996</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>I HAVE CALLED TRANSUNION JUST ABOUT EVERY MONT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59997</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Hello, there is a 2012 Chapter XXXX Bankruptcy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59998</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>I had a 2 yr internet contract with XXXX XXXX ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59999</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>I filed a complaint against XXXX XXXX XXXX wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Product                       Consumer complaint narrative\n",
       "0          Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1          Student loan  I am being contacted by a debt collector for p...\n",
       "2          Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3          Student loan  Navient has sytematically and illegally failed...\n",
       "4          Student loan  My wife became eligible for XXXX Loan Forgiven...\n",
       "...                 ...                                                ...\n",
       "59995  Credit reporting  In XXXX, I defaulted on a credit card with XXX...\n",
       "59996  Credit reporting  I HAVE CALLED TRANSUNION JUST ABOUT EVERY MONT...\n",
       "59997  Credit reporting  Hello, there is a 2012 Chapter XXXX Bankruptcy...\n",
       "59998  Credit reporting  I had a 2 yr internet contract with XXXX XXXX ...\n",
       "59999  Credit reporting  I filed a complaint against XXXX XXXX XXXX wit...\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "raw = pd.read_csv(\"Bank_complaints.csv\")\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Train - test split\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "df = raw.sample(10000, random_state=123)\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Below, perform an appropriate train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yyour code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this block of code \n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "tokenizer = Tokenizer(2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_token = tokenizer.texts_to_matrix(X_train_final)\n",
    "X_val_token = tokenizer.texts_to_matrix(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; transform the product labels to numerical values\n",
    "#Then transform these integer values into a matrix of binary flags\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_label = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_label = to_categorical(lb.transform(y_val))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "model = models.Sequential()\n",
    "model.add(Dense(50, activation=\"relu\", input_shape=(2000,)))\n",
    "model.add(Dense(25, activation=\"relu\"))\n",
    "model.add(Dense(7, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 1.9492 - accuracy: 0.1626 - val_loss: 1.9390 - val_accuracy: 0.1870\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.9285 - accuracy: 0.1868 - val_loss: 1.9219 - val_accuracy: 0.1990\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.9109 - accuracy: 0.2028 - val_loss: 1.9060 - val_accuracy: 0.2140\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8929 - accuracy: 0.2192 - val_loss: 1.8893 - val_accuracy: 0.2330\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8736 - accuracy: 0.2375 - val_loss: 1.8704 - val_accuracy: 0.2470\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8520 - accuracy: 0.2555 - val_loss: 1.8495 - val_accuracy: 0.2680\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.8280 - accuracy: 0.2848 - val_loss: 1.8254 - val_accuracy: 0.2840\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8014 - accuracy: 0.2983 - val_loss: 1.7996 - val_accuracy: 0.3060\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7721 - accuracy: 0.3205 - val_loss: 1.7710 - val_accuracy: 0.3220\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7407 - accuracy: 0.3448 - val_loss: 1.7410 - val_accuracy: 0.3390\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.7077 - accuracy: 0.3629 - val_loss: 1.7092 - val_accuracy: 0.3610\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6739 - accuracy: 0.3820 - val_loss: 1.6772 - val_accuracy: 0.3730\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.6395 - accuracy: 0.3997 - val_loss: 1.6449 - val_accuracy: 0.3840\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6052 - accuracy: 0.4134 - val_loss: 1.6118 - val_accuracy: 0.3970\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.5705 - accuracy: 0.4285 - val_loss: 1.5794 - val_accuracy: 0.4160\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5361 - accuracy: 0.4445 - val_loss: 1.5483 - val_accuracy: 0.4270\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.5023 - accuracy: 0.4623 - val_loss: 1.5169 - val_accuracy: 0.4400\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4689 - accuracy: 0.4843 - val_loss: 1.4867 - val_accuracy: 0.4600\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4354 - accuracy: 0.5023 - val_loss: 1.4565 - val_accuracy: 0.4760\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.4024 - accuracy: 0.5246 - val_loss: 1.4253 - val_accuracy: 0.4890\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3692 - accuracy: 0.5428 - val_loss: 1.3956 - val_accuracy: 0.5080\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3367 - accuracy: 0.5626 - val_loss: 1.3652 - val_accuracy: 0.5240\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.3044 - accuracy: 0.5757 - val_loss: 1.3366 - val_accuracy: 0.5420\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2727 - accuracy: 0.5898 - val_loss: 1.3087 - val_accuracy: 0.5580\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2416 - accuracy: 0.6028 - val_loss: 1.2803 - val_accuracy: 0.5620\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2112 - accuracy: 0.6123 - val_loss: 1.2539 - val_accuracy: 0.5710\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.1814 - accuracy: 0.6225 - val_loss: 1.2269 - val_accuracy: 0.5750\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.1524 - accuracy: 0.6260 - val_loss: 1.2020 - val_accuracy: 0.5930\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.1247 - accuracy: 0.6372 - val_loss: 1.1785 - val_accuracy: 0.6050\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0978 - accuracy: 0.6443 - val_loss: 1.1535 - val_accuracy: 0.6120\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0718 - accuracy: 0.6529 - val_loss: 1.1311 - val_accuracy: 0.6210\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0472 - accuracy: 0.6637 - val_loss: 1.1112 - val_accuracy: 0.6140\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0236 - accuracy: 0.6682 - val_loss: 1.0889 - val_accuracy: 0.6300\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0008 - accuracy: 0.6755 - val_loss: 1.0699 - val_accuracy: 0.6410\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9794 - accuracy: 0.6818 - val_loss: 1.0498 - val_accuracy: 0.6450\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9588 - accuracy: 0.6877 - val_loss: 1.0330 - val_accuracy: 0.6460\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9395 - accuracy: 0.6937 - val_loss: 1.0164 - val_accuracy: 0.6460\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9211 - accuracy: 0.6983 - val_loss: 0.9994 - val_accuracy: 0.6570\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9038 - accuracy: 0.7011 - val_loss: 0.9837 - val_accuracy: 0.6530\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8873 - accuracy: 0.7083 - val_loss: 0.9703 - val_accuracy: 0.6550\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8712 - accuracy: 0.7111 - val_loss: 0.9551 - val_accuracy: 0.6640\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8567 - accuracy: 0.7135 - val_loss: 0.9421 - val_accuracy: 0.6650\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8423 - accuracy: 0.7189 - val_loss: 0.9302 - val_accuracy: 0.6660\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8288 - accuracy: 0.7242 - val_loss: 0.9193 - val_accuracy: 0.6660\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8158 - accuracy: 0.7254 - val_loss: 0.9066 - val_accuracy: 0.6840\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8034 - accuracy: 0.7289 - val_loss: 0.8959 - val_accuracy: 0.6730\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7916 - accuracy: 0.7331 - val_loss: 0.8858 - val_accuracy: 0.6810\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.7804 - accuracy: 0.7375 - val_loss: 0.8760 - val_accuracy: 0.6900\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7697 - accuracy: 0.7386 - val_loss: 0.8674 - val_accuracy: 0.6860\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.7597 - accuracy: 0.7411 - val_loss: 0.8577 - val_accuracy: 0.6930\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7493 - accuracy: 0.7449 - val_loss: 0.8501 - val_accuracy: 0.6910\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.7400 - accuracy: 0.7478 - val_loss: 0.8413 - val_accuracy: 0.7030\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7307 - accuracy: 0.7529 - val_loss: 0.8351 - val_accuracy: 0.7030\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7228 - accuracy: 0.7543 - val_loss: 0.8269 - val_accuracy: 0.7080\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7139 - accuracy: 0.7572 - val_loss: 0.8198 - val_accuracy: 0.7080\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7057 - accuracy: 0.7577 - val_loss: 0.8131 - val_accuracy: 0.7030\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6980 - accuracy: 0.7620 - val_loss: 0.8059 - val_accuracy: 0.7070\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6898 - accuracy: 0.7634 - val_loss: 0.8011 - val_accuracy: 0.7080\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6829 - accuracy: 0.7655 - val_loss: 0.7962 - val_accuracy: 0.7160\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6753 - accuracy: 0.7685 - val_loss: 0.7893 - val_accuracy: 0.7170\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.6683 - accuracy: 0.7715 - val_loss: 0.7846 - val_accuracy: 0.7150\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6615 - accuracy: 0.7717 - val_loss: 0.7794 - val_accuracy: 0.7140\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6549 - accuracy: 0.7760 - val_loss: 0.7753 - val_accuracy: 0.7200\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.6489 - accuracy: 0.7766 - val_loss: 0.7717 - val_accuracy: 0.7180\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6426 - accuracy: 0.7788 - val_loss: 0.7647 - val_accuracy: 0.7190\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6367 - accuracy: 0.7822 - val_loss: 0.7592 - val_accuracy: 0.7170\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.6303 - accuracy: 0.7837 - val_loss: 0.7568 - val_accuracy: 0.7240\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6245 - accuracy: 0.7866 - val_loss: 0.7531 - val_accuracy: 0.7240\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.6189 - accuracy: 0.7871 - val_loss: 0.7478 - val_accuracy: 0.7310\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6135 - accuracy: 0.7869 - val_loss: 0.7444 - val_accuracy: 0.7290\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6080 - accuracy: 0.7909 - val_loss: 0.7406 - val_accuracy: 0.7340\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6025 - accuracy: 0.7931 - val_loss: 0.7376 - val_accuracy: 0.7300\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5973 - accuracy: 0.7928 - val_loss: 0.7350 - val_accuracy: 0.7350\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5921 - accuracy: 0.7934 - val_loss: 0.7312 - val_accuracy: 0.7380\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5874 - accuracy: 0.7951 - val_loss: 0.7265 - val_accuracy: 0.7400\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5821 - accuracy: 0.7972 - val_loss: 0.7239 - val_accuracy: 0.7410\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5774 - accuracy: 0.7988 - val_loss: 0.7216 - val_accuracy: 0.7410\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5727 - accuracy: 0.8015 - val_loss: 0.7183 - val_accuracy: 0.7420\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5682 - accuracy: 0.8025 - val_loss: 0.7152 - val_accuracy: 0.7430\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5635 - accuracy: 0.8028 - val_loss: 0.7130 - val_accuracy: 0.7400\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5588 - accuracy: 0.8072 - val_loss: 0.7097 - val_accuracy: 0.7450\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5545 - accuracy: 0.8063 - val_loss: 0.7073 - val_accuracy: 0.7460\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5497 - accuracy: 0.8080 - val_loss: 0.7055 - val_accuracy: 0.7440\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5453 - accuracy: 0.8097 - val_loss: 0.7033 - val_accuracy: 0.7440\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5412 - accuracy: 0.8135 - val_loss: 0.7000 - val_accuracy: 0.7500\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5372 - accuracy: 0.8129 - val_loss: 0.6983 - val_accuracy: 0.7470\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5336 - accuracy: 0.8165 - val_loss: 0.6959 - val_accuracy: 0.7500\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5289 - accuracy: 0.8157 - val_loss: 0.6941 - val_accuracy: 0.7560\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5251 - accuracy: 0.8174 - val_loss: 0.6911 - val_accuracy: 0.7580\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5209 - accuracy: 0.8195 - val_loss: 0.6909 - val_accuracy: 0.7550\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5165 - accuracy: 0.8218 - val_loss: 0.6895 - val_accuracy: 0.7530\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5128 - accuracy: 0.8234 - val_loss: 0.6880 - val_accuracy: 0.7480\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5095 - accuracy: 0.8258 - val_loss: 0.6846 - val_accuracy: 0.7590\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.5053 - accuracy: 0.8265 - val_loss: 0.6830 - val_accuracy: 0.7610\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.5009 - accuracy: 0.8278 - val_loss: 0.6825 - val_accuracy: 0.7610\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4977 - accuracy: 0.8283 - val_loss: 0.6809 - val_accuracy: 0.7610\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4942 - accuracy: 0.8305 - val_loss: 0.6784 - val_accuracy: 0.7620\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4905 - accuracy: 0.8335 - val_loss: 0.6762 - val_accuracy: 0.7640\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4868 - accuracy: 0.8348 - val_loss: 0.6756 - val_accuracy: 0.7590\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4831 - accuracy: 0.8354 - val_loss: 0.6768 - val_accuracy: 0.7610\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4801 - accuracy: 0.8374 - val_loss: 0.6767 - val_accuracy: 0.7640\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4768 - accuracy: 0.8378 - val_loss: 0.6714 - val_accuracy: 0.7680\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4724 - accuracy: 0.8408 - val_loss: 0.6702 - val_accuracy: 0.7650\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4697 - accuracy: 0.8402 - val_loss: 0.6701 - val_accuracy: 0.7640\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4656 - accuracy: 0.8449 - val_loss: 0.6680 - val_accuracy: 0.7640\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4626 - accuracy: 0.8449 - val_loss: 0.6689 - val_accuracy: 0.7620\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4593 - accuracy: 0.8478 - val_loss: 0.6663 - val_accuracy: 0.7680\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4563 - accuracy: 0.8475 - val_loss: 0.6650 - val_accuracy: 0.7690\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4530 - accuracy: 0.8494 - val_loss: 0.6636 - val_accuracy: 0.7710\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4493 - accuracy: 0.8517 - val_loss: 0.6634 - val_accuracy: 0.7650\n",
      "Epoch 111/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4463 - accuracy: 0.8498 - val_loss: 0.6631 - val_accuracy: 0.7670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4432 - accuracy: 0.8542 - val_loss: 0.6626 - val_accuracy: 0.7680\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4400 - accuracy: 0.8546 - val_loss: 0.6610 - val_accuracy: 0.7680\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4367 - accuracy: 0.8565 - val_loss: 0.6613 - val_accuracy: 0.7730\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4336 - accuracy: 0.8588 - val_loss: 0.6599 - val_accuracy: 0.7690\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.4309 - accuracy: 0.8614 - val_loss: 0.6609 - val_accuracy: 0.7650\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4275 - accuracy: 0.8614 - val_loss: 0.6589 - val_accuracy: 0.7730\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4246 - accuracy: 0.8614 - val_loss: 0.6594 - val_accuracy: 0.7670\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4213 - accuracy: 0.8648 - val_loss: 0.6572 - val_accuracy: 0.7680\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.4187 - accuracy: 0.8642 - val_loss: 0.6576 - val_accuracy: 0.7640\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(X_train_token, \n",
    "                      y_train_label, \n",
    "                      epochs=120, \n",
    "                      batch_size=256, \n",
    "                      validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 19us/step\n",
      "Training Loss: 0.415 Training Accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_token, y_train_label)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess then evaluate our models performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 21us/step\n",
      "Testing Loss: 0.682 Testing Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "X_test_tok = tokenizer.texts_to_matrix(X_test, mode='binary')\n",
    "y_test_cat = to_categorical(lb.transform(y_test))[:, :, 1]\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list returned by `model.evaluate` is the loss, and the second is the accuracy score. \n",
    "\n",
    "Note that the result you obtained here isn't exactly the same as before. This is because the training set is slightly different! You removed 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"val_loss\"])\n",
    "    plt.plot(history[\"loss\"])\n",
    "    plt.legend(['Validation Set', 'Train Set'])\n",
    "    plt.title(\"Loss vs number of epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_accuracy(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"val_accuracy\"])\n",
    "    plt.plot(history[\"accuracy\"])\n",
    "    plt.legend(['Validation Set', 'Train Set'])\n",
    "    plt.title(\"Accuracy vs number of epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and val set\n",
    "visualize_loss(model_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and val set\n",
    "visualize_accuracy(model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.9472 - accuracy: 0.1752 - val_loss: 1.9238 - val_accuracy: 0.2200\n",
      "Epoch 2/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.9206 - accuracy: 0.2045 - val_loss: 1.9032 - val_accuracy: 0.2340\n",
      "Epoch 3/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.9016 - accuracy: 0.2174 - val_loss: 1.8849 - val_accuracy: 0.2520\n",
      "Epoch 4/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.8833 - accuracy: 0.2262 - val_loss: 1.8663 - val_accuracy: 0.2620\n",
      "Epoch 5/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.8639 - accuracy: 0.2372 - val_loss: 1.8466 - val_accuracy: 0.2830\n",
      "Epoch 6/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.8425 - accuracy: 0.2558 - val_loss: 1.8244 - val_accuracy: 0.2890\n",
      "Epoch 7/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.8182 - accuracy: 0.2752 - val_loss: 1.7997 - val_accuracy: 0.2920\n",
      "Epoch 8/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.7912 - accuracy: 0.2949 - val_loss: 1.7742 - val_accuracy: 0.3180\n",
      "Epoch 9/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.7616 - accuracy: 0.3202 - val_loss: 1.7442 - val_accuracy: 0.3280\n",
      "Epoch 10/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.7295 - accuracy: 0.3409 - val_loss: 1.7142 - val_accuracy: 0.3450\n",
      "Epoch 11/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.6959 - accuracy: 0.3628 - val_loss: 1.6836 - val_accuracy: 0.3640\n",
      "Epoch 12/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6613 - accuracy: 0.3863 - val_loss: 1.6517 - val_accuracy: 0.3920\n",
      "Epoch 13/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.6262 - accuracy: 0.4057 - val_loss: 1.6189 - val_accuracy: 0.4120\n",
      "Epoch 14/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.5904 - accuracy: 0.4243 - val_loss: 1.5852 - val_accuracy: 0.4290\n",
      "Epoch 15/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.5541 - accuracy: 0.4480 - val_loss: 1.5514 - val_accuracy: 0.4370\n",
      "Epoch 16/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.5178 - accuracy: 0.4658 - val_loss: 1.5180 - val_accuracy: 0.4550\n",
      "Epoch 17/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.4809 - accuracy: 0.4855 - val_loss: 1.4838 - val_accuracy: 0.4700\n",
      "Epoch 18/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4438 - accuracy: 0.5032 - val_loss: 1.4507 - val_accuracy: 0.4910\n",
      "Epoch 19/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.4063 - accuracy: 0.5185 - val_loss: 1.4168 - val_accuracy: 0.5130\n",
      "Epoch 20/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.3687 - accuracy: 0.5335 - val_loss: 1.3818 - val_accuracy: 0.5140\n",
      "Epoch 21/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3316 - accuracy: 0.5468 - val_loss: 1.3480 - val_accuracy: 0.5270\n",
      "Epoch 22/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2944 - accuracy: 0.5609 - val_loss: 1.3142 - val_accuracy: 0.5490\n",
      "Epoch 23/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.2588 - accuracy: 0.5762 - val_loss: 1.2831 - val_accuracy: 0.5730\n",
      "Epoch 24/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.2243 - accuracy: 0.5900 - val_loss: 1.2528 - val_accuracy: 0.5720\n",
      "Epoch 25/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1922 - accuracy: 0.6025 - val_loss: 1.2232 - val_accuracy: 0.5920\n",
      "Epoch 26/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1604 - accuracy: 0.6168 - val_loss: 1.1957 - val_accuracy: 0.6020\n",
      "Epoch 27/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.1304 - accuracy: 0.6309 - val_loss: 1.1691 - val_accuracy: 0.6160\n",
      "Epoch 28/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.1020 - accuracy: 0.6394 - val_loss: 1.1437 - val_accuracy: 0.6170\n",
      "Epoch 29/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.0747 - accuracy: 0.6508 - val_loss: 1.1203 - val_accuracy: 0.6280\n",
      "Epoch 30/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.0489 - accuracy: 0.6586 - val_loss: 1.0970 - val_accuracy: 0.6350\n",
      "Epoch 31/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.0244 - accuracy: 0.6628 - val_loss: 1.0754 - val_accuracy: 0.6450\n",
      "Epoch 32/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 1.0012 - accuracy: 0.6748 - val_loss: 1.0542 - val_accuracy: 0.6580\n",
      "Epoch 33/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9791 - accuracy: 0.6775 - val_loss: 1.0345 - val_accuracy: 0.6630\n",
      "Epoch 34/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9581 - accuracy: 0.6869 - val_loss: 1.0159 - val_accuracy: 0.6680\n",
      "Epoch 35/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9382 - accuracy: 0.6938 - val_loss: 0.9978 - val_accuracy: 0.6660\n",
      "Epoch 36/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9195 - accuracy: 0.6997 - val_loss: 0.9817 - val_accuracy: 0.6870\n",
      "Epoch 37/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.9018 - accuracy: 0.7060 - val_loss: 0.9658 - val_accuracy: 0.6870\n",
      "Epoch 38/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8844 - accuracy: 0.7097 - val_loss: 0.9506 - val_accuracy: 0.6870\n",
      "Epoch 39/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8686 - accuracy: 0.7140 - val_loss: 0.9376 - val_accuracy: 0.6950\n",
      "Epoch 40/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8532 - accuracy: 0.7198 - val_loss: 0.9223 - val_accuracy: 0.6990\n",
      "Epoch 41/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8386 - accuracy: 0.7218 - val_loss: 0.9098 - val_accuracy: 0.7040\n",
      "Epoch 42/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8245 - accuracy: 0.7274 - val_loss: 0.8982 - val_accuracy: 0.7110\n",
      "Epoch 43/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.8113 - accuracy: 0.7322 - val_loss: 0.8866 - val_accuracy: 0.7070\n",
      "Epoch 44/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7986 - accuracy: 0.7340 - val_loss: 0.8753 - val_accuracy: 0.7100\n",
      "Epoch 45/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.7863 - accuracy: 0.7365 - val_loss: 0.8646 - val_accuracy: 0.7110\n",
      "Epoch 46/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7747 - accuracy: 0.7403 - val_loss: 0.8550 - val_accuracy: 0.7180\n",
      "Epoch 47/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7639 - accuracy: 0.7434 - val_loss: 0.8453 - val_accuracy: 0.7210\n",
      "Epoch 48/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7528 - accuracy: 0.7448 - val_loss: 0.8366 - val_accuracy: 0.7260\n",
      "Epoch 49/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7428 - accuracy: 0.7491 - val_loss: 0.8270 - val_accuracy: 0.7200\n",
      "Epoch 50/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.7329 - accuracy: 0.7502 - val_loss: 0.8220 - val_accuracy: 0.7230\n",
      "Epoch 51/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7240 - accuracy: 0.7542 - val_loss: 0.8127 - val_accuracy: 0.7260\n",
      "Epoch 52/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7145 - accuracy: 0.7577 - val_loss: 0.8040 - val_accuracy: 0.7270\n",
      "Epoch 53/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.7053 - accuracy: 0.7608 - val_loss: 0.7998 - val_accuracy: 0.7320\n",
      "Epoch 54/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6972 - accuracy: 0.7600 - val_loss: 0.7904 - val_accuracy: 0.7300\n",
      "Epoch 55/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6891 - accuracy: 0.7662 - val_loss: 0.7833 - val_accuracy: 0.7340\n",
      "Epoch 56/60\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.6809 - accuracy: 0.7665 - val_loss: 0.7771 - val_accuracy: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6731 - accuracy: 0.7702 - val_loss: 0.7723 - val_accuracy: 0.7310\n",
      "Epoch 58/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6659 - accuracy: 0.7711 - val_loss: 0.7657 - val_accuracy: 0.7410\n",
      "Epoch 59/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6589 - accuracy: 0.7725 - val_loss: 0.7610 - val_accuracy: 0.7390\n",
      "Epoch 60/60\n",
      "6500/6500 [==============================] - 0s 23us/step - loss: 0.6518 - accuracy: 0.7757 - val_loss: 0.7575 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(X_train_token,\n",
    "                    y_train_label,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 18us/step\n",
      "Training Loss: 0.648 Training Accuracy: 0.779\n",
      "2500/2500 [==============================] - 0s 19us/step\n",
      "Testing Loss: 0.768 Testing Accuracy: 0.724\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_token, y_train_label)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 2.6008 - accuracy: 0.1672 - val_loss: 2.5945 - val_accuracy: 0.1780\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.5797 - accuracy: 0.2055 - val_loss: 2.5753 - val_accuracy: 0.2050\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.5580 - accuracy: 0.2442 - val_loss: 2.5550 - val_accuracy: 0.2390\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.5343 - accuracy: 0.2692 - val_loss: 2.5313 - val_accuracy: 0.2620\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.5069 - accuracy: 0.2903 - val_loss: 2.5039 - val_accuracy: 0.2930\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.4764 - accuracy: 0.3092 - val_loss: 2.4737 - val_accuracy: 0.3100\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.4425 - accuracy: 0.3286 - val_loss: 2.4404 - val_accuracy: 0.3310\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.4061 - accuracy: 0.3449 - val_loss: 2.4049 - val_accuracy: 0.3470\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.3679 - accuracy: 0.3654 - val_loss: 2.3676 - val_accuracy: 0.3660\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.3288 - accuracy: 0.3825 - val_loss: 2.3297 - val_accuracy: 0.3860\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2886 - accuracy: 0.3998 - val_loss: 2.2917 - val_accuracy: 0.4000\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2481 - accuracy: 0.4160 - val_loss: 2.2539 - val_accuracy: 0.4170\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2077 - accuracy: 0.4389 - val_loss: 2.2150 - val_accuracy: 0.4330\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1672 - accuracy: 0.4522 - val_loss: 2.1772 - val_accuracy: 0.4460\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1269 - accuracy: 0.4709 - val_loss: 2.1401 - val_accuracy: 0.4710\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0872 - accuracy: 0.4940 - val_loss: 2.1038 - val_accuracy: 0.4940\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0483 - accuracy: 0.5163 - val_loss: 2.0670 - val_accuracy: 0.5160\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0100 - accuracy: 0.5412 - val_loss: 2.0327 - val_accuracy: 0.5360\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9725 - accuracy: 0.5666 - val_loss: 1.9967 - val_accuracy: 0.5480\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9360 - accuracy: 0.5802 - val_loss: 1.9637 - val_accuracy: 0.5600\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9004 - accuracy: 0.6006 - val_loss: 1.9300 - val_accuracy: 0.5730\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8652 - accuracy: 0.6194 - val_loss: 1.8990 - val_accuracy: 0.5910\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8312 - accuracy: 0.6360 - val_loss: 1.8653 - val_accuracy: 0.6010\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7978 - accuracy: 0.6482 - val_loss: 1.8360 - val_accuracy: 0.6130\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7654 - accuracy: 0.6571 - val_loss: 1.8061 - val_accuracy: 0.6320\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7340 - accuracy: 0.6700 - val_loss: 1.7759 - val_accuracy: 0.6390\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7037 - accuracy: 0.6780 - val_loss: 1.7487 - val_accuracy: 0.6430\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6745 - accuracy: 0.6849 - val_loss: 1.7209 - val_accuracy: 0.6520\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6469 - accuracy: 0.6882 - val_loss: 1.6964 - val_accuracy: 0.6540\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6203 - accuracy: 0.6962 - val_loss: 1.6705 - val_accuracy: 0.6630\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5947 - accuracy: 0.6983 - val_loss: 1.6473 - val_accuracy: 0.6650\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5704 - accuracy: 0.7032 - val_loss: 1.6282 - val_accuracy: 0.6730\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5476 - accuracy: 0.7089 - val_loss: 1.6053 - val_accuracy: 0.6770\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5252 - accuracy: 0.7142 - val_loss: 1.5860 - val_accuracy: 0.6730\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5052 - accuracy: 0.7185 - val_loss: 1.5674 - val_accuracy: 0.6800\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4850 - accuracy: 0.7229 - val_loss: 1.5490 - val_accuracy: 0.6820\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4663 - accuracy: 0.7286 - val_loss: 1.5321 - val_accuracy: 0.6930\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4488 - accuracy: 0.7292 - val_loss: 1.5179 - val_accuracy: 0.6920\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4318 - accuracy: 0.7338 - val_loss: 1.5011 - val_accuracy: 0.6990\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4158 - accuracy: 0.7374 - val_loss: 1.4864 - val_accuracy: 0.7010\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4001 - accuracy: 0.7386 - val_loss: 1.4743 - val_accuracy: 0.7050\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3859 - accuracy: 0.7438 - val_loss: 1.4611 - val_accuracy: 0.7050\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3718 - accuracy: 0.7443 - val_loss: 1.4475 - val_accuracy: 0.7090\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3586 - accuracy: 0.7488 - val_loss: 1.4366 - val_accuracy: 0.7130\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3457 - accuracy: 0.7531 - val_loss: 1.4256 - val_accuracy: 0.7150\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3338 - accuracy: 0.7509 - val_loss: 1.4141 - val_accuracy: 0.7170\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3220 - accuracy: 0.7531 - val_loss: 1.4035 - val_accuracy: 0.7190\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3109 - accuracy: 0.7557 - val_loss: 1.3934 - val_accuracy: 0.7160\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3001 - accuracy: 0.7598 - val_loss: 1.3847 - val_accuracy: 0.7250\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2898 - accuracy: 0.7645 - val_loss: 1.3767 - val_accuracy: 0.7250\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2797 - accuracy: 0.7629 - val_loss: 1.3677 - val_accuracy: 0.7260\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2700 - accuracy: 0.7657 - val_loss: 1.3589 - val_accuracy: 0.7290\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2606 - accuracy: 0.7714 - val_loss: 1.3537 - val_accuracy: 0.7290\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2516 - accuracy: 0.7702 - val_loss: 1.3451 - val_accuracy: 0.7290\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2429 - accuracy: 0.7722 - val_loss: 1.3383 - val_accuracy: 0.7260\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2346 - accuracy: 0.7740 - val_loss: 1.3316 - val_accuracy: 0.7340\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2262 - accuracy: 0.7769 - val_loss: 1.3242 - val_accuracy: 0.7360\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2182 - accuracy: 0.7769 - val_loss: 1.3157 - val_accuracy: 0.7380\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2104 - accuracy: 0.7791 - val_loss: 1.3105 - val_accuracy: 0.7430\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2025 - accuracy: 0.7817 - val_loss: 1.3037 - val_accuracy: 0.7440\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1955 - accuracy: 0.7823 - val_loss: 1.3009 - val_accuracy: 0.7410\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1883 - accuracy: 0.7851 - val_loss: 1.2929 - val_accuracy: 0.7410\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1814 - accuracy: 0.7855 - val_loss: 1.2882 - val_accuracy: 0.7470\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1739 - accuracy: 0.7878 - val_loss: 1.2815 - val_accuracy: 0.7480\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1675 - accuracy: 0.7906 - val_loss: 1.2778 - val_accuracy: 0.7480\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1608 - accuracy: 0.7915 - val_loss: 1.2729 - val_accuracy: 0.7470\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1544 - accuracy: 0.7928 - val_loss: 1.2678 - val_accuracy: 0.7460\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1478 - accuracy: 0.7929 - val_loss: 1.2658 - val_accuracy: 0.7510\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1421 - accuracy: 0.7949 - val_loss: 1.2596 - val_accuracy: 0.7440\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1358 - accuracy: 0.7957 - val_loss: 1.2550 - val_accuracy: 0.7500\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1296 - accuracy: 0.7997 - val_loss: 1.2490 - val_accuracy: 0.7470\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1237 - accuracy: 0.8003 - val_loss: 1.2452 - val_accuracy: 0.7460\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1180 - accuracy: 0.8000 - val_loss: 1.2406 - val_accuracy: 0.7500\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1119 - accuracy: 0.8020 - val_loss: 1.2381 - val_accuracy: 0.7490\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1066 - accuracy: 0.8029 - val_loss: 1.2320 - val_accuracy: 0.7520\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1012 - accuracy: 0.8052 - val_loss: 1.2283 - val_accuracy: 0.7540\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0954 - accuracy: 0.8072 - val_loss: 1.2241 - val_accuracy: 0.7520\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0901 - accuracy: 0.8078 - val_loss: 1.2207 - val_accuracy: 0.7480\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0849 - accuracy: 0.8071 - val_loss: 1.2180 - val_accuracy: 0.7510\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0797 - accuracy: 0.8120 - val_loss: 1.2136 - val_accuracy: 0.7510\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0744 - accuracy: 0.8108 - val_loss: 1.2101 - val_accuracy: 0.7540\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0697 - accuracy: 0.8112 - val_loss: 1.2065 - val_accuracy: 0.7580\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0644 - accuracy: 0.8143 - val_loss: 1.2033 - val_accuracy: 0.7530\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0596 - accuracy: 0.8160 - val_loss: 1.2014 - val_accuracy: 0.7560\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0551 - accuracy: 0.8151 - val_loss: 1.1969 - val_accuracy: 0.7540\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0500 - accuracy: 0.8168 - val_loss: 1.1944 - val_accuracy: 0.7580\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0450 - accuracy: 0.8194 - val_loss: 1.1898 - val_accuracy: 0.7590\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0402 - accuracy: 0.8195 - val_loss: 1.1877 - val_accuracy: 0.7560\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0355 - accuracy: 0.8234 - val_loss: 1.1849 - val_accuracy: 0.7560\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0312 - accuracy: 0.8218 - val_loss: 1.1805 - val_accuracy: 0.7610\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0265 - accuracy: 0.8232 - val_loss: 1.1783 - val_accuracy: 0.7610\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0218 - accuracy: 0.8260 - val_loss: 1.1758 - val_accuracy: 0.7570\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0174 - accuracy: 0.8272 - val_loss: 1.1728 - val_accuracy: 0.7620\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0131 - accuracy: 0.8278 - val_loss: 1.1692 - val_accuracy: 0.7600\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0087 - accuracy: 0.8280 - val_loss: 1.1670 - val_accuracy: 0.7590\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0043 - accuracy: 0.8300 - val_loss: 1.1677 - val_accuracy: 0.7640\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0003 - accuracy: 0.8315 - val_loss: 1.1617 - val_accuracy: 0.7640\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9957 - accuracy: 0.8331 - val_loss: 1.1584 - val_accuracy: 0.7600\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9917 - accuracy: 0.8349 - val_loss: 1.1557 - val_accuracy: 0.7650\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9872 - accuracy: 0.8340 - val_loss: 1.1539 - val_accuracy: 0.7630\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9836 - accuracy: 0.8374 - val_loss: 1.1517 - val_accuracy: 0.7640\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9790 - accuracy: 0.8394 - val_loss: 1.1503 - val_accuracy: 0.7650\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9756 - accuracy: 0.8375 - val_loss: 1.1473 - val_accuracy: 0.7650\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9713 - accuracy: 0.8391 - val_loss: 1.1445 - val_accuracy: 0.7640\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9673 - accuracy: 0.8405 - val_loss: 1.1426 - val_accuracy: 0.7690\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9637 - accuracy: 0.8422 - val_loss: 1.1387 - val_accuracy: 0.7670\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9594 - accuracy: 0.8417 - val_loss: 1.1377 - val_accuracy: 0.7700\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9560 - accuracy: 0.8442 - val_loss: 1.1352 - val_accuracy: 0.7660\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9516 - accuracy: 0.8448 - val_loss: 1.1330 - val_accuracy: 0.7700\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9479 - accuracy: 0.8474 - val_loss: 1.1303 - val_accuracy: 0.7690\n",
      "Epoch 111/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9441 - accuracy: 0.8488 - val_loss: 1.1284 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9405 - accuracy: 0.8482 - val_loss: 1.1257 - val_accuracy: 0.7700\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9368 - accuracy: 0.8492 - val_loss: 1.1229 - val_accuracy: 0.7690\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9327 - accuracy: 0.8506 - val_loss: 1.1207 - val_accuracy: 0.7700\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9296 - accuracy: 0.8518 - val_loss: 1.1199 - val_accuracy: 0.7690\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9259 - accuracy: 0.8532 - val_loss: 1.1171 - val_accuracy: 0.7710\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9219 - accuracy: 0.8537 - val_loss: 1.1148 - val_accuracy: 0.7690\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9182 - accuracy: 0.8549 - val_loss: 1.1173 - val_accuracy: 0.7730\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9151 - accuracy: 0.8552 - val_loss: 1.1136 - val_accuracy: 0.7760\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9115 - accuracy: 0.8569 - val_loss: 1.1090 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(X_train_token,\n",
    "                    y_train_label,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, model_acc, label='Training acc')\n",
    "ax.plot(epochs, model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 16.0143 - accuracy: 0.1468 - val_loss: 15.6544 - val_accuracy: 0.1620\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 15.3532 - accuracy: 0.1758 - val_loss: 15.0066 - val_accuracy: 0.1960\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 14.7131 - accuracy: 0.2034 - val_loss: 14.3772 - val_accuracy: 0.2090\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 14.0909 - accuracy: 0.2158 - val_loss: 13.7651 - val_accuracy: 0.2250\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 13.4854 - accuracy: 0.2225 - val_loss: 13.1683 - val_accuracy: 0.2300\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 12.8947 - accuracy: 0.2295 - val_loss: 12.5866 - val_accuracy: 0.2270\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 12.3187 - accuracy: 0.2335 - val_loss: 12.0192 - val_accuracy: 0.2350\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 11.7570 - accuracy: 0.2455 - val_loss: 11.4661 - val_accuracy: 0.2400\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 11.2098 - accuracy: 0.2557 - val_loss: 10.9283 - val_accuracy: 0.2480\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 10.6776 - accuracy: 0.2705 - val_loss: 10.4056 - val_accuracy: 0.2730\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 10.1604 - accuracy: 0.2946 - val_loss: 9.8975 - val_accuracy: 0.2920\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 9.6577 - accuracy: 0.3094 - val_loss: 9.4047 - val_accuracy: 0.3060\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 9.1693 - accuracy: 0.3231 - val_loss: 8.9253 - val_accuracy: 0.3450\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 8.6958 - accuracy: 0.3551 - val_loss: 8.4619 - val_accuracy: 0.3580\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 8.2386 - accuracy: 0.3771 - val_loss: 8.0160 - val_accuracy: 0.3990\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 7.7984 - accuracy: 0.4032 - val_loss: 7.5863 - val_accuracy: 0.4240\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 7.3748 - accuracy: 0.4262 - val_loss: 7.1728 - val_accuracy: 0.4390\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 6.9684 - accuracy: 0.4554 - val_loss: 6.7763 - val_accuracy: 0.4380\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 6.5791 - accuracy: 0.4683 - val_loss: 6.3970 - val_accuracy: 0.4750\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 6.2067 - accuracy: 0.4911 - val_loss: 6.0350 - val_accuracy: 0.4880\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.8518 - accuracy: 0.5078 - val_loss: 5.6906 - val_accuracy: 0.5110\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.5134 - accuracy: 0.5257 - val_loss: 5.3617 - val_accuracy: 0.5130\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.1923 - accuracy: 0.5392 - val_loss: 5.0507 - val_accuracy: 0.5280\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.8882 - accuracy: 0.5557 - val_loss: 4.7561 - val_accuracy: 0.5370\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.6010 - accuracy: 0.5686 - val_loss: 4.4789 - val_accuracy: 0.5510\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.3302 - accuracy: 0.5815 - val_loss: 4.2162 - val_accuracy: 0.5700\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.0754 - accuracy: 0.5926 - val_loss: 3.9710 - val_accuracy: 0.5720\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.8368 - accuracy: 0.6022 - val_loss: 3.7417 - val_accuracy: 0.5880\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.6141 - accuracy: 0.6137 - val_loss: 3.5272 - val_accuracy: 0.5860\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.4069 - accuracy: 0.6158 - val_loss: 3.3292 - val_accuracy: 0.5940\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.2156 - accuracy: 0.6229 - val_loss: 3.1480 - val_accuracy: 0.6120\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.0402 - accuracy: 0.6340 - val_loss: 2.9798 - val_accuracy: 0.6190\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.8806 - accuracy: 0.6360 - val_loss: 2.8296 - val_accuracy: 0.6160\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.7365 - accuracy: 0.6402 - val_loss: 2.6942 - val_accuracy: 0.6140\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.6082 - accuracy: 0.6455 - val_loss: 2.5744 - val_accuracy: 0.6340\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.4948 - accuracy: 0.6508 - val_loss: 2.4686 - val_accuracy: 0.6340\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.3962 - accuracy: 0.6517 - val_loss: 2.3791 - val_accuracy: 0.6380\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 2.3122 - accuracy: 0.6586 - val_loss: 2.3027 - val_accuracy: 0.6230\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2416 - accuracy: 0.6592 - val_loss: 2.2378 - val_accuracy: 0.6370\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1843 - accuracy: 0.6594 - val_loss: 2.1868 - val_accuracy: 0.6390\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1391 - accuracy: 0.6622 - val_loss: 2.1486 - val_accuracy: 0.6490\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1040 - accuracy: 0.6658 - val_loss: 2.1172 - val_accuracy: 0.6490\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0751 - accuracy: 0.6672 - val_loss: 2.0909 - val_accuracy: 0.6510\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0505 - accuracy: 0.6689 - val_loss: 2.0666 - val_accuracy: 0.6510\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0281 - accuracy: 0.6712 - val_loss: 2.0455 - val_accuracy: 0.6520\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0073 - accuracy: 0.6709 - val_loss: 2.0265 - val_accuracy: 0.6470\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9878 - accuracy: 0.6711 - val_loss: 2.0068 - val_accuracy: 0.6560\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9691 - accuracy: 0.6712 - val_loss: 1.9890 - val_accuracy: 0.6630\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9517 - accuracy: 0.6762 - val_loss: 1.9730 - val_accuracy: 0.6620\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9350 - accuracy: 0.6766 - val_loss: 1.9549 - val_accuracy: 0.6660\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9185 - accuracy: 0.6789 - val_loss: 1.9406 - val_accuracy: 0.6720\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9027 - accuracy: 0.6794 - val_loss: 1.9254 - val_accuracy: 0.6750\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8878 - accuracy: 0.6814 - val_loss: 1.9084 - val_accuracy: 0.6720\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8732 - accuracy: 0.6812 - val_loss: 1.8941 - val_accuracy: 0.6790\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8588 - accuracy: 0.6832 - val_loss: 1.8800 - val_accuracy: 0.6750\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8454 - accuracy: 0.6845 - val_loss: 1.8661 - val_accuracy: 0.6780\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8321 - accuracy: 0.6845 - val_loss: 1.8545 - val_accuracy: 0.6810\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8195 - accuracy: 0.6860 - val_loss: 1.8392 - val_accuracy: 0.6830\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8072 - accuracy: 0.6868 - val_loss: 1.8304 - val_accuracy: 0.6800\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7953 - accuracy: 0.6872 - val_loss: 1.8164 - val_accuracy: 0.6810\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7835 - accuracy: 0.6897 - val_loss: 1.8034 - val_accuracy: 0.6850\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7720 - accuracy: 0.6874 - val_loss: 1.7933 - val_accuracy: 0.6770\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7614 - accuracy: 0.6889 - val_loss: 1.7848 - val_accuracy: 0.6840\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7507 - accuracy: 0.6909 - val_loss: 1.7714 - val_accuracy: 0.6920\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7400 - accuracy: 0.6915 - val_loss: 1.7599 - val_accuracy: 0.6850\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7301 - accuracy: 0.6925 - val_loss: 1.7512 - val_accuracy: 0.6880\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7204 - accuracy: 0.6925 - val_loss: 1.7411 - val_accuracy: 0.6880\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7102 - accuracy: 0.6925 - val_loss: 1.7308 - val_accuracy: 0.6870\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7008 - accuracy: 0.6932 - val_loss: 1.7212 - val_accuracy: 0.6910\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6918 - accuracy: 0.6949 - val_loss: 1.7111 - val_accuracy: 0.6910\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6828 - accuracy: 0.6969 - val_loss: 1.7021 - val_accuracy: 0.6880\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6734 - accuracy: 0.6960 - val_loss: 1.6932 - val_accuracy: 0.6940\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6651 - accuracy: 0.6983 - val_loss: 1.6847 - val_accuracy: 0.6930\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6565 - accuracy: 0.6992 - val_loss: 1.6756 - val_accuracy: 0.6880\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6478 - accuracy: 0.6997 - val_loss: 1.6674 - val_accuracy: 0.6890\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6397 - accuracy: 0.6988 - val_loss: 1.6589 - val_accuracy: 0.6950\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6317 - accuracy: 0.6988 - val_loss: 1.6500 - val_accuracy: 0.7050\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6237 - accuracy: 0.7015 - val_loss: 1.6429 - val_accuracy: 0.6980\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6161 - accuracy: 0.7023 - val_loss: 1.6349 - val_accuracy: 0.6940\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6085 - accuracy: 0.7002 - val_loss: 1.6259 - val_accuracy: 0.7010\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6005 - accuracy: 0.7014 - val_loss: 1.6195 - val_accuracy: 0.7040\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5932 - accuracy: 0.7012 - val_loss: 1.6130 - val_accuracy: 0.7020\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5861 - accuracy: 0.7017 - val_loss: 1.6038 - val_accuracy: 0.7030\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5784 - accuracy: 0.7038 - val_loss: 1.5980 - val_accuracy: 0.6970\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5714 - accuracy: 0.7040 - val_loss: 1.5899 - val_accuracy: 0.7010\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5648 - accuracy: 0.7015 - val_loss: 1.5825 - val_accuracy: 0.7040\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5577 - accuracy: 0.7042 - val_loss: 1.5753 - val_accuracy: 0.7000\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5509 - accuracy: 0.7040 - val_loss: 1.5710 - val_accuracy: 0.6980\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5444 - accuracy: 0.7043 - val_loss: 1.5637 - val_accuracy: 0.6960\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5378 - accuracy: 0.7035 - val_loss: 1.5562 - val_accuracy: 0.7010\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5313 - accuracy: 0.7057 - val_loss: 1.5493 - val_accuracy: 0.7010\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5247 - accuracy: 0.7063 - val_loss: 1.5416 - val_accuracy: 0.7100\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5187 - accuracy: 0.7062 - val_loss: 1.5355 - val_accuracy: 0.7050\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5123 - accuracy: 0.7060 - val_loss: 1.5285 - val_accuracy: 0.7040\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5056 - accuracy: 0.7051 - val_loss: 1.5236 - val_accuracy: 0.7070\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4996 - accuracy: 0.7085 - val_loss: 1.5159 - val_accuracy: 0.7080\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4940 - accuracy: 0.7095 - val_loss: 1.5130 - val_accuracy: 0.7010\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4880 - accuracy: 0.7091 - val_loss: 1.5067 - val_accuracy: 0.7080\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4823 - accuracy: 0.7091 - val_loss: 1.4983 - val_accuracy: 0.7100\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4759 - accuracy: 0.7108 - val_loss: 1.4919 - val_accuracy: 0.7140\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4703 - accuracy: 0.7097 - val_loss: 1.4856 - val_accuracy: 0.7110\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4648 - accuracy: 0.7089 - val_loss: 1.4822 - val_accuracy: 0.7090\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4587 - accuracy: 0.7105 - val_loss: 1.4743 - val_accuracy: 0.7080\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4535 - accuracy: 0.7106 - val_loss: 1.4714 - val_accuracy: 0.7160\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4481 - accuracy: 0.7109 - val_loss: 1.4674 - val_accuracy: 0.7050\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4428 - accuracy: 0.7126 - val_loss: 1.4627 - val_accuracy: 0.7020\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4372 - accuracy: 0.7120 - val_loss: 1.4560 - val_accuracy: 0.7070\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4319 - accuracy: 0.7138 - val_loss: 1.4476 - val_accuracy: 0.7100\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4269 - accuracy: 0.7140 - val_loss: 1.4409 - val_accuracy: 0.7160\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4209 - accuracy: 0.7132 - val_loss: 1.4382 - val_accuracy: 0.7170\n",
      "Epoch 111/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4164 - accuracy: 0.7132 - val_loss: 1.4302 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4108 - accuracy: 0.7142 - val_loss: 1.4273 - val_accuracy: 0.7130\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4062 - accuracy: 0.7140 - val_loss: 1.4214 - val_accuracy: 0.7170\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4008 - accuracy: 0.7138 - val_loss: 1.4170 - val_accuracy: 0.7180\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3960 - accuracy: 0.7149 - val_loss: 1.4147 - val_accuracy: 0.7080\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3910 - accuracy: 0.7158 - val_loss: 1.4045 - val_accuracy: 0.7160\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3855 - accuracy: 0.7169 - val_loss: 1.4003 - val_accuracy: 0.7160\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3811 - accuracy: 0.7160 - val_loss: 1.3984 - val_accuracy: 0.7170\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3762 - accuracy: 0.7174 - val_loss: 1.3911 - val_accuracy: 0.7230\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3719 - accuracy: 0.7168 - val_loss: 1.3858 - val_accuracy: 0.7220\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_token,\n",
    "                    y_train_label,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 16.0369 - accuracy: 0.1458 - val_loss: 15.6770 - val_accuracy: 0.1610\n",
      "Epoch 2/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 15.3797 - accuracy: 0.1531 - val_loss: 15.0330 - val_accuracy: 0.1690\n",
      "Epoch 3/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 14.7425 - accuracy: 0.1598 - val_loss: 14.4071 - val_accuracy: 0.1810\n",
      "Epoch 4/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 14.1230 - accuracy: 0.1728 - val_loss: 13.7980 - val_accuracy: 0.2010\n",
      "Epoch 5/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 13.5199 - accuracy: 0.1885 - val_loss: 13.2050 - val_accuracy: 0.2180\n",
      "Epoch 6/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 12.9326 - accuracy: 0.2068 - val_loss: 12.6274 - val_accuracy: 0.2350\n",
      "Epoch 7/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 12.3608 - accuracy: 0.2260 - val_loss: 12.0648 - val_accuracy: 0.2470\n",
      "Epoch 8/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 11.8034 - accuracy: 0.2477 - val_loss: 11.5160 - val_accuracy: 0.2600\n",
      "Epoch 9/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 11.2602 - accuracy: 0.2671 - val_loss: 10.9817 - val_accuracy: 0.2700\n",
      "Epoch 10/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 10.7320 - accuracy: 0.2835 - val_loss: 10.4627 - val_accuracy: 0.2870\n",
      "Epoch 11/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 10.2195 - accuracy: 0.3062 - val_loss: 9.9595 - val_accuracy: 0.3100\n",
      "Epoch 12/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 9.7222 - accuracy: 0.3289 - val_loss: 9.4716 - val_accuracy: 0.3390\n",
      "Epoch 13/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 9.2397 - accuracy: 0.3609 - val_loss: 8.9984 - val_accuracy: 0.3570\n",
      "Epoch 14/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 8.7722 - accuracy: 0.3709 - val_loss: 8.5408 - val_accuracy: 0.3830\n",
      "Epoch 15/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 8.3199 - accuracy: 0.4003 - val_loss: 8.0979 - val_accuracy: 0.4090\n",
      "Epoch 16/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 7.8830 - accuracy: 0.4294 - val_loss: 7.6723 - val_accuracy: 0.4450\n",
      "Epoch 17/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 7.4623 - accuracy: 0.4665 - val_loss: 7.2620 - val_accuracy: 0.4690\n",
      "Epoch 18/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 7.0576 - accuracy: 0.4915 - val_loss: 6.8671 - val_accuracy: 0.4800\n",
      "Epoch 19/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 6.6692 - accuracy: 0.5057 - val_loss: 6.4900 - val_accuracy: 0.4990\n",
      "Epoch 20/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 6.2974 - accuracy: 0.5228 - val_loss: 6.1281 - val_accuracy: 0.5160\n",
      "Epoch 21/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.9417 - accuracy: 0.5366 - val_loss: 5.7840 - val_accuracy: 0.5220\n",
      "Epoch 22/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.6026 - accuracy: 0.5469 - val_loss: 5.4533 - val_accuracy: 0.5260\n",
      "Epoch 23/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 5.2794 - accuracy: 0.5555 - val_loss: 5.1403 - val_accuracy: 0.5450\n",
      "Epoch 24/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.9724 - accuracy: 0.5655 - val_loss: 4.8437 - val_accuracy: 0.5460\n",
      "Epoch 25/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.6819 - accuracy: 0.5728 - val_loss: 4.5625 - val_accuracy: 0.5450\n",
      "Epoch 26/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.4080 - accuracy: 0.5726 - val_loss: 4.2983 - val_accuracy: 0.5480\n",
      "Epoch 27/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 4.1503 - accuracy: 0.5762 - val_loss: 4.0494 - val_accuracy: 0.5480\n",
      "Epoch 28/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.9083 - accuracy: 0.5828 - val_loss: 3.8180 - val_accuracy: 0.5460\n",
      "Epoch 29/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.6829 - accuracy: 0.5834 - val_loss: 3.6017 - val_accuracy: 0.5490\n",
      "Epoch 30/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.4736 - accuracy: 0.5846 - val_loss: 3.4011 - val_accuracy: 0.5570\n",
      "Epoch 31/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.2798 - accuracy: 0.5815 - val_loss: 3.2175 - val_accuracy: 0.5630\n",
      "Epoch 32/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 3.1016 - accuracy: 0.5828 - val_loss: 3.0479 - val_accuracy: 0.5760\n",
      "Epoch 33/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.9395 - accuracy: 0.5906 - val_loss: 2.8950 - val_accuracy: 0.5690\n",
      "Epoch 34/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.7937 - accuracy: 0.5880 - val_loss: 2.7588 - val_accuracy: 0.5820\n",
      "Epoch 35/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.6636 - accuracy: 0.5932 - val_loss: 2.6368 - val_accuracy: 0.5750\n",
      "Epoch 36/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.5493 - accuracy: 0.5935 - val_loss: 2.5311 - val_accuracy: 0.5840\n",
      "Epoch 37/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.4499 - accuracy: 0.5957 - val_loss: 2.4387 - val_accuracy: 0.5820\n",
      "Epoch 38/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.3650 - accuracy: 0.5969 - val_loss: 2.3629 - val_accuracy: 0.5920\n",
      "Epoch 39/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2945 - accuracy: 0.6031 - val_loss: 2.2974 - val_accuracy: 0.5890\n",
      "Epoch 40/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.2367 - accuracy: 0.6046 - val_loss: 2.2471 - val_accuracy: 0.5920\n",
      "Epoch 41/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1914 - accuracy: 0.6083 - val_loss: 2.2092 - val_accuracy: 0.6020\n",
      "Epoch 42/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1563 - accuracy: 0.6165 - val_loss: 2.1776 - val_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1280 - accuracy: 0.6169 - val_loss: 2.1508 - val_accuracy: 0.5980\n",
      "Epoch 44/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.1032 - accuracy: 0.6185 - val_loss: 2.1276 - val_accuracy: 0.6030\n",
      "Epoch 45/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0804 - accuracy: 0.6251 - val_loss: 2.1067 - val_accuracy: 0.6180\n",
      "Epoch 46/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0595 - accuracy: 0.6288 - val_loss: 2.0859 - val_accuracy: 0.6230\n",
      "Epoch 47/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0395 - accuracy: 0.6355 - val_loss: 2.0667 - val_accuracy: 0.6230\n",
      "Epoch 48/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0204 - accuracy: 0.6360 - val_loss: 2.0493 - val_accuracy: 0.6300\n",
      "Epoch 49/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 2.0022 - accuracy: 0.6392 - val_loss: 2.0296 - val_accuracy: 0.6270\n",
      "Epoch 50/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9850 - accuracy: 0.6400 - val_loss: 2.0132 - val_accuracy: 0.6320\n",
      "Epoch 51/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9680 - accuracy: 0.6437 - val_loss: 1.9965 - val_accuracy: 0.6360\n",
      "Epoch 52/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9519 - accuracy: 0.6463 - val_loss: 1.9814 - val_accuracy: 0.6430\n",
      "Epoch 53/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9365 - accuracy: 0.6497 - val_loss: 1.9649 - val_accuracy: 0.6390\n",
      "Epoch 54/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9214 - accuracy: 0.6522 - val_loss: 1.9494 - val_accuracy: 0.6410\n",
      "Epoch 55/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.9066 - accuracy: 0.6526 - val_loss: 1.9355 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8928 - accuracy: 0.6552 - val_loss: 1.9232 - val_accuracy: 0.6470\n",
      "Epoch 57/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8794 - accuracy: 0.6575 - val_loss: 1.9079 - val_accuracy: 0.6400\n",
      "Epoch 58/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8659 - accuracy: 0.6577 - val_loss: 1.8975 - val_accuracy: 0.6570\n",
      "Epoch 59/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8538 - accuracy: 0.6631 - val_loss: 1.8825 - val_accuracy: 0.6550\n",
      "Epoch 60/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8411 - accuracy: 0.6620 - val_loss: 1.8700 - val_accuracy: 0.6560\n",
      "Epoch 61/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8294 - accuracy: 0.6631 - val_loss: 1.8590 - val_accuracy: 0.6610\n",
      "Epoch 62/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8176 - accuracy: 0.6638 - val_loss: 1.8470 - val_accuracy: 0.6590\n",
      "Epoch 63/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.8065 - accuracy: 0.6672 - val_loss: 1.8357 - val_accuracy: 0.6580\n",
      "Epoch 64/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7956 - accuracy: 0.6686 - val_loss: 1.8253 - val_accuracy: 0.6640\n",
      "Epoch 65/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7849 - accuracy: 0.6717 - val_loss: 1.8147 - val_accuracy: 0.6640\n",
      "Epoch 66/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7744 - accuracy: 0.6726 - val_loss: 1.8040 - val_accuracy: 0.6620\n",
      "Epoch 67/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7646 - accuracy: 0.6754 - val_loss: 1.7917 - val_accuracy: 0.6610\n",
      "Epoch 68/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7548 - accuracy: 0.6768 - val_loss: 1.7833 - val_accuracy: 0.6670\n",
      "Epoch 69/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7448 - accuracy: 0.6768 - val_loss: 1.7724 - val_accuracy: 0.6670\n",
      "Epoch 70/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7352 - accuracy: 0.6809 - val_loss: 1.7643 - val_accuracy: 0.6650\n",
      "Epoch 71/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7261 - accuracy: 0.6815 - val_loss: 1.7567 - val_accuracy: 0.6610\n",
      "Epoch 72/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7169 - accuracy: 0.6808 - val_loss: 1.7444 - val_accuracy: 0.6690\n",
      "Epoch 73/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.7077 - accuracy: 0.6834 - val_loss: 1.7348 - val_accuracy: 0.6720\n",
      "Epoch 74/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6993 - accuracy: 0.6845 - val_loss: 1.7264 - val_accuracy: 0.6710\n",
      "Epoch 75/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6904 - accuracy: 0.6848 - val_loss: 1.7185 - val_accuracy: 0.6760\n",
      "Epoch 76/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6820 - accuracy: 0.6874 - val_loss: 1.7095 - val_accuracy: 0.6750\n",
      "Epoch 77/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6737 - accuracy: 0.6871 - val_loss: 1.7004 - val_accuracy: 0.6810\n",
      "Epoch 78/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6655 - accuracy: 0.6882 - val_loss: 1.6912 - val_accuracy: 0.6720\n",
      "Epoch 79/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6576 - accuracy: 0.6902 - val_loss: 1.6858 - val_accuracy: 0.6730\n",
      "Epoch 80/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6497 - accuracy: 0.6885 - val_loss: 1.6765 - val_accuracy: 0.6790\n",
      "Epoch 81/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6417 - accuracy: 0.6877 - val_loss: 1.6681 - val_accuracy: 0.6740\n",
      "Epoch 82/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6338 - accuracy: 0.6902 - val_loss: 1.6641 - val_accuracy: 0.6810\n",
      "Epoch 83/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6268 - accuracy: 0.6912 - val_loss: 1.6527 - val_accuracy: 0.6760\n",
      "Epoch 84/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6191 - accuracy: 0.6897 - val_loss: 1.6454 - val_accuracy: 0.6810\n",
      "Epoch 85/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6116 - accuracy: 0.6911 - val_loss: 1.6369 - val_accuracy: 0.6790\n",
      "Epoch 86/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.6041 - accuracy: 0.6932 - val_loss: 1.6297 - val_accuracy: 0.6810\n",
      "Epoch 87/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5971 - accuracy: 0.6926 - val_loss: 1.6227 - val_accuracy: 0.6880\n",
      "Epoch 88/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5901 - accuracy: 0.6946 - val_loss: 1.6157 - val_accuracy: 0.6860\n",
      "Epoch 89/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5832 - accuracy: 0.6934 - val_loss: 1.6098 - val_accuracy: 0.6880\n",
      "Epoch 90/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5761 - accuracy: 0.6945 - val_loss: 1.6015 - val_accuracy: 0.6860\n",
      "Epoch 91/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5694 - accuracy: 0.6955 - val_loss: 1.5941 - val_accuracy: 0.6870\n",
      "Epoch 92/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5628 - accuracy: 0.6960 - val_loss: 1.5866 - val_accuracy: 0.6820\n",
      "Epoch 93/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5558 - accuracy: 0.6971 - val_loss: 1.5790 - val_accuracy: 0.6840\n",
      "Epoch 94/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5491 - accuracy: 0.6988 - val_loss: 1.5735 - val_accuracy: 0.6860\n",
      "Epoch 95/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5429 - accuracy: 0.6977 - val_loss: 1.5720 - val_accuracy: 0.6950\n",
      "Epoch 96/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5368 - accuracy: 0.6983 - val_loss: 1.5596 - val_accuracy: 0.6890\n",
      "Epoch 97/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5299 - accuracy: 0.6983 - val_loss: 1.5532 - val_accuracy: 0.6900\n",
      "Epoch 98/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5229 - accuracy: 0.6991 - val_loss: 1.5464 - val_accuracy: 0.6850\n",
      "Epoch 99/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5168 - accuracy: 0.7031 - val_loss: 1.5398 - val_accuracy: 0.6940\n",
      "Epoch 100/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5106 - accuracy: 0.6988 - val_loss: 1.5359 - val_accuracy: 0.6990\n",
      "Epoch 101/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.5044 - accuracy: 0.7011 - val_loss: 1.5286 - val_accuracy: 0.6990\n",
      "Epoch 102/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4985 - accuracy: 0.7018 - val_loss: 1.5214 - val_accuracy: 0.6940\n",
      "Epoch 103/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4923 - accuracy: 0.7023 - val_loss: 1.5142 - val_accuracy: 0.6970\n",
      "Epoch 104/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4863 - accuracy: 0.7037 - val_loss: 1.5107 - val_accuracy: 0.6970\n",
      "Epoch 105/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4804 - accuracy: 0.7042 - val_loss: 1.5058 - val_accuracy: 0.7010\n",
      "Epoch 106/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4744 - accuracy: 0.7022 - val_loss: 1.5016 - val_accuracy: 0.6980\n",
      "Epoch 107/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4690 - accuracy: 0.7022 - val_loss: 1.4918 - val_accuracy: 0.6970\n",
      "Epoch 108/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4631 - accuracy: 0.7034 - val_loss: 1.4861 - val_accuracy: 0.7030\n",
      "Epoch 109/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4572 - accuracy: 0.7042 - val_loss: 1.4810 - val_accuracy: 0.7010\n",
      "Epoch 110/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4514 - accuracy: 0.7043 - val_loss: 1.4745 - val_accuracy: 0.7070\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4456 - accuracy: 0.7051 - val_loss: 1.4677 - val_accuracy: 0.7060\n",
      "Epoch 112/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4402 - accuracy: 0.7052 - val_loss: 1.4615 - val_accuracy: 0.7050\n",
      "Epoch 113/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4351 - accuracy: 0.7051 - val_loss: 1.4573 - val_accuracy: 0.7070\n",
      "Epoch 114/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4301 - accuracy: 0.7078 - val_loss: 1.4540 - val_accuracy: 0.7060\n",
      "Epoch 115/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4242 - accuracy: 0.7060 - val_loss: 1.4477 - val_accuracy: 0.7100\n",
      "Epoch 116/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4189 - accuracy: 0.7074 - val_loss: 1.4425 - val_accuracy: 0.7040\n",
      "Epoch 117/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4135 - accuracy: 0.7100 - val_loss: 1.4339 - val_accuracy: 0.7110\n",
      "Epoch 118/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4088 - accuracy: 0.7089 - val_loss: 1.4293 - val_accuracy: 0.7080\n",
      "Epoch 119/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.4031 - accuracy: 0.7088 - val_loss: 1.4237 - val_accuracy: 0.7140\n",
      "Epoch 120/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3979 - accuracy: 0.7088 - val_loss: 1.4166 - val_accuracy: 0.7100\n",
      "Epoch 121/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3924 - accuracy: 0.7105 - val_loss: 1.4128 - val_accuracy: 0.7140\n",
      "Epoch 122/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3875 - accuracy: 0.7080 - val_loss: 1.4065 - val_accuracy: 0.7100\n",
      "Epoch 123/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3819 - accuracy: 0.7109 - val_loss: 1.4029 - val_accuracy: 0.7110\n",
      "Epoch 124/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3779 - accuracy: 0.7105 - val_loss: 1.3959 - val_accuracy: 0.7120\n",
      "Epoch 125/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3723 - accuracy: 0.7105 - val_loss: 1.3936 - val_accuracy: 0.7100\n",
      "Epoch 126/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3676 - accuracy: 0.7098 - val_loss: 1.3856 - val_accuracy: 0.7130\n",
      "Epoch 127/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3621 - accuracy: 0.7122 - val_loss: 1.3809 - val_accuracy: 0.7150\n",
      "Epoch 128/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3575 - accuracy: 0.7131 - val_loss: 1.3766 - val_accuracy: 0.7150\n",
      "Epoch 129/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3527 - accuracy: 0.7131 - val_loss: 1.3755 - val_accuracy: 0.7150\n",
      "Epoch 130/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3482 - accuracy: 0.7129 - val_loss: 1.3693 - val_accuracy: 0.7170\n",
      "Epoch 131/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3437 - accuracy: 0.7122 - val_loss: 1.3650 - val_accuracy: 0.7150\n",
      "Epoch 132/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3391 - accuracy: 0.7140 - val_loss: 1.3586 - val_accuracy: 0.7150\n",
      "Epoch 133/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3343 - accuracy: 0.7134 - val_loss: 1.3527 - val_accuracy: 0.7160\n",
      "Epoch 134/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3295 - accuracy: 0.7155 - val_loss: 1.3480 - val_accuracy: 0.7210\n",
      "Epoch 135/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3257 - accuracy: 0.7145 - val_loss: 1.3448 - val_accuracy: 0.7150\n",
      "Epoch 136/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3211 - accuracy: 0.7143 - val_loss: 1.3375 - val_accuracy: 0.7210\n",
      "Epoch 137/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3166 - accuracy: 0.7169 - val_loss: 1.3351 - val_accuracy: 0.7190\n",
      "Epoch 138/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3116 - accuracy: 0.7155 - val_loss: 1.3315 - val_accuracy: 0.7170\n",
      "Epoch 139/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3074 - accuracy: 0.7174 - val_loss: 1.3234 - val_accuracy: 0.7190\n",
      "Epoch 140/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.3032 - accuracy: 0.7172 - val_loss: 1.3199 - val_accuracy: 0.7270\n",
      "Epoch 141/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2993 - accuracy: 0.7162 - val_loss: 1.3164 - val_accuracy: 0.7190\n",
      "Epoch 142/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2949 - accuracy: 0.7174 - val_loss: 1.3145 - val_accuracy: 0.7240\n",
      "Epoch 143/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2911 - accuracy: 0.7189 - val_loss: 1.3107 - val_accuracy: 0.7260\n",
      "Epoch 144/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2875 - accuracy: 0.7182 - val_loss: 1.3043 - val_accuracy: 0.7230\n",
      "Epoch 145/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2831 - accuracy: 0.7192 - val_loss: 1.2999 - val_accuracy: 0.7160\n",
      "Epoch 146/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2789 - accuracy: 0.7189 - val_loss: 1.2968 - val_accuracy: 0.7200\n",
      "Epoch 147/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2752 - accuracy: 0.7200 - val_loss: 1.2917 - val_accuracy: 0.7240\n",
      "Epoch 148/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2711 - accuracy: 0.7202 - val_loss: 1.2872 - val_accuracy: 0.7300\n",
      "Epoch 149/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2676 - accuracy: 0.7183 - val_loss: 1.2831 - val_accuracy: 0.7300\n",
      "Epoch 150/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2640 - accuracy: 0.7215 - val_loss: 1.2870 - val_accuracy: 0.7200\n",
      "Epoch 151/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2601 - accuracy: 0.7205 - val_loss: 1.2750 - val_accuracy: 0.7260\n",
      "Epoch 152/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2559 - accuracy: 0.7217 - val_loss: 1.2723 - val_accuracy: 0.7260\n",
      "Epoch 153/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2524 - accuracy: 0.7208 - val_loss: 1.2672 - val_accuracy: 0.7280\n",
      "Epoch 154/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2491 - accuracy: 0.7228 - val_loss: 1.2639 - val_accuracy: 0.7320\n",
      "Epoch 155/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2446 - accuracy: 0.7217 - val_loss: 1.2590 - val_accuracy: 0.7360\n",
      "Epoch 156/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2412 - accuracy: 0.7234 - val_loss: 1.2565 - val_accuracy: 0.7280\n",
      "Epoch 157/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2374 - accuracy: 0.7231 - val_loss: 1.2537 - val_accuracy: 0.7280\n",
      "Epoch 158/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2340 - accuracy: 0.7245 - val_loss: 1.2496 - val_accuracy: 0.7280\n",
      "Epoch 159/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2302 - accuracy: 0.7252 - val_loss: 1.2456 - val_accuracy: 0.7350\n",
      "Epoch 160/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2271 - accuracy: 0.7248 - val_loss: 1.2422 - val_accuracy: 0.7330\n",
      "Epoch 161/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2237 - accuracy: 0.7245 - val_loss: 1.2386 - val_accuracy: 0.7360\n",
      "Epoch 162/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2205 - accuracy: 0.7260 - val_loss: 1.2335 - val_accuracy: 0.7320\n",
      "Epoch 163/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2165 - accuracy: 0.7263 - val_loss: 1.2358 - val_accuracy: 0.7290\n",
      "Epoch 164/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2139 - accuracy: 0.7249 - val_loss: 1.2287 - val_accuracy: 0.7340\n",
      "Epoch 165/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2103 - accuracy: 0.7269 - val_loss: 1.2252 - val_accuracy: 0.7330\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2072 - accuracy: 0.7285 - val_loss: 1.2209 - val_accuracy: 0.7310\n",
      "Epoch 167/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2042 - accuracy: 0.7275 - val_loss: 1.2183 - val_accuracy: 0.7350\n",
      "Epoch 168/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.2011 - accuracy: 0.7268 - val_loss: 1.2152 - val_accuracy: 0.7280\n",
      "Epoch 169/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1970 - accuracy: 0.7300 - val_loss: 1.2139 - val_accuracy: 0.7320\n",
      "Epoch 170/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1943 - accuracy: 0.7294 - val_loss: 1.2099 - val_accuracy: 0.7360\n",
      "Epoch 171/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1917 - accuracy: 0.7285 - val_loss: 1.2044 - val_accuracy: 0.7390\n",
      "Epoch 172/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1884 - accuracy: 0.7282 - val_loss: 1.2048 - val_accuracy: 0.7330\n",
      "Epoch 173/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1855 - accuracy: 0.7283 - val_loss: 1.2042 - val_accuracy: 0.7280\n",
      "Epoch 174/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1829 - accuracy: 0.7291 - val_loss: 1.1961 - val_accuracy: 0.7400\n",
      "Epoch 175/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1800 - accuracy: 0.7278 - val_loss: 1.1926 - val_accuracy: 0.7370\n",
      "Epoch 176/1000\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 1.1763 - accuracy: 0.7300 - val_loss: 1.1924 - val_accuracy: 0.7330\n",
      "Epoch 177/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1739 - accuracy: 0.7280 - val_loss: 1.1921 - val_accuracy: 0.7340\n",
      "Epoch 178/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1708 - accuracy: 0.7291 - val_loss: 1.1857 - val_accuracy: 0.7370\n",
      "Epoch 179/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1684 - accuracy: 0.7314 - val_loss: 1.1811 - val_accuracy: 0.7380\n",
      "Epoch 180/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1653 - accuracy: 0.7305 - val_loss: 1.1771 - val_accuracy: 0.7420\n",
      "Epoch 181/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1626 - accuracy: 0.7315 - val_loss: 1.1792 - val_accuracy: 0.7360\n",
      "Epoch 182/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1601 - accuracy: 0.7305 - val_loss: 1.1734 - val_accuracy: 0.7380\n",
      "Epoch 183/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1572 - accuracy: 0.7309 - val_loss: 1.1696 - val_accuracy: 0.7390\n",
      "Epoch 184/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1542 - accuracy: 0.7306 - val_loss: 1.1696 - val_accuracy: 0.7390\n",
      "Epoch 185/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1521 - accuracy: 0.7308 - val_loss: 1.1664 - val_accuracy: 0.7390\n",
      "Epoch 186/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1494 - accuracy: 0.7309 - val_loss: 1.1635 - val_accuracy: 0.7390\n",
      "Epoch 187/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1471 - accuracy: 0.7331 - val_loss: 1.1608 - val_accuracy: 0.7380\n",
      "Epoch 188/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1448 - accuracy: 0.7331 - val_loss: 1.1568 - val_accuracy: 0.7380\n",
      "Epoch 189/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1422 - accuracy: 0.7335 - val_loss: 1.1545 - val_accuracy: 0.7390\n",
      "Epoch 190/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1395 - accuracy: 0.7315 - val_loss: 1.1544 - val_accuracy: 0.7350\n",
      "Epoch 191/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1369 - accuracy: 0.7338 - val_loss: 1.1528 - val_accuracy: 0.7410\n",
      "Epoch 192/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1346 - accuracy: 0.7325 - val_loss: 1.1510 - val_accuracy: 0.7390\n",
      "Epoch 193/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1323 - accuracy: 0.7337 - val_loss: 1.1459 - val_accuracy: 0.7410\n",
      "Epoch 194/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1302 - accuracy: 0.7348 - val_loss: 1.1443 - val_accuracy: 0.7400\n",
      "Epoch 195/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1276 - accuracy: 0.7338 - val_loss: 1.1422 - val_accuracy: 0.7410\n",
      "Epoch 196/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1255 - accuracy: 0.7343 - val_loss: 1.1414 - val_accuracy: 0.7360\n",
      "Epoch 197/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1234 - accuracy: 0.7352 - val_loss: 1.1405 - val_accuracy: 0.7430\n",
      "Epoch 198/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1215 - accuracy: 0.7358 - val_loss: 1.1343 - val_accuracy: 0.7410\n",
      "Epoch 199/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1194 - accuracy: 0.7348 - val_loss: 1.1336 - val_accuracy: 0.7400\n",
      "Epoch 200/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1174 - accuracy: 0.7355 - val_loss: 1.1298 - val_accuracy: 0.7380\n",
      "Epoch 201/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1150 - accuracy: 0.7372 - val_loss: 1.1295 - val_accuracy: 0.7380\n",
      "Epoch 202/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1132 - accuracy: 0.7346 - val_loss: 1.1312 - val_accuracy: 0.7420\n",
      "Epoch 203/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1112 - accuracy: 0.7358 - val_loss: 1.1228 - val_accuracy: 0.7450\n",
      "Epoch 204/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1095 - accuracy: 0.7366 - val_loss: 1.1206 - val_accuracy: 0.7440\n",
      "Epoch 205/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1070 - accuracy: 0.7360 - val_loss: 1.1194 - val_accuracy: 0.7420\n",
      "Epoch 206/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1057 - accuracy: 0.7378 - val_loss: 1.1206 - val_accuracy: 0.7410\n",
      "Epoch 207/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1035 - accuracy: 0.7369 - val_loss: 1.1164 - val_accuracy: 0.7420\n",
      "Epoch 208/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1018 - accuracy: 0.7355 - val_loss: 1.1164 - val_accuracy: 0.7470\n",
      "Epoch 209/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.1002 - accuracy: 0.7365 - val_loss: 1.1138 - val_accuracy: 0.7410\n",
      "Epoch 210/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0981 - accuracy: 0.7391 - val_loss: 1.1126 - val_accuracy: 0.7470\n",
      "Epoch 211/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0975 - accuracy: 0.7360 - val_loss: 1.1102 - val_accuracy: 0.7430\n",
      "Epoch 212/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0947 - accuracy: 0.7417 - val_loss: 1.1095 - val_accuracy: 0.7430\n",
      "Epoch 213/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0933 - accuracy: 0.7386 - val_loss: 1.1074 - val_accuracy: 0.7480\n",
      "Epoch 214/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0922 - accuracy: 0.7388 - val_loss: 1.1031 - val_accuracy: 0.7440\n",
      "Epoch 215/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0901 - accuracy: 0.7385 - val_loss: 1.1034 - val_accuracy: 0.7460\n",
      "Epoch 216/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0885 - accuracy: 0.7388 - val_loss: 1.1035 - val_accuracy: 0.7460\n",
      "Epoch 217/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0874 - accuracy: 0.7383 - val_loss: 1.0997 - val_accuracy: 0.7460\n",
      "Epoch 218/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0858 - accuracy: 0.7385 - val_loss: 1.1023 - val_accuracy: 0.7440\n",
      "Epoch 219/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0846 - accuracy: 0.7431 - val_loss: 1.1003 - val_accuracy: 0.7430\n",
      "Epoch 220/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0831 - accuracy: 0.7378 - val_loss: 1.0945 - val_accuracy: 0.7460\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0814 - accuracy: 0.7402 - val_loss: 1.0952 - val_accuracy: 0.7440\n",
      "Epoch 222/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0800 - accuracy: 0.7395 - val_loss: 1.0959 - val_accuracy: 0.7480\n",
      "Epoch 223/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0792 - accuracy: 0.7409 - val_loss: 1.0907 - val_accuracy: 0.7480\n",
      "Epoch 224/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0775 - accuracy: 0.7412 - val_loss: 1.0908 - val_accuracy: 0.7490\n",
      "Epoch 225/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0766 - accuracy: 0.7414 - val_loss: 1.0882 - val_accuracy: 0.7450\n",
      "Epoch 226/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0756 - accuracy: 0.7397 - val_loss: 1.0868 - val_accuracy: 0.7490\n",
      "Epoch 227/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0733 - accuracy: 0.7437 - val_loss: 1.0896 - val_accuracy: 0.7450\n",
      "Epoch 228/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0721 - accuracy: 0.7405 - val_loss: 1.0866 - val_accuracy: 0.7490\n",
      "Epoch 229/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0717 - accuracy: 0.7402 - val_loss: 1.0848 - val_accuracy: 0.7510\n",
      "Epoch 230/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0708 - accuracy: 0.7406 - val_loss: 1.0922 - val_accuracy: 0.7440\n",
      "Epoch 231/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0694 - accuracy: 0.7383 - val_loss: 1.0818 - val_accuracy: 0.7480\n",
      "Epoch 232/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0674 - accuracy: 0.7415 - val_loss: 1.0851 - val_accuracy: 0.7480\n",
      "Epoch 233/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0669 - accuracy: 0.7429 - val_loss: 1.0792 - val_accuracy: 0.7520\n",
      "Epoch 234/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0653 - accuracy: 0.7422 - val_loss: 1.0820 - val_accuracy: 0.7450\n",
      "Epoch 235/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0647 - accuracy: 0.7420 - val_loss: 1.0820 - val_accuracy: 0.7490\n",
      "Epoch 236/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0629 - accuracy: 0.7431 - val_loss: 1.0759 - val_accuracy: 0.7470\n",
      "Epoch 237/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0620 - accuracy: 0.7443 - val_loss: 1.0760 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0604 - accuracy: 0.7415 - val_loss: 1.0768 - val_accuracy: 0.7510\n",
      "Epoch 239/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0598 - accuracy: 0.7431 - val_loss: 1.0766 - val_accuracy: 0.7450\n",
      "Epoch 240/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0586 - accuracy: 0.7428 - val_loss: 1.0740 - val_accuracy: 0.7540\n",
      "Epoch 241/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0579 - accuracy: 0.7415 - val_loss: 1.0697 - val_accuracy: 0.7460\n",
      "Epoch 242/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0562 - accuracy: 0.7455 - val_loss: 1.0737 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0550 - accuracy: 0.7446 - val_loss: 1.0686 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0544 - accuracy: 0.7446 - val_loss: 1.0674 - val_accuracy: 0.7480\n",
      "Epoch 245/1000\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 1.0532 - accuracy: 0.7448 - val_loss: 1.0667 - val_accuracy: 0.7450\n",
      "Epoch 246/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0528 - accuracy: 0.7435 - val_loss: 1.0653 - val_accuracy: 0.7440\n",
      "Epoch 247/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0510 - accuracy: 0.7438 - val_loss: 1.0658 - val_accuracy: 0.7460\n",
      "Epoch 248/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0501 - accuracy: 0.7445 - val_loss: 1.0644 - val_accuracy: 0.7480\n",
      "Epoch 249/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0489 - accuracy: 0.7468 - val_loss: 1.0623 - val_accuracy: 0.7460\n",
      "Epoch 250/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0472 - accuracy: 0.7448 - val_loss: 1.0632 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0471 - accuracy: 0.7449 - val_loss: 1.0621 - val_accuracy: 0.7480\n",
      "Epoch 252/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0458 - accuracy: 0.7445 - val_loss: 1.0626 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0444 - accuracy: 0.7448 - val_loss: 1.0608 - val_accuracy: 0.7490\n",
      "Epoch 254/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0435 - accuracy: 0.7463 - val_loss: 1.0571 - val_accuracy: 0.7460\n",
      "Epoch 255/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0428 - accuracy: 0.7451 - val_loss: 1.0587 - val_accuracy: 0.7440\n",
      "Epoch 256/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0416 - accuracy: 0.7443 - val_loss: 1.0541 - val_accuracy: 0.7490\n",
      "Epoch 257/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0409 - accuracy: 0.7485 - val_loss: 1.0574 - val_accuracy: 0.7470\n",
      "Epoch 258/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0394 - accuracy: 0.7498 - val_loss: 1.0536 - val_accuracy: 0.7470\n",
      "Epoch 259/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0379 - accuracy: 0.7462 - val_loss: 1.0584 - val_accuracy: 0.7540\n",
      "Epoch 260/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0374 - accuracy: 0.7482 - val_loss: 1.0523 - val_accuracy: 0.7530\n",
      "Epoch 261/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0368 - accuracy: 0.7485 - val_loss: 1.0505 - val_accuracy: 0.7480\n",
      "Epoch 262/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0358 - accuracy: 0.7454 - val_loss: 1.0494 - val_accuracy: 0.7510\n",
      "Epoch 263/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0346 - accuracy: 0.7486 - val_loss: 1.0502 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0340 - accuracy: 0.7452 - val_loss: 1.0492 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0327 - accuracy: 0.7485 - val_loss: 1.0493 - val_accuracy: 0.7490\n",
      "Epoch 266/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0317 - accuracy: 0.7457 - val_loss: 1.0489 - val_accuracy: 0.7520\n",
      "Epoch 267/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0312 - accuracy: 0.7485 - val_loss: 1.0477 - val_accuracy: 0.7450\n",
      "Epoch 268/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0299 - accuracy: 0.7474 - val_loss: 1.0506 - val_accuracy: 0.7450\n",
      "Epoch 269/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0290 - accuracy: 0.7472 - val_loss: 1.0443 - val_accuracy: 0.7530\n",
      "Epoch 270/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0281 - accuracy: 0.7488 - val_loss: 1.0588 - val_accuracy: 0.7420\n",
      "Epoch 271/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0277 - accuracy: 0.7480 - val_loss: 1.0452 - val_accuracy: 0.7480\n",
      "Epoch 272/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0258 - accuracy: 0.7492 - val_loss: 1.0420 - val_accuracy: 0.7490\n",
      "Epoch 273/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0252 - accuracy: 0.7492 - val_loss: 1.0406 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0246 - accuracy: 0.7517 - val_loss: 1.0419 - val_accuracy: 0.7580\n",
      "Epoch 275/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0239 - accuracy: 0.7485 - val_loss: 1.0396 - val_accuracy: 0.7510\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0225 - accuracy: 0.7503 - val_loss: 1.0372 - val_accuracy: 0.7510\n",
      "Epoch 277/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0214 - accuracy: 0.7475 - val_loss: 1.0389 - val_accuracy: 0.7560\n",
      "Epoch 278/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0209 - accuracy: 0.7509 - val_loss: 1.0391 - val_accuracy: 0.7490\n",
      "Epoch 279/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0197 - accuracy: 0.7489 - val_loss: 1.0364 - val_accuracy: 0.7510\n",
      "Epoch 280/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0191 - accuracy: 0.7495 - val_loss: 1.0323 - val_accuracy: 0.7550\n",
      "Epoch 281/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0178 - accuracy: 0.7535 - val_loss: 1.0345 - val_accuracy: 0.7550\n",
      "Epoch 282/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0174 - accuracy: 0.7526 - val_loss: 1.0313 - val_accuracy: 0.7520\n",
      "Epoch 283/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0166 - accuracy: 0.7512 - val_loss: 1.0348 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0159 - accuracy: 0.7537 - val_loss: 1.0422 - val_accuracy: 0.7480\n",
      "Epoch 285/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0166 - accuracy: 0.7486 - val_loss: 1.0298 - val_accuracy: 0.7580\n",
      "Epoch 286/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0147 - accuracy: 0.7514 - val_loss: 1.0292 - val_accuracy: 0.7510\n",
      "Epoch 287/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0132 - accuracy: 0.7542 - val_loss: 1.0294 - val_accuracy: 0.7540\n",
      "Epoch 288/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0120 - accuracy: 0.7522 - val_loss: 1.0274 - val_accuracy: 0.7540\n",
      "Epoch 289/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0116 - accuracy: 0.7512 - val_loss: 1.0272 - val_accuracy: 0.7540\n",
      "Epoch 290/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0109 - accuracy: 0.7525 - val_loss: 1.0268 - val_accuracy: 0.7540\n",
      "Epoch 291/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0102 - accuracy: 0.7532 - val_loss: 1.0279 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0090 - accuracy: 0.7522 - val_loss: 1.0286 - val_accuracy: 0.7460\n",
      "Epoch 293/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0083 - accuracy: 0.7529 - val_loss: 1.0334 - val_accuracy: 0.7460\n",
      "Epoch 294/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0082 - accuracy: 0.7512 - val_loss: 1.0280 - val_accuracy: 0.7530\n",
      "Epoch 295/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0074 - accuracy: 0.7552 - val_loss: 1.0302 - val_accuracy: 0.7520\n",
      "Epoch 296/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0068 - accuracy: 0.7545 - val_loss: 1.0257 - val_accuracy: 0.7480\n",
      "Epoch 297/1000\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 1.0057 - accuracy: 0.7548 - val_loss: 1.0249 - val_accuracy: 0.7520\n",
      "Epoch 298/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0044 - accuracy: 0.7529 - val_loss: 1.0276 - val_accuracy: 0.7510\n",
      "Epoch 299/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0045 - accuracy: 0.7532 - val_loss: 1.0234 - val_accuracy: 0.7580\n",
      "Epoch 300/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0037 - accuracy: 0.7546 - val_loss: 1.0193 - val_accuracy: 0.7510\n",
      "Epoch 301/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0019 - accuracy: 0.7531 - val_loss: 1.0208 - val_accuracy: 0.7560\n",
      "Epoch 302/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0019 - accuracy: 0.7534 - val_loss: 1.0222 - val_accuracy: 0.7490\n",
      "Epoch 303/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0008 - accuracy: 0.7537 - val_loss: 1.0262 - val_accuracy: 0.7530\n",
      "Epoch 304/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0004 - accuracy: 0.7542 - val_loss: 1.0239 - val_accuracy: 0.7520\n",
      "Epoch 305/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 1.0000 - accuracy: 0.7535 - val_loss: 1.0205 - val_accuracy: 0.7530\n",
      "Epoch 306/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9987 - accuracy: 0.7557 - val_loss: 1.0160 - val_accuracy: 0.7550\n",
      "Epoch 307/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9984 - accuracy: 0.7555 - val_loss: 1.0238 - val_accuracy: 0.7480\n",
      "Epoch 308/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9974 - accuracy: 0.7538 - val_loss: 1.0142 - val_accuracy: 0.7560\n",
      "Epoch 309/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9967 - accuracy: 0.7574 - val_loss: 1.0157 - val_accuracy: 0.7550\n",
      "Epoch 310/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9957 - accuracy: 0.7562 - val_loss: 1.0203 - val_accuracy: 0.7520\n",
      "Epoch 311/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9952 - accuracy: 0.7551 - val_loss: 1.0123 - val_accuracy: 0.7560\n",
      "Epoch 312/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9943 - accuracy: 0.7557 - val_loss: 1.0161 - val_accuracy: 0.7540\n",
      "Epoch 313/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9944 - accuracy: 0.7563 - val_loss: 1.0158 - val_accuracy: 0.7570\n",
      "Epoch 314/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9933 - accuracy: 0.7588 - val_loss: 1.0223 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9939 - accuracy: 0.7531 - val_loss: 1.0107 - val_accuracy: 0.7560\n",
      "Epoch 316/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9920 - accuracy: 0.7580 - val_loss: 1.0102 - val_accuracy: 0.7560\n",
      "Epoch 317/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9910 - accuracy: 0.7571 - val_loss: 1.0124 - val_accuracy: 0.7560\n",
      "Epoch 318/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9909 - accuracy: 0.7557 - val_loss: 1.0104 - val_accuracy: 0.7520\n",
      "Epoch 319/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9904 - accuracy: 0.7566 - val_loss: 1.0078 - val_accuracy: 0.7530\n",
      "Epoch 320/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9893 - accuracy: 0.7566 - val_loss: 1.0068 - val_accuracy: 0.7590\n",
      "Epoch 321/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9888 - accuracy: 0.7585 - val_loss: 1.0107 - val_accuracy: 0.7540\n",
      "Epoch 322/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9877 - accuracy: 0.7560 - val_loss: 1.0068 - val_accuracy: 0.7550\n",
      "Epoch 323/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9874 - accuracy: 0.7598 - val_loss: 1.0071 - val_accuracy: 0.7590\n",
      "Epoch 324/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9871 - accuracy: 0.7568 - val_loss: 1.0057 - val_accuracy: 0.7580\n",
      "Epoch 325/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9861 - accuracy: 0.7580 - val_loss: 1.0055 - val_accuracy: 0.7580\n",
      "Epoch 326/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9855 - accuracy: 0.7589 - val_loss: 1.0032 - val_accuracy: 0.7580\n",
      "Epoch 327/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9849 - accuracy: 0.7569 - val_loss: 1.0053 - val_accuracy: 0.7540\n",
      "Epoch 328/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9850 - accuracy: 0.7583 - val_loss: 1.0027 - val_accuracy: 0.7580\n",
      "Epoch 329/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9839 - accuracy: 0.7585 - val_loss: 1.0046 - val_accuracy: 0.7600\n",
      "Epoch 330/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9836 - accuracy: 0.7577 - val_loss: 1.0036 - val_accuracy: 0.7600\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9827 - accuracy: 0.7591 - val_loss: 1.0067 - val_accuracy: 0.7580\n",
      "Epoch 332/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9817 - accuracy: 0.7574 - val_loss: 1.0049 - val_accuracy: 0.7580\n",
      "Epoch 333/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9814 - accuracy: 0.7602 - val_loss: 1.0022 - val_accuracy: 0.7570\n",
      "Epoch 334/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9806 - accuracy: 0.7575 - val_loss: 1.0015 - val_accuracy: 0.7600\n",
      "Epoch 335/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9795 - accuracy: 0.7586 - val_loss: 1.0010 - val_accuracy: 0.7580\n",
      "Epoch 336/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9799 - accuracy: 0.7585 - val_loss: 1.0006 - val_accuracy: 0.7590\n",
      "Epoch 337/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9791 - accuracy: 0.7612 - val_loss: 1.0010 - val_accuracy: 0.7590\n",
      "Epoch 338/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9786 - accuracy: 0.7586 - val_loss: 1.0073 - val_accuracy: 0.7600\n",
      "Epoch 339/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9784 - accuracy: 0.7591 - val_loss: 1.0013 - val_accuracy: 0.7580\n",
      "Epoch 340/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9778 - accuracy: 0.7569 - val_loss: 1.0008 - val_accuracy: 0.7600\n",
      "Epoch 341/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9768 - accuracy: 0.7609 - val_loss: 0.9959 - val_accuracy: 0.7590\n",
      "Epoch 342/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9753 - accuracy: 0.7594 - val_loss: 0.9977 - val_accuracy: 0.7590\n",
      "Epoch 343/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9760 - accuracy: 0.7591 - val_loss: 0.9975 - val_accuracy: 0.7610\n",
      "Epoch 344/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9741 - accuracy: 0.7640 - val_loss: 1.0031 - val_accuracy: 0.7530\n",
      "Epoch 345/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9741 - accuracy: 0.7591 - val_loss: 0.9954 - val_accuracy: 0.7590\n",
      "Epoch 346/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9740 - accuracy: 0.7598 - val_loss: 0.9962 - val_accuracy: 0.7600\n",
      "Epoch 347/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9735 - accuracy: 0.7618 - val_loss: 0.9978 - val_accuracy: 0.7580\n",
      "Epoch 348/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9732 - accuracy: 0.7594 - val_loss: 1.0033 - val_accuracy: 0.7550\n",
      "Epoch 349/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9727 - accuracy: 0.7611 - val_loss: 0.9948 - val_accuracy: 0.7610\n",
      "Epoch 350/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9707 - accuracy: 0.7609 - val_loss: 1.0078 - val_accuracy: 0.7560\n",
      "Epoch 351/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9713 - accuracy: 0.7617 - val_loss: 0.9973 - val_accuracy: 0.7600\n",
      "Epoch 352/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9705 - accuracy: 0.7614 - val_loss: 0.9927 - val_accuracy: 0.7580\n",
      "Epoch 353/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9702 - accuracy: 0.7629 - val_loss: 0.9962 - val_accuracy: 0.7590\n",
      "Epoch 354/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9697 - accuracy: 0.7602 - val_loss: 0.9956 - val_accuracy: 0.7570\n",
      "Epoch 355/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9697 - accuracy: 0.7617 - val_loss: 0.9903 - val_accuracy: 0.7630\n",
      "Epoch 356/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9684 - accuracy: 0.7614 - val_loss: 0.9926 - val_accuracy: 0.7610\n",
      "Epoch 357/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9683 - accuracy: 0.7628 - val_loss: 0.9951 - val_accuracy: 0.7570\n",
      "Epoch 358/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9678 - accuracy: 0.7631 - val_loss: 0.9926 - val_accuracy: 0.7620\n",
      "Epoch 359/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9667 - accuracy: 0.7654 - val_loss: 0.9942 - val_accuracy: 0.7600\n",
      "Epoch 360/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9662 - accuracy: 0.7605 - val_loss: 0.9883 - val_accuracy: 0.7590\n",
      "Epoch 361/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9658 - accuracy: 0.7648 - val_loss: 0.9909 - val_accuracy: 0.7610\n",
      "Epoch 362/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9651 - accuracy: 0.7632 - val_loss: 0.9877 - val_accuracy: 0.7610\n",
      "Epoch 363/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9646 - accuracy: 0.7625 - val_loss: 0.9877 - val_accuracy: 0.7630\n",
      "Epoch 364/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9641 - accuracy: 0.7646 - val_loss: 0.9922 - val_accuracy: 0.7570\n",
      "Epoch 365/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9635 - accuracy: 0.7648 - val_loss: 0.9888 - val_accuracy: 0.7590\n",
      "Epoch 366/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9635 - accuracy: 0.7648 - val_loss: 0.9924 - val_accuracy: 0.7580\n",
      "Epoch 367/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9624 - accuracy: 0.7666 - val_loss: 0.9952 - val_accuracy: 0.7590\n",
      "Epoch 368/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9625 - accuracy: 0.7622 - val_loss: 0.9907 - val_accuracy: 0.7590\n",
      "Epoch 369/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9608 - accuracy: 0.7654 - val_loss: 0.9847 - val_accuracy: 0.7640\n",
      "Epoch 370/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9610 - accuracy: 0.7655 - val_loss: 0.9871 - val_accuracy: 0.7650\n",
      "Epoch 371/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9613 - accuracy: 0.7642 - val_loss: 0.9879 - val_accuracy: 0.7630\n",
      "Epoch 372/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9606 - accuracy: 0.7623 - val_loss: 0.9839 - val_accuracy: 0.7610\n",
      "Epoch 373/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9601 - accuracy: 0.7672 - val_loss: 0.9885 - val_accuracy: 0.7600\n",
      "Epoch 374/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9593 - accuracy: 0.7643 - val_loss: 0.9841 - val_accuracy: 0.7640\n",
      "Epoch 375/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9579 - accuracy: 0.7660 - val_loss: 0.9853 - val_accuracy: 0.7630\n",
      "Epoch 376/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9586 - accuracy: 0.7672 - val_loss: 0.9848 - val_accuracy: 0.7630\n",
      "Epoch 377/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9574 - accuracy: 0.7660 - val_loss: 0.9848 - val_accuracy: 0.7620\n",
      "Epoch 378/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9568 - accuracy: 0.7657 - val_loss: 0.9878 - val_accuracy: 0.7610\n",
      "Epoch 379/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9566 - accuracy: 0.7648 - val_loss: 0.9836 - val_accuracy: 0.7650\n",
      "Epoch 380/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9564 - accuracy: 0.7669 - val_loss: 0.9799 - val_accuracy: 0.7580\n",
      "Epoch 381/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9560 - accuracy: 0.7666 - val_loss: 0.9803 - val_accuracy: 0.7640\n",
      "Epoch 382/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9553 - accuracy: 0.7662 - val_loss: 0.9826 - val_accuracy: 0.7640\n",
      "Epoch 383/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9547 - accuracy: 0.7678 - val_loss: 0.9932 - val_accuracy: 0.7630\n",
      "Epoch 384/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9552 - accuracy: 0.7668 - val_loss: 0.9826 - val_accuracy: 0.7640\n",
      "Epoch 385/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9542 - accuracy: 0.7662 - val_loss: 0.9811 - val_accuracy: 0.7620\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9537 - accuracy: 0.7643 - val_loss: 0.9869 - val_accuracy: 0.7620\n",
      "Epoch 387/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9522 - accuracy: 0.7666 - val_loss: 0.9801 - val_accuracy: 0.7640\n",
      "Epoch 388/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9528 - accuracy: 0.7674 - val_loss: 0.9849 - val_accuracy: 0.7610\n",
      "Epoch 389/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9520 - accuracy: 0.7662 - val_loss: 0.9784 - val_accuracy: 0.7600\n",
      "Epoch 390/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9516 - accuracy: 0.7666 - val_loss: 0.9822 - val_accuracy: 0.7600\n",
      "Epoch 391/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9519 - accuracy: 0.7678 - val_loss: 0.9765 - val_accuracy: 0.7620\n",
      "Epoch 392/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9502 - accuracy: 0.7672 - val_loss: 0.9771 - val_accuracy: 0.7640\n",
      "Epoch 393/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9496 - accuracy: 0.7689 - val_loss: 0.9760 - val_accuracy: 0.7610\n",
      "Epoch 394/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9499 - accuracy: 0.7708 - val_loss: 0.9770 - val_accuracy: 0.7650\n",
      "Epoch 395/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9495 - accuracy: 0.7695 - val_loss: 0.9843 - val_accuracy: 0.7610\n",
      "Epoch 396/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9491 - accuracy: 0.7698 - val_loss: 0.9760 - val_accuracy: 0.7640\n",
      "Epoch 397/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9484 - accuracy: 0.7688 - val_loss: 0.9754 - val_accuracy: 0.7640\n",
      "Epoch 398/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9486 - accuracy: 0.7694 - val_loss: 0.9754 - val_accuracy: 0.7630\n",
      "Epoch 399/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9480 - accuracy: 0.7680 - val_loss: 0.9770 - val_accuracy: 0.7680\n",
      "Epoch 400/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9477 - accuracy: 0.7685 - val_loss: 0.9758 - val_accuracy: 0.7640\n",
      "Epoch 401/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9464 - accuracy: 0.7683 - val_loss: 0.9784 - val_accuracy: 0.7650\n",
      "Epoch 402/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9459 - accuracy: 0.7691 - val_loss: 0.9752 - val_accuracy: 0.7650\n",
      "Epoch 403/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9453 - accuracy: 0.7702 - val_loss: 0.9818 - val_accuracy: 0.7610\n",
      "Epoch 404/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9450 - accuracy: 0.7692 - val_loss: 0.9741 - val_accuracy: 0.7640\n",
      "Epoch 405/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9456 - accuracy: 0.7671 - val_loss: 0.9747 - val_accuracy: 0.7620\n",
      "Epoch 406/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9453 - accuracy: 0.7677 - val_loss: 0.9724 - val_accuracy: 0.7630\n",
      "Epoch 407/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9438 - accuracy: 0.7722 - val_loss: 0.9795 - val_accuracy: 0.7650\n",
      "Epoch 408/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9446 - accuracy: 0.7703 - val_loss: 0.9716 - val_accuracy: 0.7640\n",
      "Epoch 409/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9433 - accuracy: 0.7691 - val_loss: 0.9735 - val_accuracy: 0.7630\n",
      "Epoch 410/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9430 - accuracy: 0.7694 - val_loss: 0.9702 - val_accuracy: 0.7610\n",
      "Epoch 411/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9428 - accuracy: 0.7714 - val_loss: 0.9711 - val_accuracy: 0.7620\n",
      "Epoch 412/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9434 - accuracy: 0.7695 - val_loss: 0.9789 - val_accuracy: 0.7640\n",
      "Epoch 413/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9417 - accuracy: 0.7698 - val_loss: 0.9717 - val_accuracy: 0.7660\n",
      "Epoch 414/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9417 - accuracy: 0.7715 - val_loss: 0.9731 - val_accuracy: 0.7600\n",
      "Epoch 415/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9409 - accuracy: 0.7717 - val_loss: 0.9796 - val_accuracy: 0.7570\n",
      "Epoch 416/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9410 - accuracy: 0.7706 - val_loss: 0.9724 - val_accuracy: 0.7660\n",
      "Epoch 417/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9405 - accuracy: 0.7700 - val_loss: 0.9756 - val_accuracy: 0.7650\n",
      "Epoch 418/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9392 - accuracy: 0.7709 - val_loss: 0.9796 - val_accuracy: 0.7580\n",
      "Epoch 419/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9392 - accuracy: 0.7706 - val_loss: 0.9714 - val_accuracy: 0.7670\n",
      "Epoch 420/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9393 - accuracy: 0.7718 - val_loss: 0.9721 - val_accuracy: 0.7660\n",
      "Epoch 421/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9384 - accuracy: 0.7703 - val_loss: 0.9713 - val_accuracy: 0.7660\n",
      "Epoch 422/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9385 - accuracy: 0.7705 - val_loss: 0.9679 - val_accuracy: 0.7620\n",
      "Epoch 423/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9391 - accuracy: 0.7715 - val_loss: 0.9684 - val_accuracy: 0.7680\n",
      "Epoch 424/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9373 - accuracy: 0.7723 - val_loss: 0.9652 - val_accuracy: 0.7600\n",
      "Epoch 425/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9363 - accuracy: 0.7746 - val_loss: 0.9652 - val_accuracy: 0.7620\n",
      "Epoch 426/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9353 - accuracy: 0.7709 - val_loss: 0.9737 - val_accuracy: 0.7600\n",
      "Epoch 427/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9364 - accuracy: 0.7734 - val_loss: 0.9690 - val_accuracy: 0.7630\n",
      "Epoch 428/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9359 - accuracy: 0.7686 - val_loss: 0.9723 - val_accuracy: 0.7630\n",
      "Epoch 429/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9359 - accuracy: 0.7714 - val_loss: 0.9683 - val_accuracy: 0.7680\n",
      "Epoch 430/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9351 - accuracy: 0.7723 - val_loss: 0.9651 - val_accuracy: 0.7610\n",
      "Epoch 431/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9348 - accuracy: 0.7720 - val_loss: 0.9731 - val_accuracy: 0.7650\n",
      "Epoch 432/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9345 - accuracy: 0.7708 - val_loss: 0.9662 - val_accuracy: 0.7710\n",
      "Epoch 433/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9337 - accuracy: 0.7738 - val_loss: 0.9775 - val_accuracy: 0.7630\n",
      "Epoch 434/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9345 - accuracy: 0.7705 - val_loss: 0.9668 - val_accuracy: 0.7720\n",
      "Epoch 435/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9337 - accuracy: 0.7746 - val_loss: 0.9646 - val_accuracy: 0.7670\n",
      "Epoch 436/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9322 - accuracy: 0.7748 - val_loss: 0.9643 - val_accuracy: 0.7670\n",
      "Epoch 437/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9325 - accuracy: 0.7731 - val_loss: 0.9673 - val_accuracy: 0.7640\n",
      "Epoch 438/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9322 - accuracy: 0.7745 - val_loss: 0.9638 - val_accuracy: 0.7690\n",
      "Epoch 439/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9313 - accuracy: 0.7729 - val_loss: 0.9674 - val_accuracy: 0.7660\n",
      "Epoch 440/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9304 - accuracy: 0.7731 - val_loss: 0.9667 - val_accuracy: 0.7580\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9313 - accuracy: 0.7712 - val_loss: 0.9699 - val_accuracy: 0.7640\n",
      "Epoch 442/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9321 - accuracy: 0.7746 - val_loss: 0.9635 - val_accuracy: 0.7680\n",
      "Epoch 443/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9294 - accuracy: 0.7752 - val_loss: 0.9639 - val_accuracy: 0.7670\n",
      "Epoch 444/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9296 - accuracy: 0.7745 - val_loss: 0.9655 - val_accuracy: 0.7630\n",
      "Epoch 445/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9289 - accuracy: 0.7748 - val_loss: 0.9635 - val_accuracy: 0.7650\n",
      "Epoch 446/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9298 - accuracy: 0.7742 - val_loss: 0.9640 - val_accuracy: 0.7630\n",
      "Epoch 447/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9285 - accuracy: 0.7765 - val_loss: 0.9609 - val_accuracy: 0.7640\n",
      "Epoch 448/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9290 - accuracy: 0.7755 - val_loss: 0.9679 - val_accuracy: 0.7600\n",
      "Epoch 449/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9284 - accuracy: 0.7742 - val_loss: 0.9666 - val_accuracy: 0.7670\n",
      "Epoch 450/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9282 - accuracy: 0.7729 - val_loss: 0.9614 - val_accuracy: 0.7650\n",
      "Epoch 451/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9271 - accuracy: 0.7740 - val_loss: 0.9653 - val_accuracy: 0.7640\n",
      "Epoch 452/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9278 - accuracy: 0.7743 - val_loss: 0.9670 - val_accuracy: 0.7590\n",
      "Epoch 453/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9266 - accuracy: 0.7749 - val_loss: 0.9744 - val_accuracy: 0.7610\n",
      "Epoch 454/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9266 - accuracy: 0.7742 - val_loss: 0.9629 - val_accuracy: 0.7630\n",
      "Epoch 455/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9262 - accuracy: 0.7763 - val_loss: 0.9607 - val_accuracy: 0.7650\n",
      "Epoch 456/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9253 - accuracy: 0.7772 - val_loss: 0.9620 - val_accuracy: 0.7660\n",
      "Epoch 457/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9252 - accuracy: 0.7757 - val_loss: 0.9624 - val_accuracy: 0.7630\n",
      "Epoch 458/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9252 - accuracy: 0.7751 - val_loss: 0.9588 - val_accuracy: 0.7660\n",
      "Epoch 459/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9248 - accuracy: 0.7751 - val_loss: 0.9622 - val_accuracy: 0.7700\n",
      "Epoch 460/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9249 - accuracy: 0.7763 - val_loss: 0.9667 - val_accuracy: 0.7650\n",
      "Epoch 461/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9243 - accuracy: 0.7771 - val_loss: 0.9603 - val_accuracy: 0.7700\n",
      "Epoch 462/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9226 - accuracy: 0.7800 - val_loss: 0.9683 - val_accuracy: 0.7600\n",
      "Epoch 463/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9243 - accuracy: 0.7789 - val_loss: 0.9590 - val_accuracy: 0.7660\n",
      "Epoch 464/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9230 - accuracy: 0.7754 - val_loss: 0.9608 - val_accuracy: 0.7620\n",
      "Epoch 465/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9223 - accuracy: 0.7785 - val_loss: 0.9587 - val_accuracy: 0.7630\n",
      "Epoch 466/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9219 - accuracy: 0.7768 - val_loss: 0.9610 - val_accuracy: 0.7630\n",
      "Epoch 467/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9217 - accuracy: 0.7757 - val_loss: 0.9645 - val_accuracy: 0.7620\n",
      "Epoch 468/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9213 - accuracy: 0.7775 - val_loss: 0.9570 - val_accuracy: 0.7620\n",
      "Epoch 469/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9204 - accuracy: 0.7789 - val_loss: 0.9571 - val_accuracy: 0.7650\n",
      "Epoch 470/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9206 - accuracy: 0.7769 - val_loss: 0.9618 - val_accuracy: 0.7660\n",
      "Epoch 471/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9201 - accuracy: 0.7786 - val_loss: 0.9656 - val_accuracy: 0.7660\n",
      "Epoch 472/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9202 - accuracy: 0.7746 - val_loss: 0.9578 - val_accuracy: 0.7670\n",
      "Epoch 473/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9210 - accuracy: 0.7765 - val_loss: 0.9585 - val_accuracy: 0.7670\n",
      "Epoch 474/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9188 - accuracy: 0.7800 - val_loss: 0.9639 - val_accuracy: 0.7640\n",
      "Epoch 475/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9192 - accuracy: 0.7780 - val_loss: 0.9656 - val_accuracy: 0.7660\n",
      "Epoch 476/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9197 - accuracy: 0.7795 - val_loss: 0.9562 - val_accuracy: 0.7660\n",
      "Epoch 477/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9183 - accuracy: 0.7777 - val_loss: 0.9805 - val_accuracy: 0.7650\n",
      "Epoch 478/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9210 - accuracy: 0.7771 - val_loss: 0.9581 - val_accuracy: 0.7650\n",
      "Epoch 479/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9184 - accuracy: 0.7774 - val_loss: 0.9576 - val_accuracy: 0.7690\n",
      "Epoch 480/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9172 - accuracy: 0.7780 - val_loss: 0.9642 - val_accuracy: 0.7620\n",
      "Epoch 481/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9170 - accuracy: 0.7806 - val_loss: 0.9540 - val_accuracy: 0.7650\n",
      "Epoch 482/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9168 - accuracy: 0.7792 - val_loss: 0.9547 - val_accuracy: 0.7620\n",
      "Epoch 483/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9169 - accuracy: 0.7795 - val_loss: 0.9573 - val_accuracy: 0.7640\n",
      "Epoch 484/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9177 - accuracy: 0.7780 - val_loss: 0.9552 - val_accuracy: 0.7640\n",
      "Epoch 485/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9153 - accuracy: 0.7798 - val_loss: 0.9555 - val_accuracy: 0.7640\n",
      "Epoch 486/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9155 - accuracy: 0.7782 - val_loss: 0.9525 - val_accuracy: 0.7650\n",
      "Epoch 487/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9146 - accuracy: 0.7806 - val_loss: 0.9560 - val_accuracy: 0.7600\n",
      "Epoch 488/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9141 - accuracy: 0.7797 - val_loss: 0.9548 - val_accuracy: 0.7700\n",
      "Epoch 489/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9141 - accuracy: 0.7797 - val_loss: 0.9519 - val_accuracy: 0.7680\n",
      "Epoch 490/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9149 - accuracy: 0.7798 - val_loss: 0.9551 - val_accuracy: 0.7690\n",
      "Epoch 491/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9145 - accuracy: 0.7786 - val_loss: 0.9577 - val_accuracy: 0.7670\n",
      "Epoch 492/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9138 - accuracy: 0.7789 - val_loss: 0.9502 - val_accuracy: 0.7700\n",
      "Epoch 493/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9124 - accuracy: 0.7809 - val_loss: 0.9599 - val_accuracy: 0.7660\n",
      "Epoch 494/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9121 - accuracy: 0.7817 - val_loss: 0.9574 - val_accuracy: 0.7680\n",
      "Epoch 495/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9126 - accuracy: 0.7808 - val_loss: 0.9569 - val_accuracy: 0.7720\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9125 - accuracy: 0.7809 - val_loss: 0.9528 - val_accuracy: 0.7700\n",
      "Epoch 497/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9129 - accuracy: 0.7789 - val_loss: 0.9533 - val_accuracy: 0.7690\n",
      "Epoch 498/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9130 - accuracy: 0.7782 - val_loss: 0.9505 - val_accuracy: 0.7690\n",
      "Epoch 499/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9121 - accuracy: 0.7814 - val_loss: 0.9526 - val_accuracy: 0.7630\n",
      "Epoch 500/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9099 - accuracy: 0.7829 - val_loss: 0.9509 - val_accuracy: 0.7680\n",
      "Epoch 501/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9097 - accuracy: 0.7825 - val_loss: 0.9664 - val_accuracy: 0.7570\n",
      "Epoch 502/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9111 - accuracy: 0.7809 - val_loss: 0.9566 - val_accuracy: 0.7670\n",
      "Epoch 503/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9100 - accuracy: 0.7817 - val_loss: 0.9540 - val_accuracy: 0.7700\n",
      "Epoch 504/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9099 - accuracy: 0.7820 - val_loss: 0.9520 - val_accuracy: 0.7610\n",
      "Epoch 505/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9100 - accuracy: 0.7832 - val_loss: 0.9564 - val_accuracy: 0.7640\n",
      "Epoch 506/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9097 - accuracy: 0.7831 - val_loss: 0.9595 - val_accuracy: 0.7650\n",
      "Epoch 507/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9091 - accuracy: 0.7828 - val_loss: 0.9537 - val_accuracy: 0.7610\n",
      "Epoch 508/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9082 - accuracy: 0.7837 - val_loss: 0.9503 - val_accuracy: 0.7750\n",
      "Epoch 509/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9089 - accuracy: 0.7811 - val_loss: 0.9515 - val_accuracy: 0.7650\n",
      "Epoch 510/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9077 - accuracy: 0.7820 - val_loss: 0.9495 - val_accuracy: 0.7710\n",
      "Epoch 511/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9079 - accuracy: 0.7831 - val_loss: 0.9500 - val_accuracy: 0.7680\n",
      "Epoch 512/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9081 - accuracy: 0.7823 - val_loss: 0.9518 - val_accuracy: 0.7690\n",
      "Epoch 513/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9072 - accuracy: 0.7825 - val_loss: 0.9529 - val_accuracy: 0.7780\n",
      "Epoch 514/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9075 - accuracy: 0.7851 - val_loss: 0.9591 - val_accuracy: 0.7680\n",
      "Epoch 515/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9080 - accuracy: 0.7834 - val_loss: 0.9579 - val_accuracy: 0.7600\n",
      "Epoch 516/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9074 - accuracy: 0.7840 - val_loss: 0.9499 - val_accuracy: 0.7660\n",
      "Epoch 517/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9060 - accuracy: 0.7846 - val_loss: 0.9504 - val_accuracy: 0.7600\n",
      "Epoch 518/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9067 - accuracy: 0.7828 - val_loss: 0.9487 - val_accuracy: 0.7630\n",
      "Epoch 519/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9056 - accuracy: 0.7835 - val_loss: 0.9577 - val_accuracy: 0.7620\n",
      "Epoch 520/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9051 - accuracy: 0.7834 - val_loss: 0.9476 - val_accuracy: 0.7690\n",
      "Epoch 521/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9052 - accuracy: 0.7872 - val_loss: 0.9587 - val_accuracy: 0.7650\n",
      "Epoch 522/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9050 - accuracy: 0.7823 - val_loss: 0.9478 - val_accuracy: 0.7690\n",
      "Epoch 523/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9041 - accuracy: 0.7812 - val_loss: 0.9615 - val_accuracy: 0.7610\n",
      "Epoch 524/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9036 - accuracy: 0.7835 - val_loss: 0.9481 - val_accuracy: 0.7720\n",
      "Epoch 525/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9041 - accuracy: 0.7843 - val_loss: 0.9572 - val_accuracy: 0.7740\n",
      "Epoch 526/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9032 - accuracy: 0.7845 - val_loss: 0.9505 - val_accuracy: 0.7640\n",
      "Epoch 527/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9045 - accuracy: 0.7849 - val_loss: 0.9486 - val_accuracy: 0.7690\n",
      "Epoch 528/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9024 - accuracy: 0.7828 - val_loss: 0.9462 - val_accuracy: 0.7740\n",
      "Epoch 529/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9033 - accuracy: 0.7845 - val_loss: 0.9532 - val_accuracy: 0.7700\n",
      "Epoch 530/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9027 - accuracy: 0.7869 - val_loss: 0.9489 - val_accuracy: 0.7730\n",
      "Epoch 531/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9032 - accuracy: 0.7854 - val_loss: 0.9546 - val_accuracy: 0.7690\n",
      "Epoch 532/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9016 - accuracy: 0.7862 - val_loss: 0.9517 - val_accuracy: 0.7690\n",
      "Epoch 533/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9015 - accuracy: 0.7829 - val_loss: 0.9510 - val_accuracy: 0.7740\n",
      "Epoch 534/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9019 - accuracy: 0.7852 - val_loss: 0.9500 - val_accuracy: 0.7700\n",
      "Epoch 535/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9018 - accuracy: 0.7840 - val_loss: 0.9506 - val_accuracy: 0.7680\n",
      "Epoch 536/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9009 - accuracy: 0.7865 - val_loss: 0.9466 - val_accuracy: 0.7710\n",
      "Epoch 537/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9007 - accuracy: 0.7869 - val_loss: 0.9465 - val_accuracy: 0.7640\n",
      "Epoch 538/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9012 - accuracy: 0.7858 - val_loss: 0.9555 - val_accuracy: 0.7690\n",
      "Epoch 539/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9002 - accuracy: 0.7855 - val_loss: 0.9505 - val_accuracy: 0.7670\n",
      "Epoch 540/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8997 - accuracy: 0.7872 - val_loss: 0.9593 - val_accuracy: 0.7630\n",
      "Epoch 541/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.9006 - accuracy: 0.7838 - val_loss: 0.9461 - val_accuracy: 0.7670\n",
      "Epoch 542/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8994 - accuracy: 0.7883 - val_loss: 0.9507 - val_accuracy: 0.7700\n",
      "Epoch 543/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8991 - accuracy: 0.7875 - val_loss: 0.9437 - val_accuracy: 0.7730\n",
      "Epoch 544/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8981 - accuracy: 0.7865 - val_loss: 0.9468 - val_accuracy: 0.7680\n",
      "Epoch 545/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8984 - accuracy: 0.7878 - val_loss: 0.9460 - val_accuracy: 0.7690\n",
      "Epoch 546/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8990 - accuracy: 0.7886 - val_loss: 0.9582 - val_accuracy: 0.7660\n",
      "Epoch 547/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8983 - accuracy: 0.7866 - val_loss: 0.9515 - val_accuracy: 0.7780\n",
      "Epoch 548/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8981 - accuracy: 0.7858 - val_loss: 0.9436 - val_accuracy: 0.7700\n",
      "Epoch 549/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8979 - accuracy: 0.7882 - val_loss: 0.9530 - val_accuracy: 0.7690\n",
      "Epoch 550/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8966 - accuracy: 0.7882 - val_loss: 0.9545 - val_accuracy: 0.7650\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8969 - accuracy: 0.7874 - val_loss: 0.9427 - val_accuracy: 0.7680\n",
      "Epoch 552/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8966 - accuracy: 0.7865 - val_loss: 0.9434 - val_accuracy: 0.7710\n",
      "Epoch 553/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8967 - accuracy: 0.7872 - val_loss: 0.9443 - val_accuracy: 0.7740\n",
      "Epoch 554/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8955 - accuracy: 0.7877 - val_loss: 0.9470 - val_accuracy: 0.7670\n",
      "Epoch 555/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8950 - accuracy: 0.7911 - val_loss: 0.9425 - val_accuracy: 0.7660\n",
      "Epoch 556/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8954 - accuracy: 0.7880 - val_loss: 0.9535 - val_accuracy: 0.7640\n",
      "Epoch 557/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8956 - accuracy: 0.7863 - val_loss: 0.9496 - val_accuracy: 0.7680\n",
      "Epoch 558/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8953 - accuracy: 0.7902 - val_loss: 0.9474 - val_accuracy: 0.7750\n",
      "Epoch 559/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8962 - accuracy: 0.7897 - val_loss: 0.9434 - val_accuracy: 0.7730\n",
      "Epoch 560/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8950 - accuracy: 0.7880 - val_loss: 0.9429 - val_accuracy: 0.7660\n",
      "Epoch 561/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8935 - accuracy: 0.7885 - val_loss: 0.9489 - val_accuracy: 0.7680\n",
      "Epoch 562/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8946 - accuracy: 0.7875 - val_loss: 0.9592 - val_accuracy: 0.7760\n",
      "Epoch 563/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8942 - accuracy: 0.7889 - val_loss: 0.9461 - val_accuracy: 0.7620\n",
      "Epoch 564/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8948 - accuracy: 0.7883 - val_loss: 0.9482 - val_accuracy: 0.7630\n",
      "Epoch 565/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8929 - accuracy: 0.7889 - val_loss: 0.9557 - val_accuracy: 0.7680\n",
      "Epoch 566/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8930 - accuracy: 0.7902 - val_loss: 0.9541 - val_accuracy: 0.7690\n",
      "Epoch 567/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8932 - accuracy: 0.7912 - val_loss: 0.9457 - val_accuracy: 0.7630\n",
      "Epoch 568/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8930 - accuracy: 0.7900 - val_loss: 0.9425 - val_accuracy: 0.7660\n",
      "Epoch 569/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8925 - accuracy: 0.7906 - val_loss: 0.9429 - val_accuracy: 0.7760\n",
      "Epoch 570/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8935 - accuracy: 0.7877 - val_loss: 0.9425 - val_accuracy: 0.7690\n",
      "Epoch 571/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8916 - accuracy: 0.7903 - val_loss: 0.9481 - val_accuracy: 0.7680\n",
      "Epoch 572/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8923 - accuracy: 0.7917 - val_loss: 0.9481 - val_accuracy: 0.7760\n",
      "Epoch 573/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8917 - accuracy: 0.7915 - val_loss: 0.9418 - val_accuracy: 0.7750\n",
      "Epoch 574/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8917 - accuracy: 0.7914 - val_loss: 0.9465 - val_accuracy: 0.7700\n",
      "Epoch 575/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8915 - accuracy: 0.7906 - val_loss: 0.9545 - val_accuracy: 0.7640\n",
      "Epoch 576/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8910 - accuracy: 0.7885 - val_loss: 0.9413 - val_accuracy: 0.7680\n",
      "Epoch 577/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8900 - accuracy: 0.7912 - val_loss: 0.9443 - val_accuracy: 0.7660\n",
      "Epoch 578/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8922 - accuracy: 0.7909 - val_loss: 0.9481 - val_accuracy: 0.7630\n",
      "Epoch 579/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8897 - accuracy: 0.7872 - val_loss: 0.9438 - val_accuracy: 0.7680\n",
      "Epoch 580/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8897 - accuracy: 0.7920 - val_loss: 0.9676 - val_accuracy: 0.7570\n",
      "Epoch 581/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8905 - accuracy: 0.7928 - val_loss: 0.9574 - val_accuracy: 0.7570\n",
      "Epoch 582/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8908 - accuracy: 0.7897 - val_loss: 0.9555 - val_accuracy: 0.7660\n",
      "Epoch 583/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8899 - accuracy: 0.7891 - val_loss: 0.9576 - val_accuracy: 0.7610\n",
      "Epoch 584/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8897 - accuracy: 0.7905 - val_loss: 0.9449 - val_accuracy: 0.7680\n",
      "Epoch 585/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8894 - accuracy: 0.7912 - val_loss: 0.9440 - val_accuracy: 0.7770\n",
      "Epoch 586/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8878 - accuracy: 0.7917 - val_loss: 0.9486 - val_accuracy: 0.7660\n",
      "Epoch 587/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8883 - accuracy: 0.7931 - val_loss: 0.9474 - val_accuracy: 0.7680\n",
      "Epoch 588/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8874 - accuracy: 0.7935 - val_loss: 0.9430 - val_accuracy: 0.7720\n",
      "Epoch 589/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8891 - accuracy: 0.7925 - val_loss: 0.9454 - val_accuracy: 0.7720\n",
      "Epoch 590/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8872 - accuracy: 0.7922 - val_loss: 0.9413 - val_accuracy: 0.7800\n",
      "Epoch 591/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8872 - accuracy: 0.7943 - val_loss: 0.9481 - val_accuracy: 0.7770\n",
      "Epoch 592/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8873 - accuracy: 0.7920 - val_loss: 0.9416 - val_accuracy: 0.7730\n",
      "Epoch 593/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8862 - accuracy: 0.7969 - val_loss: 0.9387 - val_accuracy: 0.7770\n",
      "Epoch 594/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8858 - accuracy: 0.7937 - val_loss: 0.9455 - val_accuracy: 0.7690\n",
      "Epoch 595/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8862 - accuracy: 0.7943 - val_loss: 0.9473 - val_accuracy: 0.7690\n",
      "Epoch 596/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8851 - accuracy: 0.7948 - val_loss: 0.9411 - val_accuracy: 0.7700\n",
      "Epoch 597/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8863 - accuracy: 0.7909 - val_loss: 0.9466 - val_accuracy: 0.7680\n",
      "Epoch 598/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8845 - accuracy: 0.7942 - val_loss: 0.9458 - val_accuracy: 0.7740\n",
      "Epoch 599/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8852 - accuracy: 0.7935 - val_loss: 0.9565 - val_accuracy: 0.7670\n",
      "Epoch 600/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8855 - accuracy: 0.7938 - val_loss: 0.9513 - val_accuracy: 0.7610\n",
      "Epoch 601/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8854 - accuracy: 0.7938 - val_loss: 0.9474 - val_accuracy: 0.7680\n",
      "Epoch 602/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8858 - accuracy: 0.7922 - val_loss: 0.9495 - val_accuracy: 0.7790\n",
      "Epoch 603/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8856 - accuracy: 0.7914 - val_loss: 0.9390 - val_accuracy: 0.7700\n",
      "Epoch 604/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8834 - accuracy: 0.7975 - val_loss: 0.9437 - val_accuracy: 0.7730\n",
      "Epoch 605/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8851 - accuracy: 0.7945 - val_loss: 0.9576 - val_accuracy: 0.7590\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8843 - accuracy: 0.7965 - val_loss: 0.9413 - val_accuracy: 0.7730\n",
      "Epoch 607/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8832 - accuracy: 0.7920 - val_loss: 0.9511 - val_accuracy: 0.7720\n",
      "Epoch 608/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8838 - accuracy: 0.7923 - val_loss: 0.9427 - val_accuracy: 0.7730\n",
      "Epoch 609/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8849 - accuracy: 0.7938 - val_loss: 0.9445 - val_accuracy: 0.7680\n",
      "Epoch 610/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8830 - accuracy: 0.7934 - val_loss: 0.9389 - val_accuracy: 0.7750\n",
      "Epoch 611/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8826 - accuracy: 0.7931 - val_loss: 0.9407 - val_accuracy: 0.7760\n",
      "Epoch 612/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8819 - accuracy: 0.7951 - val_loss: 0.9444 - val_accuracy: 0.7730\n",
      "Epoch 613/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8840 - accuracy: 0.7942 - val_loss: 0.9411 - val_accuracy: 0.7750\n",
      "Epoch 614/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8812 - accuracy: 0.7949 - val_loss: 0.9467 - val_accuracy: 0.7660\n",
      "Epoch 615/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8818 - accuracy: 0.7982 - val_loss: 0.9467 - val_accuracy: 0.7670\n",
      "Epoch 616/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8816 - accuracy: 0.7954 - val_loss: 0.9619 - val_accuracy: 0.7510\n",
      "Epoch 617/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8816 - accuracy: 0.7937 - val_loss: 0.9440 - val_accuracy: 0.7700\n",
      "Epoch 618/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8809 - accuracy: 0.7934 - val_loss: 0.9505 - val_accuracy: 0.7660\n",
      "Epoch 619/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8801 - accuracy: 0.7955 - val_loss: 0.9422 - val_accuracy: 0.7800\n",
      "Epoch 620/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8805 - accuracy: 0.7954 - val_loss: 0.9447 - val_accuracy: 0.7800\n",
      "Epoch 621/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8798 - accuracy: 0.7963 - val_loss: 0.9437 - val_accuracy: 0.7760\n",
      "Epoch 622/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8798 - accuracy: 0.7985 - val_loss: 0.9430 - val_accuracy: 0.7770\n",
      "Epoch 623/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8786 - accuracy: 0.7980 - val_loss: 0.9377 - val_accuracy: 0.7730\n",
      "Epoch 624/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8803 - accuracy: 0.7968 - val_loss: 0.9409 - val_accuracy: 0.7750\n",
      "Epoch 625/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8799 - accuracy: 0.7986 - val_loss: 0.9453 - val_accuracy: 0.7710\n",
      "Epoch 626/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8794 - accuracy: 0.7955 - val_loss: 0.9479 - val_accuracy: 0.7610\n",
      "Epoch 627/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8810 - accuracy: 0.7968 - val_loss: 0.9423 - val_accuracy: 0.7750\n",
      "Epoch 628/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8787 - accuracy: 0.7983 - val_loss: 0.9429 - val_accuracy: 0.7700\n",
      "Epoch 629/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8779 - accuracy: 0.7965 - val_loss: 0.9654 - val_accuracy: 0.7680\n",
      "Epoch 630/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8785 - accuracy: 0.7957 - val_loss: 0.9433 - val_accuracy: 0.7730\n",
      "Epoch 631/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8779 - accuracy: 0.7972 - val_loss: 0.9405 - val_accuracy: 0.7740\n",
      "Epoch 632/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8792 - accuracy: 0.7960 - val_loss: 0.9450 - val_accuracy: 0.7710\n",
      "Epoch 633/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8765 - accuracy: 0.7985 - val_loss: 0.9381 - val_accuracy: 0.7720\n",
      "Epoch 634/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8781 - accuracy: 0.7955 - val_loss: 0.9484 - val_accuracy: 0.7710\n",
      "Epoch 635/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8772 - accuracy: 0.8002 - val_loss: 0.9417 - val_accuracy: 0.7710\n",
      "Epoch 636/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8775 - accuracy: 0.7971 - val_loss: 0.9365 - val_accuracy: 0.7710\n",
      "Epoch 637/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8763 - accuracy: 0.7988 - val_loss: 0.9353 - val_accuracy: 0.7730\n",
      "Epoch 638/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8755 - accuracy: 0.7989 - val_loss: 0.9467 - val_accuracy: 0.7700\n",
      "Epoch 639/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8777 - accuracy: 0.8002 - val_loss: 0.9571 - val_accuracy: 0.7590\n",
      "Epoch 640/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8763 - accuracy: 0.7960 - val_loss: 0.9384 - val_accuracy: 0.7730\n",
      "Epoch 641/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8754 - accuracy: 0.7997 - val_loss: 0.9410 - val_accuracy: 0.7770\n",
      "Epoch 642/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8755 - accuracy: 0.7972 - val_loss: 0.9376 - val_accuracy: 0.7770\n",
      "Epoch 643/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8766 - accuracy: 0.7992 - val_loss: 0.9376 - val_accuracy: 0.7740\n",
      "Epoch 644/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8775 - accuracy: 0.7965 - val_loss: 0.9391 - val_accuracy: 0.7730\n",
      "Epoch 645/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8747 - accuracy: 0.7968 - val_loss: 0.9372 - val_accuracy: 0.7700\n",
      "Epoch 646/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8752 - accuracy: 0.7985 - val_loss: 0.9503 - val_accuracy: 0.7650\n",
      "Epoch 647/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8758 - accuracy: 0.8008 - val_loss: 0.9367 - val_accuracy: 0.7730\n",
      "Epoch 648/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8738 - accuracy: 0.8018 - val_loss: 0.9554 - val_accuracy: 0.7680\n",
      "Epoch 649/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8739 - accuracy: 0.7992 - val_loss: 0.9382 - val_accuracy: 0.7720\n",
      "Epoch 650/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8756 - accuracy: 0.7991 - val_loss: 0.9492 - val_accuracy: 0.7700\n",
      "Epoch 651/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8758 - accuracy: 0.8008 - val_loss: 0.9410 - val_accuracy: 0.7730\n",
      "Epoch 652/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8733 - accuracy: 0.8015 - val_loss: 0.9446 - val_accuracy: 0.7770\n",
      "Epoch 653/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8750 - accuracy: 0.7982 - val_loss: 0.9411 - val_accuracy: 0.7800\n",
      "Epoch 654/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8744 - accuracy: 0.7992 - val_loss: 0.9541 - val_accuracy: 0.7690\n",
      "Epoch 655/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8738 - accuracy: 0.8028 - val_loss: 0.9375 - val_accuracy: 0.7790\n",
      "Epoch 656/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8721 - accuracy: 0.8042 - val_loss: 0.9398 - val_accuracy: 0.7780\n",
      "Epoch 657/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8739 - accuracy: 0.7988 - val_loss: 0.9404 - val_accuracy: 0.7730\n",
      "Epoch 658/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8722 - accuracy: 0.7983 - val_loss: 0.9640 - val_accuracy: 0.7570\n",
      "Epoch 659/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8745 - accuracy: 0.7969 - val_loss: 0.9465 - val_accuracy: 0.7820\n",
      "Epoch 660/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8721 - accuracy: 0.8017 - val_loss: 0.9392 - val_accuracy: 0.7730\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8729 - accuracy: 0.7980 - val_loss: 0.9547 - val_accuracy: 0.7710\n",
      "Epoch 662/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8733 - accuracy: 0.8002 - val_loss: 0.9395 - val_accuracy: 0.7740\n",
      "Epoch 663/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8728 - accuracy: 0.8023 - val_loss: 0.9446 - val_accuracy: 0.7720\n",
      "Epoch 664/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8731 - accuracy: 0.8018 - val_loss: 0.9370 - val_accuracy: 0.7780\n",
      "Epoch 665/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8711 - accuracy: 0.7997 - val_loss: 0.9374 - val_accuracy: 0.7770\n",
      "Epoch 666/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8710 - accuracy: 0.8035 - val_loss: 0.9415 - val_accuracy: 0.7770\n",
      "Epoch 667/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8722 - accuracy: 0.8017 - val_loss: 0.9411 - val_accuracy: 0.7710\n",
      "Epoch 668/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8710 - accuracy: 0.8022 - val_loss: 0.9367 - val_accuracy: 0.7750\n",
      "Epoch 669/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8702 - accuracy: 0.8020 - val_loss: 0.9430 - val_accuracy: 0.7670\n",
      "Epoch 670/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8711 - accuracy: 0.8035 - val_loss: 0.9500 - val_accuracy: 0.7650\n",
      "Epoch 671/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8697 - accuracy: 0.8017 - val_loss: 0.9440 - val_accuracy: 0.7790\n",
      "Epoch 672/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8698 - accuracy: 0.8012 - val_loss: 0.9391 - val_accuracy: 0.7730\n",
      "Epoch 673/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8696 - accuracy: 0.8017 - val_loss: 0.9397 - val_accuracy: 0.7700\n",
      "Epoch 674/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8689 - accuracy: 0.8012 - val_loss: 0.9366 - val_accuracy: 0.7790\n",
      "Epoch 675/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8690 - accuracy: 0.8026 - val_loss: 0.9415 - val_accuracy: 0.7710\n",
      "Epoch 676/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8703 - accuracy: 0.8020 - val_loss: 0.9422 - val_accuracy: 0.7680\n",
      "Epoch 677/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8669 - accuracy: 0.8058 - val_loss: 0.9503 - val_accuracy: 0.7690\n",
      "Epoch 678/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8679 - accuracy: 0.8031 - val_loss: 0.9401 - val_accuracy: 0.7730\n",
      "Epoch 679/1000\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 0.8679 - accuracy: 0.8054 - val_loss: 0.9418 - val_accuracy: 0.7860\n",
      "Epoch 680/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8663 - accuracy: 0.8040 - val_loss: 0.9425 - val_accuracy: 0.7740\n",
      "Epoch 681/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8692 - accuracy: 0.8034 - val_loss: 0.9357 - val_accuracy: 0.7720\n",
      "Epoch 682/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8689 - accuracy: 0.8022 - val_loss: 0.9370 - val_accuracy: 0.7730\n",
      "Epoch 683/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8678 - accuracy: 0.8040 - val_loss: 0.9353 - val_accuracy: 0.7760\n",
      "Epoch 684/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8671 - accuracy: 0.8034 - val_loss: 0.9386 - val_accuracy: 0.7760\n",
      "Epoch 685/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8686 - accuracy: 0.8015 - val_loss: 0.9417 - val_accuracy: 0.7750\n",
      "Epoch 686/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8676 - accuracy: 0.8025 - val_loss: 0.9326 - val_accuracy: 0.7710\n",
      "Epoch 687/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8650 - accuracy: 0.8057 - val_loss: 0.9719 - val_accuracy: 0.7530\n",
      "Epoch 688/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8652 - accuracy: 0.8057 - val_loss: 0.9398 - val_accuracy: 0.7740\n",
      "Epoch 689/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8666 - accuracy: 0.8062 - val_loss: 0.9477 - val_accuracy: 0.7720\n",
      "Epoch 690/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8681 - accuracy: 0.8012 - val_loss: 0.9443 - val_accuracy: 0.7700\n",
      "Epoch 691/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8670 - accuracy: 0.8058 - val_loss: 0.9553 - val_accuracy: 0.7700\n",
      "Epoch 692/1000\n",
      "6500/6500 [==============================] - 0s 25us/step - loss: 0.8663 - accuracy: 0.8035 - val_loss: 0.9423 - val_accuracy: 0.7700\n",
      "Epoch 693/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8660 - accuracy: 0.8018 - val_loss: 0.9401 - val_accuracy: 0.7750\n",
      "Epoch 694/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8646 - accuracy: 0.8065 - val_loss: 0.9542 - val_accuracy: 0.7820\n",
      "Epoch 695/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8653 - accuracy: 0.8057 - val_loss: 0.9402 - val_accuracy: 0.7790\n",
      "Epoch 696/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8647 - accuracy: 0.8026 - val_loss: 0.9389 - val_accuracy: 0.7800\n",
      "Epoch 697/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8649 - accuracy: 0.8035 - val_loss: 0.9449 - val_accuracy: 0.7770\n",
      "Epoch 698/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8636 - accuracy: 0.8045 - val_loss: 0.9349 - val_accuracy: 0.7750\n",
      "Epoch 699/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8648 - accuracy: 0.8032 - val_loss: 0.9332 - val_accuracy: 0.7790\n",
      "Epoch 700/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8644 - accuracy: 0.8028 - val_loss: 0.9354 - val_accuracy: 0.7760\n",
      "Epoch 701/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8658 - accuracy: 0.8060 - val_loss: 0.9401 - val_accuracy: 0.7740\n",
      "Epoch 702/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8638 - accuracy: 0.8048 - val_loss: 0.9373 - val_accuracy: 0.7830\n",
      "Epoch 703/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8638 - accuracy: 0.8075 - val_loss: 0.9411 - val_accuracy: 0.7720\n",
      "Epoch 704/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8638 - accuracy: 0.8066 - val_loss: 0.9375 - val_accuracy: 0.7780\n",
      "Epoch 705/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8637 - accuracy: 0.8014 - val_loss: 0.9418 - val_accuracy: 0.7760\n",
      "Epoch 706/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8637 - accuracy: 0.8074 - val_loss: 0.9398 - val_accuracy: 0.7710\n",
      "Epoch 707/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8621 - accuracy: 0.8040 - val_loss: 0.9383 - val_accuracy: 0.7720\n",
      "Epoch 708/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8630 - accuracy: 0.8065 - val_loss: 0.9367 - val_accuracy: 0.7790\n",
      "Epoch 709/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8618 - accuracy: 0.8049 - val_loss: 0.9356 - val_accuracy: 0.7780\n",
      "Epoch 710/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8617 - accuracy: 0.8060 - val_loss: 0.9417 - val_accuracy: 0.7790\n",
      "Epoch 711/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8624 - accuracy: 0.8066 - val_loss: 0.9490 - val_accuracy: 0.7660\n",
      "Epoch 712/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8621 - accuracy: 0.8052 - val_loss: 0.9345 - val_accuracy: 0.7790\n",
      "Epoch 713/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8622 - accuracy: 0.8062 - val_loss: 0.9400 - val_accuracy: 0.7800\n",
      "Epoch 714/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8604 - accuracy: 0.8057 - val_loss: 0.9335 - val_accuracy: 0.7810\n",
      "Epoch 715/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8628 - accuracy: 0.8052 - val_loss: 0.9396 - val_accuracy: 0.7780\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8610 - accuracy: 0.8071 - val_loss: 0.9414 - val_accuracy: 0.7790\n",
      "Epoch 717/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8637 - accuracy: 0.8038 - val_loss: 0.9344 - val_accuracy: 0.7710\n",
      "Epoch 718/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8611 - accuracy: 0.8057 - val_loss: 0.9396 - val_accuracy: 0.7770\n",
      "Epoch 719/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8609 - accuracy: 0.8049 - val_loss: 0.9378 - val_accuracy: 0.7740\n",
      "Epoch 720/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8605 - accuracy: 0.8069 - val_loss: 0.9488 - val_accuracy: 0.7780\n",
      "Epoch 721/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8605 - accuracy: 0.8049 - val_loss: 0.9343 - val_accuracy: 0.7760\n",
      "Epoch 722/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8607 - accuracy: 0.8063 - val_loss: 0.9346 - val_accuracy: 0.7790\n",
      "Epoch 723/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8606 - accuracy: 0.8065 - val_loss: 0.9381 - val_accuracy: 0.7730\n",
      "Epoch 724/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8587 - accuracy: 0.8077 - val_loss: 0.9397 - val_accuracy: 0.7770\n",
      "Epoch 725/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8589 - accuracy: 0.8072 - val_loss: 0.9542 - val_accuracy: 0.7600\n",
      "Epoch 726/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8603 - accuracy: 0.8040 - val_loss: 0.9362 - val_accuracy: 0.7790\n",
      "Epoch 727/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8582 - accuracy: 0.8060 - val_loss: 0.9344 - val_accuracy: 0.7800\n",
      "Epoch 728/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8597 - accuracy: 0.8077 - val_loss: 0.9571 - val_accuracy: 0.7630\n",
      "Epoch 729/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8579 - accuracy: 0.8060 - val_loss: 0.9442 - val_accuracy: 0.7700\n",
      "Epoch 730/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8594 - accuracy: 0.8043 - val_loss: 0.9327 - val_accuracy: 0.7730\n",
      "Epoch 731/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8587 - accuracy: 0.8077 - val_loss: 0.9757 - val_accuracy: 0.7740\n",
      "Epoch 732/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8596 - accuracy: 0.8035 - val_loss: 0.9533 - val_accuracy: 0.7650\n",
      "Epoch 733/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8597 - accuracy: 0.8080 - val_loss: 0.9455 - val_accuracy: 0.7710\n",
      "Epoch 734/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8577 - accuracy: 0.8062 - val_loss: 0.9418 - val_accuracy: 0.7690\n",
      "Epoch 735/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8579 - accuracy: 0.8063 - val_loss: 0.9361 - val_accuracy: 0.7790\n",
      "Epoch 736/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8587 - accuracy: 0.8052 - val_loss: 0.9356 - val_accuracy: 0.7760\n",
      "Epoch 737/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8571 - accuracy: 0.8100 - val_loss: 0.9337 - val_accuracy: 0.7780\n",
      "Epoch 738/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8559 - accuracy: 0.8055 - val_loss: 0.9458 - val_accuracy: 0.7730\n",
      "Epoch 739/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8574 - accuracy: 0.8058 - val_loss: 0.9354 - val_accuracy: 0.7770\n",
      "Epoch 740/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8564 - accuracy: 0.8085 - val_loss: 0.9435 - val_accuracy: 0.7700\n",
      "Epoch 741/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8586 - accuracy: 0.8065 - val_loss: 0.9403 - val_accuracy: 0.7740\n",
      "Epoch 742/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8565 - accuracy: 0.8074 - val_loss: 0.9341 - val_accuracy: 0.7760\n",
      "Epoch 743/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8578 - accuracy: 0.8075 - val_loss: 0.9304 - val_accuracy: 0.7790\n",
      "Epoch 744/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8552 - accuracy: 0.8117 - val_loss: 0.9385 - val_accuracy: 0.7790\n",
      "Epoch 745/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8566 - accuracy: 0.8102 - val_loss: 0.9734 - val_accuracy: 0.7610\n",
      "Epoch 746/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8566 - accuracy: 0.8055 - val_loss: 0.9328 - val_accuracy: 0.7770\n",
      "Epoch 747/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8548 - accuracy: 0.8074 - val_loss: 0.9996 - val_accuracy: 0.7490\n",
      "Epoch 748/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8575 - accuracy: 0.8091 - val_loss: 0.9484 - val_accuracy: 0.7760\n",
      "Epoch 749/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8547 - accuracy: 0.8072 - val_loss: 0.9350 - val_accuracy: 0.7730\n",
      "Epoch 750/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8560 - accuracy: 0.8078 - val_loss: 0.9436 - val_accuracy: 0.7800\n",
      "Epoch 751/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8564 - accuracy: 0.8086 - val_loss: 0.9305 - val_accuracy: 0.7760\n",
      "Epoch 752/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8549 - accuracy: 0.8100 - val_loss: 0.9364 - val_accuracy: 0.7750\n",
      "Epoch 753/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8561 - accuracy: 0.8086 - val_loss: 0.9334 - val_accuracy: 0.7780\n",
      "Epoch 754/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8544 - accuracy: 0.8100 - val_loss: 0.9416 - val_accuracy: 0.7770\n",
      "Epoch 755/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8547 - accuracy: 0.8072 - val_loss: 0.9326 - val_accuracy: 0.7760\n",
      "Epoch 756/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8541 - accuracy: 0.8125 - val_loss: 0.9556 - val_accuracy: 0.7640\n",
      "Epoch 757/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8545 - accuracy: 0.8082 - val_loss: 0.9447 - val_accuracy: 0.7730\n",
      "Epoch 758/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8530 - accuracy: 0.8129 - val_loss: 0.9388 - val_accuracy: 0.7810\n",
      "Epoch 759/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8560 - accuracy: 0.8072 - val_loss: 0.9425 - val_accuracy: 0.7760\n",
      "Epoch 760/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8544 - accuracy: 0.8085 - val_loss: 0.9450 - val_accuracy: 0.7720\n",
      "Epoch 761/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8549 - accuracy: 0.8082 - val_loss: 0.9337 - val_accuracy: 0.7770\n",
      "Epoch 762/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8539 - accuracy: 0.8097 - val_loss: 0.9339 - val_accuracy: 0.7800\n",
      "Epoch 763/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8524 - accuracy: 0.8105 - val_loss: 0.9348 - val_accuracy: 0.7820\n",
      "Epoch 764/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8527 - accuracy: 0.8108 - val_loss: 0.9380 - val_accuracy: 0.7750\n",
      "Epoch 765/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8510 - accuracy: 0.8102 - val_loss: 0.9419 - val_accuracy: 0.7770\n",
      "Epoch 766/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8525 - accuracy: 0.8108 - val_loss: 0.9530 - val_accuracy: 0.7780\n",
      "Epoch 767/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8523 - accuracy: 0.8125 - val_loss: 0.9352 - val_accuracy: 0.7760\n",
      "Epoch 768/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8521 - accuracy: 0.8115 - val_loss: 0.9408 - val_accuracy: 0.7850\n",
      "Epoch 769/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8511 - accuracy: 0.8126 - val_loss: 0.9348 - val_accuracy: 0.7750\n",
      "Epoch 770/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8515 - accuracy: 0.8091 - val_loss: 0.9370 - val_accuracy: 0.7800\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8533 - accuracy: 0.8105 - val_loss: 0.9523 - val_accuracy: 0.7760\n",
      "Epoch 772/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8524 - accuracy: 0.8122 - val_loss: 0.9427 - val_accuracy: 0.7800\n",
      "Epoch 773/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8519 - accuracy: 0.8111 - val_loss: 0.9363 - val_accuracy: 0.7800\n",
      "Epoch 774/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8488 - accuracy: 0.8134 - val_loss: 0.9407 - val_accuracy: 0.7750\n",
      "Epoch 775/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8494 - accuracy: 0.8132 - val_loss: 0.9839 - val_accuracy: 0.7600\n",
      "Epoch 776/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8517 - accuracy: 0.8106 - val_loss: 0.9456 - val_accuracy: 0.7770\n",
      "Epoch 777/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8520 - accuracy: 0.8092 - val_loss: 0.9342 - val_accuracy: 0.7780\n",
      "Epoch 778/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8507 - accuracy: 0.8122 - val_loss: 0.9487 - val_accuracy: 0.7640\n",
      "Epoch 779/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8517 - accuracy: 0.8106 - val_loss: 0.9353 - val_accuracy: 0.7730\n",
      "Epoch 780/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8485 - accuracy: 0.8129 - val_loss: 0.9317 - val_accuracy: 0.7840\n",
      "Epoch 781/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8501 - accuracy: 0.8118 - val_loss: 0.9306 - val_accuracy: 0.7790\n",
      "Epoch 782/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8479 - accuracy: 0.8145 - val_loss: 0.9403 - val_accuracy: 0.7730\n",
      "Epoch 783/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8490 - accuracy: 0.8100 - val_loss: 0.9375 - val_accuracy: 0.7730\n",
      "Epoch 784/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8487 - accuracy: 0.8128 - val_loss: 0.9723 - val_accuracy: 0.7520\n",
      "Epoch 785/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8508 - accuracy: 0.8103 - val_loss: 0.9379 - val_accuracy: 0.7750\n",
      "Epoch 786/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8480 - accuracy: 0.8105 - val_loss: 0.9434 - val_accuracy: 0.7710\n",
      "Epoch 787/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8473 - accuracy: 0.8109 - val_loss: 0.9501 - val_accuracy: 0.7700\n",
      "Epoch 788/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8479 - accuracy: 0.8120 - val_loss: 0.9348 - val_accuracy: 0.7800\n",
      "Epoch 789/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8488 - accuracy: 0.8143 - val_loss: 0.9394 - val_accuracy: 0.7740\n",
      "Epoch 790/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8497 - accuracy: 0.8111 - val_loss: 0.9513 - val_accuracy: 0.7640\n",
      "Epoch 791/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8488 - accuracy: 0.8131 - val_loss: 0.9365 - val_accuracy: 0.7770\n",
      "Epoch 792/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8466 - accuracy: 0.8122 - val_loss: 0.9362 - val_accuracy: 0.7800\n",
      "Epoch 793/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8475 - accuracy: 0.8123 - val_loss: 0.9499 - val_accuracy: 0.7630\n",
      "Epoch 794/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8478 - accuracy: 0.8145 - val_loss: 0.9320 - val_accuracy: 0.7760\n",
      "Epoch 795/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8485 - accuracy: 0.8135 - val_loss: 0.9325 - val_accuracy: 0.7850\n",
      "Epoch 796/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8472 - accuracy: 0.8106 - val_loss: 0.9470 - val_accuracy: 0.7640\n",
      "Epoch 797/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8454 - accuracy: 0.8138 - val_loss: 0.9344 - val_accuracy: 0.7800\n",
      "Epoch 798/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8468 - accuracy: 0.8128 - val_loss: 0.9299 - val_accuracy: 0.7850\n",
      "Epoch 799/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8489 - accuracy: 0.8098 - val_loss: 0.9331 - val_accuracy: 0.7800\n",
      "Epoch 800/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8463 - accuracy: 0.8149 - val_loss: 0.9295 - val_accuracy: 0.7830\n",
      "Epoch 801/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8454 - accuracy: 0.8148 - val_loss: 0.9369 - val_accuracy: 0.7780\n",
      "Epoch 802/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8454 - accuracy: 0.8132 - val_loss: 0.9315 - val_accuracy: 0.7810\n",
      "Epoch 803/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8459 - accuracy: 0.8178 - val_loss: 0.9332 - val_accuracy: 0.7840\n",
      "Epoch 804/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8448 - accuracy: 0.8163 - val_loss: 0.9445 - val_accuracy: 0.7770\n",
      "Epoch 805/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8455 - accuracy: 0.8154 - val_loss: 0.9321 - val_accuracy: 0.7820\n",
      "Epoch 806/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8463 - accuracy: 0.8126 - val_loss: 0.9426 - val_accuracy: 0.7830\n",
      "Epoch 807/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8441 - accuracy: 0.8157 - val_loss: 0.9527 - val_accuracy: 0.7760\n",
      "Epoch 808/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8448 - accuracy: 0.8157 - val_loss: 0.9325 - val_accuracy: 0.7810\n",
      "Epoch 809/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8444 - accuracy: 0.8117 - val_loss: 0.9453 - val_accuracy: 0.7760\n",
      "Epoch 810/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8447 - accuracy: 0.8148 - val_loss: 0.9628 - val_accuracy: 0.7710\n",
      "Epoch 811/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8487 - accuracy: 0.8128 - val_loss: 0.9388 - val_accuracy: 0.7790\n",
      "Epoch 812/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8445 - accuracy: 0.8154 - val_loss: 0.9539 - val_accuracy: 0.7770\n",
      "Epoch 813/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8440 - accuracy: 0.8120 - val_loss: 0.9409 - val_accuracy: 0.7790\n",
      "Epoch 814/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8474 - accuracy: 0.8154 - val_loss: 0.9316 - val_accuracy: 0.7800\n",
      "Epoch 815/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8434 - accuracy: 0.8148 - val_loss: 0.9300 - val_accuracy: 0.7840\n",
      "Epoch 816/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8427 - accuracy: 0.8148 - val_loss: 0.9496 - val_accuracy: 0.7670\n",
      "Epoch 817/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8436 - accuracy: 0.8151 - val_loss: 0.9391 - val_accuracy: 0.7760\n",
      "Epoch 818/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8442 - accuracy: 0.8162 - val_loss: 0.9325 - val_accuracy: 0.7780\n",
      "Epoch 819/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8420 - accuracy: 0.8160 - val_loss: 0.9408 - val_accuracy: 0.7760\n",
      "Epoch 820/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8430 - accuracy: 0.8145 - val_loss: 0.9350 - val_accuracy: 0.7820\n",
      "Epoch 821/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8423 - accuracy: 0.8138 - val_loss: 0.9340 - val_accuracy: 0.7820\n",
      "Epoch 822/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8416 - accuracy: 0.8195 - val_loss: 0.9318 - val_accuracy: 0.7790\n",
      "Epoch 823/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8434 - accuracy: 0.8131 - val_loss: 0.9403 - val_accuracy: 0.7830\n",
      "Epoch 824/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8449 - accuracy: 0.8117 - val_loss: 1.0119 - val_accuracy: 0.7380\n",
      "Epoch 825/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8454 - accuracy: 0.8149 - val_loss: 0.9472 - val_accuracy: 0.7780\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8425 - accuracy: 0.8154 - val_loss: 0.9289 - val_accuracy: 0.7810\n",
      "Epoch 827/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8423 - accuracy: 0.8175 - val_loss: 0.9320 - val_accuracy: 0.7830\n",
      "Epoch 828/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8424 - accuracy: 0.8155 - val_loss: 0.9483 - val_accuracy: 0.7690\n",
      "Epoch 829/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8428 - accuracy: 0.8143 - val_loss: 0.9292 - val_accuracy: 0.7800\n",
      "Epoch 830/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8407 - accuracy: 0.8134 - val_loss: 0.9484 - val_accuracy: 0.7770\n",
      "Epoch 831/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8390 - accuracy: 0.8178 - val_loss: 0.9499 - val_accuracy: 0.7760\n",
      "Epoch 832/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8413 - accuracy: 0.8162 - val_loss: 0.9317 - val_accuracy: 0.7800\n",
      "Epoch 833/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8409 - accuracy: 0.8163 - val_loss: 0.9619 - val_accuracy: 0.7700\n",
      "Epoch 834/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8410 - accuracy: 0.8148 - val_loss: 0.9409 - val_accuracy: 0.7780\n",
      "Epoch 835/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8376 - accuracy: 0.8174 - val_loss: 0.9332 - val_accuracy: 0.7870\n",
      "Epoch 836/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8390 - accuracy: 0.8165 - val_loss: 0.9448 - val_accuracy: 0.7680\n",
      "Epoch 837/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8400 - accuracy: 0.8149 - val_loss: 0.9397 - val_accuracy: 0.7730\n",
      "Epoch 838/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8401 - accuracy: 0.8166 - val_loss: 0.9335 - val_accuracy: 0.7820\n",
      "Epoch 839/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8400 - accuracy: 0.8165 - val_loss: 0.9937 - val_accuracy: 0.7490\n",
      "Epoch 840/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8424 - accuracy: 0.8154 - val_loss: 0.9402 - val_accuracy: 0.7740\n",
      "Epoch 841/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8392 - accuracy: 0.8149 - val_loss: 0.9609 - val_accuracy: 0.7690\n",
      "Epoch 842/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8424 - accuracy: 0.8120 - val_loss: 0.9319 - val_accuracy: 0.7860\n",
      "Epoch 843/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8368 - accuracy: 0.8174 - val_loss: 0.9452 - val_accuracy: 0.7800\n",
      "Epoch 844/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8405 - accuracy: 0.8142 - val_loss: 0.9287 - val_accuracy: 0.7830\n",
      "Epoch 845/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8392 - accuracy: 0.8149 - val_loss: 0.9285 - val_accuracy: 0.7860\n",
      "Epoch 846/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8374 - accuracy: 0.8182 - val_loss: 0.9309 - val_accuracy: 0.7840\n",
      "Epoch 847/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8413 - accuracy: 0.8171 - val_loss: 0.9293 - val_accuracy: 0.7840\n",
      "Epoch 848/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8385 - accuracy: 0.8183 - val_loss: 0.9374 - val_accuracy: 0.7740\n",
      "Epoch 849/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8378 - accuracy: 0.8171 - val_loss: 0.9393 - val_accuracy: 0.7770\n",
      "Epoch 850/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8387 - accuracy: 0.8134 - val_loss: 0.9455 - val_accuracy: 0.7800\n",
      "Epoch 851/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8355 - accuracy: 0.8163 - val_loss: 0.9373 - val_accuracy: 0.7820\n",
      "Epoch 852/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8369 - accuracy: 0.8148 - val_loss: 0.9506 - val_accuracy: 0.7670\n",
      "Epoch 853/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8374 - accuracy: 0.8148 - val_loss: 0.9309 - val_accuracy: 0.7810\n",
      "Epoch 854/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8361 - accuracy: 0.8166 - val_loss: 0.9365 - val_accuracy: 0.7820\n",
      "Epoch 855/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8394 - accuracy: 0.8151 - val_loss: 0.9360 - val_accuracy: 0.7850\n",
      "Epoch 856/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8386 - accuracy: 0.8172 - val_loss: 0.9343 - val_accuracy: 0.7850\n",
      "Epoch 857/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8371 - accuracy: 0.8168 - val_loss: 0.9488 - val_accuracy: 0.7650\n",
      "Epoch 858/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8379 - accuracy: 0.8134 - val_loss: 0.9348 - val_accuracy: 0.7790\n",
      "Epoch 859/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8381 - accuracy: 0.8132 - val_loss: 0.9313 - val_accuracy: 0.7790\n",
      "Epoch 860/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8394 - accuracy: 0.8137 - val_loss: 0.9360 - val_accuracy: 0.7770\n",
      "Epoch 861/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8366 - accuracy: 0.8160 - val_loss: 0.9426 - val_accuracy: 0.7840\n",
      "Epoch 862/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8362 - accuracy: 0.8194 - val_loss: 0.9545 - val_accuracy: 0.7760\n",
      "Epoch 863/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8337 - accuracy: 0.8175 - val_loss: 0.9447 - val_accuracy: 0.7760\n",
      "Epoch 864/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8384 - accuracy: 0.8175 - val_loss: 0.9786 - val_accuracy: 0.7690\n",
      "Epoch 865/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8347 - accuracy: 0.8165 - val_loss: 0.9403 - val_accuracy: 0.7790\n",
      "Epoch 866/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8350 - accuracy: 0.8208 - val_loss: 0.9304 - val_accuracy: 0.7860\n",
      "Epoch 867/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8386 - accuracy: 0.8163 - val_loss: 0.9425 - val_accuracy: 0.7810\n",
      "Epoch 868/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8362 - accuracy: 0.8182 - val_loss: 0.9614 - val_accuracy: 0.7670\n",
      "Epoch 869/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8379 - accuracy: 0.8169 - val_loss: 0.9606 - val_accuracy: 0.7840\n",
      "Epoch 870/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8387 - accuracy: 0.8157 - val_loss: 0.9395 - val_accuracy: 0.7810\n",
      "Epoch 871/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8383 - accuracy: 0.8202 - val_loss: 0.9448 - val_accuracy: 0.7660\n",
      "Epoch 872/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8357 - accuracy: 0.8177 - val_loss: 0.9508 - val_accuracy: 0.7730\n",
      "Epoch 873/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8365 - accuracy: 0.8182 - val_loss: 0.9724 - val_accuracy: 0.7710\n",
      "Epoch 874/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8337 - accuracy: 0.8182 - val_loss: 0.9296 - val_accuracy: 0.7850\n",
      "Epoch 875/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8324 - accuracy: 0.8205 - val_loss: 0.9462 - val_accuracy: 0.7890\n",
      "Epoch 876/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8327 - accuracy: 0.8211 - val_loss: 0.9301 - val_accuracy: 0.7850\n",
      "Epoch 877/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8323 - accuracy: 0.8205 - val_loss: 0.9377 - val_accuracy: 0.7820\n",
      "Epoch 878/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8330 - accuracy: 0.8214 - val_loss: 0.9413 - val_accuracy: 0.7790\n",
      "Epoch 879/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8341 - accuracy: 0.8183 - val_loss: 0.9752 - val_accuracy: 0.7550\n",
      "Epoch 880/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8351 - accuracy: 0.8160 - val_loss: 0.9304 - val_accuracy: 0.7850\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8374 - accuracy: 0.8145 - val_loss: 0.9534 - val_accuracy: 0.7750\n",
      "Epoch 882/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8345 - accuracy: 0.8155 - val_loss: 0.9284 - val_accuracy: 0.7850\n",
      "Epoch 883/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8335 - accuracy: 0.8218 - val_loss: 0.9663 - val_accuracy: 0.7570\n",
      "Epoch 884/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8332 - accuracy: 0.8198 - val_loss: 0.9676 - val_accuracy: 0.7650\n",
      "Epoch 885/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8339 - accuracy: 0.8195 - val_loss: 0.9436 - val_accuracy: 0.7750\n",
      "Epoch 886/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8304 - accuracy: 0.8234 - val_loss: 0.9419 - val_accuracy: 0.7780\n",
      "Epoch 887/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8311 - accuracy: 0.8205 - val_loss: 0.9367 - val_accuracy: 0.7850\n",
      "Epoch 888/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8315 - accuracy: 0.8178 - val_loss: 0.9371 - val_accuracy: 0.7740\n",
      "Epoch 889/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8346 - accuracy: 0.8218 - val_loss: 0.9466 - val_accuracy: 0.7740\n",
      "Epoch 890/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8303 - accuracy: 0.8212 - val_loss: 0.9709 - val_accuracy: 0.7610\n",
      "Epoch 891/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8428 - accuracy: 0.8154 - val_loss: 0.9330 - val_accuracy: 0.7820\n",
      "Epoch 892/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8324 - accuracy: 0.8182 - val_loss: 0.9349 - val_accuracy: 0.7860\n",
      "Epoch 893/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8322 - accuracy: 0.8197 - val_loss: 0.9414 - val_accuracy: 0.7760\n",
      "Epoch 894/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8303 - accuracy: 0.8178 - val_loss: 0.9286 - val_accuracy: 0.7880\n",
      "Epoch 895/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8317 - accuracy: 0.8200 - val_loss: 0.9304 - val_accuracy: 0.7820\n",
      "Epoch 896/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8275 - accuracy: 0.8223 - val_loss: 0.9378 - val_accuracy: 0.7830\n",
      "Epoch 897/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8282 - accuracy: 0.8225 - val_loss: 0.9455 - val_accuracy: 0.7760\n",
      "Epoch 898/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8297 - accuracy: 0.8209 - val_loss: 0.9712 - val_accuracy: 0.7600\n",
      "Epoch 899/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8324 - accuracy: 0.8198 - val_loss: 0.9276 - val_accuracy: 0.7920\n",
      "Epoch 900/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8283 - accuracy: 0.8205 - val_loss: 0.9287 - val_accuracy: 0.7870\n",
      "Epoch 901/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8274 - accuracy: 0.8278 - val_loss: 0.9470 - val_accuracy: 0.7730\n",
      "Epoch 902/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8292 - accuracy: 0.8238 - val_loss: 0.9365 - val_accuracy: 0.7770\n",
      "Epoch 903/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8283 - accuracy: 0.8205 - val_loss: 0.9398 - val_accuracy: 0.7830\n",
      "Epoch 904/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8276 - accuracy: 0.8234 - val_loss: 0.9525 - val_accuracy: 0.7680\n",
      "Epoch 905/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8298 - accuracy: 0.8200 - val_loss: 0.9694 - val_accuracy: 0.7590\n",
      "Epoch 906/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8362 - accuracy: 0.8169 - val_loss: 0.9533 - val_accuracy: 0.7760\n",
      "Epoch 907/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8287 - accuracy: 0.8191 - val_loss: 0.9998 - val_accuracy: 0.7600\n",
      "Epoch 908/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8317 - accuracy: 0.8212 - val_loss: 0.9285 - val_accuracy: 0.7890\n",
      "Epoch 909/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8331 - accuracy: 0.8169 - val_loss: 0.9351 - val_accuracy: 0.7800\n",
      "Epoch 910/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8278 - accuracy: 0.8217 - val_loss: 0.9567 - val_accuracy: 0.7670\n",
      "Epoch 911/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8318 - accuracy: 0.8206 - val_loss: 0.9342 - val_accuracy: 0.7790\n",
      "Epoch 912/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8293 - accuracy: 0.8228 - val_loss: 0.9770 - val_accuracy: 0.7610\n",
      "Epoch 913/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8306 - accuracy: 0.8209 - val_loss: 0.9450 - val_accuracy: 0.7780\n",
      "Epoch 914/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8271 - accuracy: 0.8228 - val_loss: 0.9300 - val_accuracy: 0.7920\n",
      "Epoch 915/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8313 - accuracy: 0.8203 - val_loss: 0.9324 - val_accuracy: 0.7850\n",
      "Epoch 916/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8250 - accuracy: 0.8255 - val_loss: 0.9321 - val_accuracy: 0.7840\n",
      "Epoch 917/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8295 - accuracy: 0.8215 - val_loss: 0.9426 - val_accuracy: 0.7790\n",
      "Epoch 918/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8251 - accuracy: 0.8249 - val_loss: 0.9434 - val_accuracy: 0.7760\n",
      "Epoch 919/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8278 - accuracy: 0.8218 - val_loss: 0.9424 - val_accuracy: 0.7760\n",
      "Epoch 920/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8271 - accuracy: 0.8222 - val_loss: 0.9586 - val_accuracy: 0.7670\n",
      "Epoch 921/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8248 - accuracy: 0.8231 - val_loss: 0.9408 - val_accuracy: 0.7790\n",
      "Epoch 922/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8270 - accuracy: 0.8209 - val_loss: 0.9372 - val_accuracy: 0.7800\n",
      "Epoch 923/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8279 - accuracy: 0.8206 - val_loss: 0.9393 - val_accuracy: 0.7800\n",
      "Epoch 924/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8329 - accuracy: 0.8205 - val_loss: 0.9374 - val_accuracy: 0.7810\n",
      "Epoch 925/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8264 - accuracy: 0.8246 - val_loss: 0.9484 - val_accuracy: 0.7740\n",
      "Epoch 926/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8264 - accuracy: 0.8245 - val_loss: 0.9489 - val_accuracy: 0.7710\n",
      "Epoch 927/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8308 - accuracy: 0.8143 - val_loss: 0.9367 - val_accuracy: 0.7770\n",
      "Epoch 928/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8241 - accuracy: 0.8198 - val_loss: 0.9268 - val_accuracy: 0.7900\n",
      "Epoch 929/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8274 - accuracy: 0.8206 - val_loss: 0.9445 - val_accuracy: 0.7800\n",
      "Epoch 930/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8240 - accuracy: 0.8246 - val_loss: 0.9282 - val_accuracy: 0.7870\n",
      "Epoch 931/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8274 - accuracy: 0.8195 - val_loss: 0.9515 - val_accuracy: 0.7830\n",
      "Epoch 932/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8270 - accuracy: 0.8186 - val_loss: 0.9534 - val_accuracy: 0.7710\n",
      "Epoch 933/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8240 - accuracy: 0.8258 - val_loss: 0.9478 - val_accuracy: 0.7640\n",
      "Epoch 934/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8279 - accuracy: 0.8225 - val_loss: 0.9604 - val_accuracy: 0.7650\n",
      "Epoch 935/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8272 - accuracy: 0.8226 - val_loss: 0.9660 - val_accuracy: 0.7580\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8285 - accuracy: 0.8195 - val_loss: 0.9336 - val_accuracy: 0.7890\n",
      "Epoch 937/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8221 - accuracy: 0.8280 - val_loss: 0.9368 - val_accuracy: 0.7860\n",
      "Epoch 938/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8249 - accuracy: 0.8245 - val_loss: 0.9491 - val_accuracy: 0.7720\n",
      "Epoch 939/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8235 - accuracy: 0.8226 - val_loss: 0.9320 - val_accuracy: 0.7890\n",
      "Epoch 940/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8237 - accuracy: 0.8232 - val_loss: 1.0627 - val_accuracy: 0.7260\n",
      "Epoch 941/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8299 - accuracy: 0.8192 - val_loss: 0.9283 - val_accuracy: 0.7820\n",
      "Epoch 942/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8241 - accuracy: 0.8228 - val_loss: 0.9773 - val_accuracy: 0.7610\n",
      "Epoch 943/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8269 - accuracy: 0.8222 - val_loss: 1.0263 - val_accuracy: 0.7400\n",
      "Epoch 944/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8316 - accuracy: 0.8198 - val_loss: 0.9334 - val_accuracy: 0.7850\n",
      "Epoch 945/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8247 - accuracy: 0.8235 - val_loss: 0.9323 - val_accuracy: 0.7880\n",
      "Epoch 946/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8237 - accuracy: 0.8249 - val_loss: 0.9510 - val_accuracy: 0.7670\n",
      "Epoch 947/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8231 - accuracy: 0.8223 - val_loss: 0.9408 - val_accuracy: 0.7800\n",
      "Epoch 948/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8219 - accuracy: 0.8258 - val_loss: 0.9294 - val_accuracy: 0.7870\n",
      "Epoch 949/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8217 - accuracy: 0.8251 - val_loss: 0.9564 - val_accuracy: 0.7730\n",
      "Epoch 950/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8214 - accuracy: 0.8238 - val_loss: 1.0048 - val_accuracy: 0.7440\n",
      "Epoch 951/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8239 - accuracy: 0.8220 - val_loss: 0.9408 - val_accuracy: 0.7780\n",
      "Epoch 952/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8249 - accuracy: 0.8235 - val_loss: 0.9475 - val_accuracy: 0.7800\n",
      "Epoch 953/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8209 - accuracy: 0.8245 - val_loss: 0.9333 - val_accuracy: 0.7870\n",
      "Epoch 954/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8195 - accuracy: 0.8278 - val_loss: 0.9509 - val_accuracy: 0.7640\n",
      "Epoch 955/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8234 - accuracy: 0.8238 - val_loss: 0.9557 - val_accuracy: 0.7760\n",
      "Epoch 956/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8213 - accuracy: 0.8217 - val_loss: 0.9383 - val_accuracy: 0.7800\n",
      "Epoch 957/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8284 - accuracy: 0.8212 - val_loss: 0.9264 - val_accuracy: 0.7890\n",
      "Epoch 958/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8236 - accuracy: 0.8226 - val_loss: 1.0037 - val_accuracy: 0.7470\n",
      "Epoch 959/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8269 - accuracy: 0.8249 - val_loss: 0.9593 - val_accuracy: 0.7620\n",
      "Epoch 960/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8248 - accuracy: 0.8268 - val_loss: 0.9652 - val_accuracy: 0.7810\n",
      "Epoch 961/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8235 - accuracy: 0.8234 - val_loss: 0.9456 - val_accuracy: 0.7830\n",
      "Epoch 962/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8263 - accuracy: 0.8211 - val_loss: 0.9371 - val_accuracy: 0.7820\n",
      "Epoch 963/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8187 - accuracy: 0.8252 - val_loss: 0.9577 - val_accuracy: 0.7810\n",
      "Epoch 964/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8203 - accuracy: 0.8265 - val_loss: 0.9289 - val_accuracy: 0.7850\n",
      "Epoch 965/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8261 - accuracy: 0.8206 - val_loss: 0.9479 - val_accuracy: 0.7800\n",
      "Epoch 966/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8233 - accuracy: 0.8262 - val_loss: 0.9334 - val_accuracy: 0.7760\n",
      "Epoch 967/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8223 - accuracy: 0.8246 - val_loss: 0.9328 - val_accuracy: 0.7740\n",
      "Epoch 968/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8234 - accuracy: 0.8246 - val_loss: 0.9447 - val_accuracy: 0.7750\n",
      "Epoch 969/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8268 - accuracy: 0.8195 - val_loss: 0.9462 - val_accuracy: 0.7830\n",
      "Epoch 970/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8247 - accuracy: 0.8254 - val_loss: 0.9313 - val_accuracy: 0.7830\n",
      "Epoch 971/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8195 - accuracy: 0.8275 - val_loss: 0.9908 - val_accuracy: 0.7580\n",
      "Epoch 972/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8237 - accuracy: 0.8231 - val_loss: 0.9349 - val_accuracy: 0.7890\n",
      "Epoch 973/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8271 - accuracy: 0.8237 - val_loss: 0.9374 - val_accuracy: 0.7750\n",
      "Epoch 974/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8318 - accuracy: 0.8195 - val_loss: 0.9720 - val_accuracy: 0.7620\n",
      "Epoch 975/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8173 - accuracy: 0.8298 - val_loss: 0.9457 - val_accuracy: 0.7760\n",
      "Epoch 976/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8214 - accuracy: 0.8251 - val_loss: 0.9643 - val_accuracy: 0.7650\n",
      "Epoch 977/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8262 - accuracy: 0.8217 - val_loss: 0.9572 - val_accuracy: 0.7760\n",
      "Epoch 978/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8254 - accuracy: 0.8223 - val_loss: 0.9306 - val_accuracy: 0.7840\n",
      "Epoch 979/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8223 - accuracy: 0.8235 - val_loss: 0.9349 - val_accuracy: 0.7800\n",
      "Epoch 980/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8182 - accuracy: 0.8248 - val_loss: 0.9393 - val_accuracy: 0.7820\n",
      "Epoch 981/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8252 - accuracy: 0.8205 - val_loss: 0.9405 - val_accuracy: 0.7760\n",
      "Epoch 982/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8236 - accuracy: 0.8251 - val_loss: 0.9467 - val_accuracy: 0.7640\n",
      "Epoch 983/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8196 - accuracy: 0.8265 - val_loss: 0.9314 - val_accuracy: 0.7810\n",
      "Epoch 984/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8238 - accuracy: 0.8214 - val_loss: 0.9347 - val_accuracy: 0.7900\n",
      "Epoch 985/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8208 - accuracy: 0.8235 - val_loss: 0.9682 - val_accuracy: 0.7570\n",
      "Epoch 986/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8215 - accuracy: 0.8242 - val_loss: 0.9391 - val_accuracy: 0.7900\n",
      "Epoch 987/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8184 - accuracy: 0.8291 - val_loss: 0.9834 - val_accuracy: 0.7740\n",
      "Epoch 988/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8203 - accuracy: 0.8277 - val_loss: 0.9350 - val_accuracy: 0.7770\n",
      "Epoch 989/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8163 - accuracy: 0.8292 - val_loss: 0.9481 - val_accuracy: 0.7740\n",
      "Epoch 990/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8197 - accuracy: 0.8282 - val_loss: 0.9300 - val_accuracy: 0.7890\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8142 - accuracy: 0.8286 - val_loss: 0.9302 - val_accuracy: 0.7840\n",
      "Epoch 992/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8240 - accuracy: 0.8212 - val_loss: 0.9409 - val_accuracy: 0.7700\n",
      "Epoch 993/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8179 - accuracy: 0.8243 - val_loss: 0.9391 - val_accuracy: 0.7810\n",
      "Epoch 994/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8224 - accuracy: 0.8271 - val_loss: 0.9387 - val_accuracy: 0.7730\n",
      "Epoch 995/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8248 - accuracy: 0.8251 - val_loss: 0.9358 - val_accuracy: 0.7790\n",
      "Epoch 996/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8218 - accuracy: 0.8223 - val_loss: 0.9376 - val_accuracy: 0.7730\n",
      "Epoch 997/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8149 - accuracy: 0.8309 - val_loss: 0.9549 - val_accuracy: 0.7780\n",
      "Epoch 998/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8219 - accuracy: 0.8248 - val_loss: 0.9354 - val_accuracy: 0.7810\n",
      "Epoch 999/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8174 - accuracy: 0.8234 - val_loss: 0.9385 - val_accuracy: 0.7810\n",
      "Epoch 1000/1000\n",
      "6500/6500 [==============================] - 0s 24us/step - loss: 0.8154 - accuracy: 0.8297 - val_loss: 0.9291 - val_accuracy: 0.7830\n"
     ]
    }
   ],
   "source": [
    "# â° This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_token,\n",
    "                    y_train_label,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 20us/step\n",
      "Training Loss: 0.806 Training Accuracy: 0.837\n",
      "2500/2500 [==============================] - 0s 20us/step\n",
      "Testing Loss: 0.956 Testing Accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_token, y_train_label)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "6500/6500 [==============================] - 0s 54us/step - loss: 1.9931 - accuracy: 0.1549 - val_loss: 1.9406 - val_accuracy: 0.1580\n",
      "Epoch 2/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.9485 - accuracy: 0.1709 - val_loss: 1.9253 - val_accuracy: 0.1970\n",
      "Epoch 3/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.9378 - accuracy: 0.1700 - val_loss: 1.9141 - val_accuracy: 0.2160\n",
      "Epoch 4/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.9263 - accuracy: 0.1878 - val_loss: 1.9039 - val_accuracy: 0.2420\n",
      "Epoch 5/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.9155 - accuracy: 0.1917 - val_loss: 1.8923 - val_accuracy: 0.2590\n",
      "Epoch 6/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.8988 - accuracy: 0.2168 - val_loss: 1.8781 - val_accuracy: 0.2790\n",
      "Epoch 7/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.8922 - accuracy: 0.2208 - val_loss: 1.8644 - val_accuracy: 0.2880\n",
      "Epoch 8/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.8783 - accuracy: 0.2355 - val_loss: 1.8468 - val_accuracy: 0.2930\n",
      "Epoch 9/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.8681 - accuracy: 0.2398 - val_loss: 1.8312 - val_accuracy: 0.3090\n",
      "Epoch 10/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.8492 - accuracy: 0.2545 - val_loss: 1.8124 - val_accuracy: 0.3270\n",
      "Epoch 11/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.8408 - accuracy: 0.2498 - val_loss: 1.7943 - val_accuracy: 0.3440\n",
      "Epoch 12/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.8226 - accuracy: 0.2623 - val_loss: 1.7722 - val_accuracy: 0.3450\n",
      "Epoch 13/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.8132 - accuracy: 0.2706 - val_loss: 1.7568 - val_accuracy: 0.3690\n",
      "Epoch 14/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7889 - accuracy: 0.2845 - val_loss: 1.7345 - val_accuracy: 0.3870\n",
      "Epoch 15/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7743 - accuracy: 0.2926 - val_loss: 1.7127 - val_accuracy: 0.4040\n",
      "Epoch 16/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7638 - accuracy: 0.3095 - val_loss: 1.6912 - val_accuracy: 0.4140\n",
      "Epoch 17/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7396 - accuracy: 0.3155 - val_loss: 1.6720 - val_accuracy: 0.4250\n",
      "Epoch 18/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7168 - accuracy: 0.3358 - val_loss: 1.6472 - val_accuracy: 0.4330\n",
      "Epoch 19/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7168 - accuracy: 0.3269 - val_loss: 1.6283 - val_accuracy: 0.4480\n",
      "Epoch 20/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.7006 - accuracy: 0.3366 - val_loss: 1.6107 - val_accuracy: 0.4590\n",
      "Epoch 21/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6824 - accuracy: 0.3451 - val_loss: 1.5895 - val_accuracy: 0.4680\n",
      "Epoch 22/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6681 - accuracy: 0.3463 - val_loss: 1.5702 - val_accuracy: 0.4760\n",
      "Epoch 23/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6583 - accuracy: 0.3552 - val_loss: 1.5480 - val_accuracy: 0.4820\n",
      "Epoch 24/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6336 - accuracy: 0.3691 - val_loss: 1.5278 - val_accuracy: 0.4960\n",
      "Epoch 25/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6189 - accuracy: 0.3763 - val_loss: 1.5074 - val_accuracy: 0.5170\n",
      "Epoch 26/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.6011 - accuracy: 0.3811 - val_loss: 1.4878 - val_accuracy: 0.5260\n",
      "Epoch 27/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.5930 - accuracy: 0.3886 - val_loss: 1.4664 - val_accuracy: 0.5320\n",
      "Epoch 28/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.5804 - accuracy: 0.3968 - val_loss: 1.4450 - val_accuracy: 0.5450\n",
      "Epoch 29/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.5637 - accuracy: 0.3957 - val_loss: 1.4282 - val_accuracy: 0.5530\n",
      "Epoch 30/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.5406 - accuracy: 0.4145 - val_loss: 1.4064 - val_accuracy: 0.5640\n",
      "Epoch 31/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.5427 - accuracy: 0.4009 - val_loss: 1.3911 - val_accuracy: 0.5710\n",
      "Epoch 32/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.5179 - accuracy: 0.4294 - val_loss: 1.3709 - val_accuracy: 0.5720\n",
      "Epoch 33/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.5032 - accuracy: 0.4269 - val_loss: 1.3502 - val_accuracy: 0.5840\n",
      "Epoch 34/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.4894 - accuracy: 0.4309 - val_loss: 1.3313 - val_accuracy: 0.5900\n",
      "Epoch 35/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.4830 - accuracy: 0.4348 - val_loss: 1.3173 - val_accuracy: 0.6020\n",
      "Epoch 36/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.4670 - accuracy: 0.4423 - val_loss: 1.3022 - val_accuracy: 0.6060\n",
      "Epoch 37/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.4540 - accuracy: 0.4502 - val_loss: 1.2813 - val_accuracy: 0.6120\n",
      "Epoch 38/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.4384 - accuracy: 0.4488 - val_loss: 1.2644 - val_accuracy: 0.6190\n",
      "Epoch 39/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.4147 - accuracy: 0.4620 - val_loss: 1.2447 - val_accuracy: 0.6280\n",
      "Epoch 40/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.4091 - accuracy: 0.4629 - val_loss: 1.2296 - val_accuracy: 0.6300\n",
      "Epoch 41/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.4043 - accuracy: 0.4662 - val_loss: 1.2173 - val_accuracy: 0.6280\n",
      "Epoch 42/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3879 - accuracy: 0.4768 - val_loss: 1.1999 - val_accuracy: 0.6320\n",
      "Epoch 43/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.3887 - accuracy: 0.4697 - val_loss: 1.1914 - val_accuracy: 0.6440\n",
      "Epoch 44/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3688 - accuracy: 0.4837 - val_loss: 1.1750 - val_accuracy: 0.6480\n",
      "Epoch 45/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3677 - accuracy: 0.4857 - val_loss: 1.1641 - val_accuracy: 0.6570\n",
      "Epoch 46/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3483 - accuracy: 0.4877 - val_loss: 1.1549 - val_accuracy: 0.6540\n",
      "Epoch 47/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3409 - accuracy: 0.4968 - val_loss: 1.1372 - val_accuracy: 0.6600\n",
      "Epoch 48/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3343 - accuracy: 0.4955 - val_loss: 1.1260 - val_accuracy: 0.6650\n",
      "Epoch 49/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3184 - accuracy: 0.4992 - val_loss: 1.1172 - val_accuracy: 0.6690\n",
      "Epoch 50/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.3067 - accuracy: 0.4920 - val_loss: 1.1012 - val_accuracy: 0.6730\n",
      "Epoch 51/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.2982 - accuracy: 0.5054 - val_loss: 1.0890 - val_accuracy: 0.6820\n",
      "Epoch 52/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2928 - accuracy: 0.5094 - val_loss: 1.0805 - val_accuracy: 0.6800\n",
      "Epoch 53/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2718 - accuracy: 0.5242 - val_loss: 1.0682 - val_accuracy: 0.6830\n",
      "Epoch 54/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2649 - accuracy: 0.5217 - val_loss: 1.0566 - val_accuracy: 0.6790\n",
      "Epoch 55/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2543 - accuracy: 0.5314 - val_loss: 1.0456 - val_accuracy: 0.6800\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2573 - accuracy: 0.5245 - val_loss: 1.0382 - val_accuracy: 0.6820\n",
      "Epoch 57/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2457 - accuracy: 0.5249 - val_loss: 1.0295 - val_accuracy: 0.6870\n",
      "Epoch 58/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2336 - accuracy: 0.5398 - val_loss: 1.0230 - val_accuracy: 0.6900\n",
      "Epoch 59/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2320 - accuracy: 0.5360 - val_loss: 1.0148 - val_accuracy: 0.6890\n",
      "Epoch 60/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2317 - accuracy: 0.5360 - val_loss: 1.0062 - val_accuracy: 0.6960\n",
      "Epoch 61/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2210 - accuracy: 0.5506 - val_loss: 0.9986 - val_accuracy: 0.6930\n",
      "Epoch 62/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.2119 - accuracy: 0.5480 - val_loss: 0.9899 - val_accuracy: 0.6940\n",
      "Epoch 63/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1990 - accuracy: 0.5534 - val_loss: 0.9841 - val_accuracy: 0.6940\n",
      "Epoch 64/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1841 - accuracy: 0.5592 - val_loss: 0.9734 - val_accuracy: 0.6990\n",
      "Epoch 65/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1968 - accuracy: 0.5482 - val_loss: 0.9665 - val_accuracy: 0.7060\n",
      "Epoch 66/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1701 - accuracy: 0.5651 - val_loss: 0.9591 - val_accuracy: 0.7070\n",
      "Epoch 67/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1765 - accuracy: 0.5642 - val_loss: 0.9509 - val_accuracy: 0.7050\n",
      "Epoch 68/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1656 - accuracy: 0.5643 - val_loss: 0.9449 - val_accuracy: 0.7060\n",
      "Epoch 69/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1658 - accuracy: 0.5632 - val_loss: 0.9389 - val_accuracy: 0.7130\n",
      "Epoch 70/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1508 - accuracy: 0.5709 - val_loss: 0.9306 - val_accuracy: 0.7100\n",
      "Epoch 71/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.1555 - accuracy: 0.5728 - val_loss: 0.9268 - val_accuracy: 0.7130\n",
      "Epoch 72/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1394 - accuracy: 0.5778 - val_loss: 0.9167 - val_accuracy: 0.7170\n",
      "Epoch 73/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1411 - accuracy: 0.5751 - val_loss: 0.9128 - val_accuracy: 0.7160\n",
      "Epoch 74/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1355 - accuracy: 0.5740 - val_loss: 0.9092 - val_accuracy: 0.7190\n",
      "Epoch 75/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1273 - accuracy: 0.5777 - val_loss: 0.9028 - val_accuracy: 0.7160\n",
      "Epoch 76/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1276 - accuracy: 0.5826 - val_loss: 0.8990 - val_accuracy: 0.7190\n",
      "Epoch 77/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1104 - accuracy: 0.5785 - val_loss: 0.8920 - val_accuracy: 0.7230\n",
      "Epoch 78/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1043 - accuracy: 0.5914 - val_loss: 0.8856 - val_accuracy: 0.7230\n",
      "Epoch 79/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.1049 - accuracy: 0.5885 - val_loss: 0.8793 - val_accuracy: 0.7220\n",
      "Epoch 80/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0943 - accuracy: 0.5918 - val_loss: 0.8725 - val_accuracy: 0.7260\n",
      "Epoch 81/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0920 - accuracy: 0.5922 - val_loss: 0.8691 - val_accuracy: 0.7240\n",
      "Epoch 82/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0964 - accuracy: 0.5906 - val_loss: 0.8671 - val_accuracy: 0.7320\n",
      "Epoch 83/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0757 - accuracy: 0.5966 - val_loss: 0.8609 - val_accuracy: 0.7360\n",
      "Epoch 84/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0795 - accuracy: 0.5965 - val_loss: 0.8574 - val_accuracy: 0.7320\n",
      "Epoch 85/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0632 - accuracy: 0.6023 - val_loss: 0.8481 - val_accuracy: 0.7310\n",
      "Epoch 86/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0673 - accuracy: 0.6005 - val_loss: 0.8451 - val_accuracy: 0.7290\n",
      "Epoch 87/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0695 - accuracy: 0.5989 - val_loss: 0.8405 - val_accuracy: 0.7320\n",
      "Epoch 88/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0691 - accuracy: 0.6020 - val_loss: 0.8374 - val_accuracy: 0.7350\n",
      "Epoch 89/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0600 - accuracy: 0.6092 - val_loss: 0.8364 - val_accuracy: 0.7330\n",
      "Epoch 90/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0571 - accuracy: 0.6038 - val_loss: 0.8309 - val_accuracy: 0.7350\n",
      "Epoch 91/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0403 - accuracy: 0.6206 - val_loss: 0.8261 - val_accuracy: 0.7380\n",
      "Epoch 92/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0467 - accuracy: 0.6166 - val_loss: 0.8207 - val_accuracy: 0.7320\n",
      "Epoch 93/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0362 - accuracy: 0.6123 - val_loss: 0.8177 - val_accuracy: 0.7380\n",
      "Epoch 94/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0382 - accuracy: 0.6186 - val_loss: 0.8153 - val_accuracy: 0.7400\n",
      "Epoch 95/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 1.0216 - accuracy: 0.6217 - val_loss: 0.8105 - val_accuracy: 0.7420\n",
      "Epoch 96/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0205 - accuracy: 0.6289 - val_loss: 0.8049 - val_accuracy: 0.7440\n",
      "Epoch 97/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0171 - accuracy: 0.6215 - val_loss: 0.8007 - val_accuracy: 0.7410\n",
      "Epoch 98/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0268 - accuracy: 0.6172 - val_loss: 0.7979 - val_accuracy: 0.7440\n",
      "Epoch 99/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0114 - accuracy: 0.6251 - val_loss: 0.7941 - val_accuracy: 0.7460\n",
      "Epoch 100/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0111 - accuracy: 0.6294 - val_loss: 0.7919 - val_accuracy: 0.7440\n",
      "Epoch 101/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.0115 - accuracy: 0.6217 - val_loss: 0.7896 - val_accuracy: 0.7450\n",
      "Epoch 102/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9971 - accuracy: 0.6331 - val_loss: 0.7840 - val_accuracy: 0.7460\n",
      "Epoch 103/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 0.9995 - accuracy: 0.6431 - val_loss: 0.7801 - val_accuracy: 0.7490\n",
      "Epoch 104/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9898 - accuracy: 0.6357 - val_loss: 0.7746 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9926 - accuracy: 0.6322 - val_loss: 0.7766 - val_accuracy: 0.7460\n",
      "Epoch 106/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9870 - accuracy: 0.6357 - val_loss: 0.7730 - val_accuracy: 0.7440\n",
      "Epoch 107/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9831 - accuracy: 0.6355 - val_loss: 0.7705 - val_accuracy: 0.7480\n",
      "Epoch 108/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9698 - accuracy: 0.6365 - val_loss: 0.7646 - val_accuracy: 0.7480\n",
      "Epoch 109/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9726 - accuracy: 0.6392 - val_loss: 0.7620 - val_accuracy: 0.7520\n",
      "Epoch 110/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9740 - accuracy: 0.6434 - val_loss: 0.7567 - val_accuracy: 0.7540\n",
      "Epoch 111/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9804 - accuracy: 0.6351 - val_loss: 0.7548 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9667 - accuracy: 0.6398 - val_loss: 0.7539 - val_accuracy: 0.7510\n",
      "Epoch 113/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9695 - accuracy: 0.6391 - val_loss: 0.7525 - val_accuracy: 0.7550\n",
      "Epoch 114/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9671 - accuracy: 0.6377 - val_loss: 0.7490 - val_accuracy: 0.7540\n",
      "Epoch 115/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9682 - accuracy: 0.6445 - val_loss: 0.7469 - val_accuracy: 0.7540\n",
      "Epoch 116/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9532 - accuracy: 0.6474 - val_loss: 0.7429 - val_accuracy: 0.7590\n",
      "Epoch 117/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9450 - accuracy: 0.6483 - val_loss: 0.7404 - val_accuracy: 0.7560\n",
      "Epoch 118/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9501 - accuracy: 0.6491 - val_loss: 0.7387 - val_accuracy: 0.7540\n",
      "Epoch 119/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9545 - accuracy: 0.6448 - val_loss: 0.7364 - val_accuracy: 0.7560\n",
      "Epoch 120/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9392 - accuracy: 0.6452 - val_loss: 0.7328 - val_accuracy: 0.7540\n",
      "Epoch 121/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9422 - accuracy: 0.6537 - val_loss: 0.7329 - val_accuracy: 0.7540\n",
      "Epoch 122/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9264 - accuracy: 0.6543 - val_loss: 0.7261 - val_accuracy: 0.7570\n",
      "Epoch 123/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9250 - accuracy: 0.6529 - val_loss: 0.7245 - val_accuracy: 0.7570\n",
      "Epoch 124/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9381 - accuracy: 0.6509 - val_loss: 0.7222 - val_accuracy: 0.7600\n",
      "Epoch 125/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9370 - accuracy: 0.6603 - val_loss: 0.7223 - val_accuracy: 0.7570\n",
      "Epoch 126/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9229 - accuracy: 0.6580 - val_loss: 0.7194 - val_accuracy: 0.7600\n",
      "Epoch 127/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9168 - accuracy: 0.6643 - val_loss: 0.7153 - val_accuracy: 0.7580\n",
      "Epoch 128/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9254 - accuracy: 0.6578 - val_loss: 0.7129 - val_accuracy: 0.7640\n",
      "Epoch 129/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9038 - accuracy: 0.6657 - val_loss: 0.7106 - val_accuracy: 0.7620\n",
      "Epoch 130/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9276 - accuracy: 0.6558 - val_loss: 0.7100 - val_accuracy: 0.7630\n",
      "Epoch 131/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9076 - accuracy: 0.6575 - val_loss: 0.7077 - val_accuracy: 0.7610\n",
      "Epoch 132/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9093 - accuracy: 0.6632 - val_loss: 0.7059 - val_accuracy: 0.7620\n",
      "Epoch 133/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9030 - accuracy: 0.6702 - val_loss: 0.7039 - val_accuracy: 0.7640\n",
      "Epoch 134/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9158 - accuracy: 0.6635 - val_loss: 0.7017 - val_accuracy: 0.7610\n",
      "Epoch 135/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.9054 - accuracy: 0.6634 - val_loss: 0.7008 - val_accuracy: 0.7660\n",
      "Epoch 136/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8853 - accuracy: 0.6735 - val_loss: 0.6969 - val_accuracy: 0.7630\n",
      "Epoch 137/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8957 - accuracy: 0.6663 - val_loss: 0.6973 - val_accuracy: 0.7650\n",
      "Epoch 138/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8961 - accuracy: 0.6677 - val_loss: 0.6943 - val_accuracy: 0.7660\n",
      "Epoch 139/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8943 - accuracy: 0.6723 - val_loss: 0.6926 - val_accuracy: 0.7660\n",
      "Epoch 140/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8877 - accuracy: 0.6666 - val_loss: 0.6902 - val_accuracy: 0.7640\n",
      "Epoch 141/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8790 - accuracy: 0.6766 - val_loss: 0.6880 - val_accuracy: 0.7670\n",
      "Epoch 142/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8944 - accuracy: 0.6689 - val_loss: 0.6877 - val_accuracy: 0.7650\n",
      "Epoch 143/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8843 - accuracy: 0.6742 - val_loss: 0.6858 - val_accuracy: 0.7710\n",
      "Epoch 144/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8771 - accuracy: 0.6780 - val_loss: 0.6847 - val_accuracy: 0.7660\n",
      "Epoch 145/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8784 - accuracy: 0.6777 - val_loss: 0.6836 - val_accuracy: 0.7720\n",
      "Epoch 146/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8783 - accuracy: 0.6760 - val_loss: 0.6810 - val_accuracy: 0.7690\n",
      "Epoch 147/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8746 - accuracy: 0.6669 - val_loss: 0.6798 - val_accuracy: 0.7690\n",
      "Epoch 148/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8631 - accuracy: 0.6762 - val_loss: 0.6788 - val_accuracy: 0.7690\n",
      "Epoch 149/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8590 - accuracy: 0.6812 - val_loss: 0.6771 - val_accuracy: 0.7660\n",
      "Epoch 150/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8644 - accuracy: 0.6782 - val_loss: 0.6756 - val_accuracy: 0.7670\n",
      "Epoch 151/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8760 - accuracy: 0.6717 - val_loss: 0.6748 - val_accuracy: 0.7670\n",
      "Epoch 152/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8683 - accuracy: 0.6740 - val_loss: 0.6733 - val_accuracy: 0.7670\n",
      "Epoch 153/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8606 - accuracy: 0.6897 - val_loss: 0.6719 - val_accuracy: 0.7640\n",
      "Epoch 154/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8520 - accuracy: 0.6803 - val_loss: 0.6695 - val_accuracy: 0.7690\n",
      "Epoch 155/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 0.8699 - accuracy: 0.6786 - val_loss: 0.6686 - val_accuracy: 0.7680\n",
      "Epoch 156/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8584 - accuracy: 0.6802 - val_loss: 0.6676 - val_accuracy: 0.7670\n",
      "Epoch 157/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8548 - accuracy: 0.6817 - val_loss: 0.6670 - val_accuracy: 0.7710\n",
      "Epoch 158/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8676 - accuracy: 0.6748 - val_loss: 0.6679 - val_accuracy: 0.7690\n",
      "Epoch 159/200\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 0.8487 - accuracy: 0.6868 - val_loss: 0.6645 - val_accuracy: 0.7700\n",
      "Epoch 160/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8539 - accuracy: 0.6823 - val_loss: 0.6626 - val_accuracy: 0.7720\n",
      "Epoch 161/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8423 - accuracy: 0.6858 - val_loss: 0.6613 - val_accuracy: 0.7680\n",
      "Epoch 162/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8461 - accuracy: 0.6863 - val_loss: 0.6622 - val_accuracy: 0.7700\n",
      "Epoch 163/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8402 - accuracy: 0.6892 - val_loss: 0.6607 - val_accuracy: 0.7720\n",
      "Epoch 164/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8516 - accuracy: 0.6851 - val_loss: 0.6596 - val_accuracy: 0.7740\n",
      "Epoch 165/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8424 - accuracy: 0.6865 - val_loss: 0.6589 - val_accuracy: 0.7670\n",
      "Epoch 166/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8493 - accuracy: 0.6895 - val_loss: 0.6577 - val_accuracy: 0.7770\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8323 - accuracy: 0.6922 - val_loss: 0.6553 - val_accuracy: 0.7710\n",
      "Epoch 168/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8297 - accuracy: 0.6895 - val_loss: 0.6527 - val_accuracy: 0.7730\n",
      "Epoch 169/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8356 - accuracy: 0.6928 - val_loss: 0.6518 - val_accuracy: 0.7720\n",
      "Epoch 170/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8224 - accuracy: 0.7003 - val_loss: 0.6502 - val_accuracy: 0.7740\n",
      "Epoch 171/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8252 - accuracy: 0.6918 - val_loss: 0.6480 - val_accuracy: 0.7720\n",
      "Epoch 172/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8423 - accuracy: 0.6883 - val_loss: 0.6498 - val_accuracy: 0.7720\n",
      "Epoch 173/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8254 - accuracy: 0.6914 - val_loss: 0.6481 - val_accuracy: 0.7740\n",
      "Epoch 174/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8064 - accuracy: 0.6971 - val_loss: 0.6460 - val_accuracy: 0.7730\n",
      "Epoch 175/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8318 - accuracy: 0.6918 - val_loss: 0.6460 - val_accuracy: 0.7740\n",
      "Epoch 176/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8333 - accuracy: 0.6863 - val_loss: 0.6458 - val_accuracy: 0.7740\n",
      "Epoch 177/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8219 - accuracy: 0.6985 - val_loss: 0.6428 - val_accuracy: 0.7750\n",
      "Epoch 178/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7951 - accuracy: 0.7060 - val_loss: 0.6395 - val_accuracy: 0.7730\n",
      "Epoch 179/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8228 - accuracy: 0.6982 - val_loss: 0.6401 - val_accuracy: 0.7780\n",
      "Epoch 180/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7872 - accuracy: 0.7089 - val_loss: 0.6375 - val_accuracy: 0.7760\n",
      "Epoch 181/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8112 - accuracy: 0.7000 - val_loss: 0.6397 - val_accuracy: 0.7700\n",
      "Epoch 182/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8120 - accuracy: 0.7005 - val_loss: 0.6393 - val_accuracy: 0.7760\n",
      "Epoch 183/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7939 - accuracy: 0.6972 - val_loss: 0.6380 - val_accuracy: 0.7740\n",
      "Epoch 184/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8059 - accuracy: 0.6957 - val_loss: 0.6374 - val_accuracy: 0.7750\n",
      "Epoch 185/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7970 - accuracy: 0.6997 - val_loss: 0.6367 - val_accuracy: 0.7720\n",
      "Epoch 186/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8019 - accuracy: 0.6977 - val_loss: 0.6347 - val_accuracy: 0.7790\n",
      "Epoch 187/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8045 - accuracy: 0.7002 - val_loss: 0.6340 - val_accuracy: 0.7760\n",
      "Epoch 188/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8016 - accuracy: 0.6982 - val_loss: 0.6326 - val_accuracy: 0.7790\n",
      "Epoch 189/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7976 - accuracy: 0.7032 - val_loss: 0.6320 - val_accuracy: 0.7770\n",
      "Epoch 190/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7944 - accuracy: 0.7035 - val_loss: 0.6315 - val_accuracy: 0.7770\n",
      "Epoch 191/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7860 - accuracy: 0.7083 - val_loss: 0.6302 - val_accuracy: 0.7780\n",
      "Epoch 192/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7977 - accuracy: 0.7037 - val_loss: 0.6302 - val_accuracy: 0.7750\n",
      "Epoch 193/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7935 - accuracy: 0.7025 - val_loss: 0.6290 - val_accuracy: 0.7780\n",
      "Epoch 194/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7934 - accuracy: 0.7062 - val_loss: 0.6281 - val_accuracy: 0.7790\n",
      "Epoch 195/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7932 - accuracy: 0.7031 - val_loss: 0.6270 - val_accuracy: 0.7780\n",
      "Epoch 196/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7961 - accuracy: 0.7066 - val_loss: 0.6267 - val_accuracy: 0.7780\n",
      "Epoch 197/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7963 - accuracy: 0.7069 - val_loss: 0.6262 - val_accuracy: 0.7780\n",
      "Epoch 198/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7849 - accuracy: 0.7094 - val_loss: 0.6249 - val_accuracy: 0.7790\n",
      "Epoch 199/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7802 - accuracy: 0.7085 - val_loss: 0.6239 - val_accuracy: 0.7800\n",
      "Epoch 200/200\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.7851 - accuracy: 0.7069 - val_loss: 0.6232 - val_accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# â° This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(X_train_token,\n",
    "                    y_train_label,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_token, y_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 21us/step\n",
      "Training Loss: 0.489 Training Accuracy: 0.822\n",
      "2500/2500 [==============================] - 0s 21us/step\n",
      "Testing Loss: 0.653 Testing Accuracy: 0.753\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_token, y_train_label)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! The variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]\n",
    "\n",
    "# train test split\n",
    "X_train_lrg, X_test_lrg, y_train_lrg, y_test_lrg = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Validation set\n",
    "X_train_final_lrg, X_val_lrg, y_train_final_lrg, y_val_lrg = train_test_split(X_train_lrg, y_train_lrg, random_state=123)\n",
    "\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_lrg)\n",
    "\n",
    "X_train_tok_lrg = tokenizer.texts_to_matrix(X_train_final_lrg, mode='binary')\n",
    "X_val_lrg = tokenizer.texts_to_matrix(X_val_lrg, mode='binary')\n",
    "X_test_lrg = tokenizer.texts_to_matrix(X_test_lrg, mode='binary')\n",
    "\n",
    "#one-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_lrg)\n",
    "\n",
    "y_train_lb_lrg = to_categorical(lb.transform(y_train_final_lrg))[:, :, 1]\n",
    "y_val_lrg = to_categorical(lb.transform(y_val_lrg))[:, :, 1]\n",
    "y_test_lrg = to_categorical(lb.transform(y_test_lrg))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 1.9217 - accuracy: 0.2038 - val_loss: 1.8929 - val_accuracy: 0.2337\n",
      "Epoch 2/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.8607 - accuracy: 0.2601 - val_loss: 1.8294 - val_accuracy: 0.2884\n",
      "Epoch 3/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.7857 - accuracy: 0.3180 - val_loss: 1.7418 - val_accuracy: 0.3540\n",
      "Epoch 4/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.6804 - accuracy: 0.3942 - val_loss: 1.6183 - val_accuracy: 0.4419\n",
      "Epoch 5/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.5439 - accuracy: 0.4808 - val_loss: 1.4701 - val_accuracy: 0.5221\n",
      "Epoch 6/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.3927 - accuracy: 0.5532 - val_loss: 1.3197 - val_accuracy: 0.5835\n",
      "Epoch 7/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.2470 - accuracy: 0.6136 - val_loss: 1.1852 - val_accuracy: 0.6280\n",
      "Epoch 8/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.1218 - accuracy: 0.6548 - val_loss: 1.0734 - val_accuracy: 0.6580\n",
      "Epoch 9/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 1.0196 - accuracy: 0.6800 - val_loss: 0.9842 - val_accuracy: 0.6791\n",
      "Epoch 10/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.9381 - accuracy: 0.6995 - val_loss: 0.9149 - val_accuracy: 0.6932\n",
      "Epoch 11/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.8738 - accuracy: 0.7156 - val_loss: 0.8608 - val_accuracy: 0.7071\n",
      "Epoch 12/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.8232 - accuracy: 0.7273 - val_loss: 0.8183 - val_accuracy: 0.7133\n",
      "Epoch 13/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.7826 - accuracy: 0.7352 - val_loss: 0.7843 - val_accuracy: 0.7244\n",
      "Epoch 14/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.7498 - accuracy: 0.7435 - val_loss: 0.7590 - val_accuracy: 0.7276\n",
      "Epoch 15/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.7229 - accuracy: 0.7508 - val_loss: 0.7377 - val_accuracy: 0.7345\n",
      "Epoch 16/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.7000 - accuracy: 0.7572 - val_loss: 0.7180 - val_accuracy: 0.7393\n",
      "Epoch 17/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.6807 - accuracy: 0.7608 - val_loss: 0.7033 - val_accuracy: 0.7433\n",
      "Epoch 18/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.6639 - accuracy: 0.7653 - val_loss: 0.6904 - val_accuracy: 0.7489\n",
      "Epoch 19/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.6491 - accuracy: 0.7703 - val_loss: 0.6789 - val_accuracy: 0.7507\n",
      "Epoch 20/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.6359 - accuracy: 0.7729 - val_loss: 0.6691 - val_accuracy: 0.7543\n",
      "Epoch 21/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.6238 - accuracy: 0.7770 - val_loss: 0.6614 - val_accuracy: 0.7556\n",
      "Epoch 22/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.6128 - accuracy: 0.7810 - val_loss: 0.6534 - val_accuracy: 0.7600\n",
      "Epoch 23/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.6027 - accuracy: 0.7856 - val_loss: 0.6465 - val_accuracy: 0.7612\n",
      "Epoch 24/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.5930 - accuracy: 0.7877 - val_loss: 0.6423 - val_accuracy: 0.7620\n",
      "Epoch 25/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5847 - accuracy: 0.7905 - val_loss: 0.6355 - val_accuracy: 0.7637\n",
      "Epoch 26/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5761 - accuracy: 0.7946 - val_loss: 0.6299 - val_accuracy: 0.7659\n",
      "Epoch 27/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5683 - accuracy: 0.7964 - val_loss: 0.6260 - val_accuracy: 0.7691\n",
      "Epoch 28/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5611 - accuracy: 0.8000 - val_loss: 0.6226 - val_accuracy: 0.7673\n",
      "Epoch 29/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5541 - accuracy: 0.8018 - val_loss: 0.6194 - val_accuracy: 0.7707\n",
      "Epoch 30/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5475 - accuracy: 0.8045 - val_loss: 0.6139 - val_accuracy: 0.7728\n",
      "Epoch 31/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5411 - accuracy: 0.8072 - val_loss: 0.6103 - val_accuracy: 0.7747\n",
      "Epoch 32/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5351 - accuracy: 0.8111 - val_loss: 0.6078 - val_accuracy: 0.7745\n",
      "Epoch 33/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5290 - accuracy: 0.8136 - val_loss: 0.6057 - val_accuracy: 0.7748\n",
      "Epoch 34/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5231 - accuracy: 0.8141 - val_loss: 0.6028 - val_accuracy: 0.7763\n",
      "Epoch 35/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5175 - accuracy: 0.8176 - val_loss: 0.6001 - val_accuracy: 0.7768\n",
      "Epoch 36/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5124 - accuracy: 0.8196 - val_loss: 0.5983 - val_accuracy: 0.7779\n",
      "Epoch 37/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5072 - accuracy: 0.8202 - val_loss: 0.5951 - val_accuracy: 0.7804\n",
      "Epoch 38/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.5019 - accuracy: 0.8224 - val_loss: 0.5928 - val_accuracy: 0.7801\n",
      "Epoch 39/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4971 - accuracy: 0.8246 - val_loss: 0.5949 - val_accuracy: 0.7808\n",
      "Epoch 40/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4927 - accuracy: 0.8251 - val_loss: 0.5907 - val_accuracy: 0.7819\n",
      "Epoch 41/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.4881 - accuracy: 0.8275 - val_loss: 0.5881 - val_accuracy: 0.7827\n",
      "Epoch 42/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4835 - accuracy: 0.8288 - val_loss: 0.5870 - val_accuracy: 0.7829\n",
      "Epoch 43/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4794 - accuracy: 0.8316 - val_loss: 0.5847 - val_accuracy: 0.7848\n",
      "Epoch 44/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4753 - accuracy: 0.8326 - val_loss: 0.5829 - val_accuracy: 0.7857\n",
      "Epoch 45/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4710 - accuracy: 0.8351 - val_loss: 0.5816 - val_accuracy: 0.7861\n",
      "Epoch 46/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4668 - accuracy: 0.8356 - val_loss: 0.5845 - val_accuracy: 0.7863\n",
      "Epoch 47/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4630 - accuracy: 0.8364 - val_loss: 0.5797 - val_accuracy: 0.7887\n",
      "Epoch 48/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4594 - accuracy: 0.8389 - val_loss: 0.5793 - val_accuracy: 0.7883\n",
      "Epoch 49/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4554 - accuracy: 0.8399 - val_loss: 0.5781 - val_accuracy: 0.7868\n",
      "Epoch 50/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4517 - accuracy: 0.8403 - val_loss: 0.5777 - val_accuracy: 0.7892\n",
      "Epoch 51/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4484 - accuracy: 0.8427 - val_loss: 0.5768 - val_accuracy: 0.7895\n",
      "Epoch 52/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4446 - accuracy: 0.8439 - val_loss: 0.5760 - val_accuracy: 0.7892\n",
      "Epoch 53/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4412 - accuracy: 0.8450 - val_loss: 0.5752 - val_accuracy: 0.7911\n",
      "Epoch 54/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4381 - accuracy: 0.8473 - val_loss: 0.5781 - val_accuracy: 0.7911\n",
      "Epoch 55/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4347 - accuracy: 0.8473 - val_loss: 0.5738 - val_accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4313 - accuracy: 0.8484 - val_loss: 0.5731 - val_accuracy: 0.7897\n",
      "Epoch 57/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4282 - accuracy: 0.8496 - val_loss: 0.5721 - val_accuracy: 0.7891\n",
      "Epoch 58/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4250 - accuracy: 0.8509 - val_loss: 0.5728 - val_accuracy: 0.7915\n",
      "Epoch 59/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4222 - accuracy: 0.8516 - val_loss: 0.5716 - val_accuracy: 0.7899\n",
      "Epoch 60/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4192 - accuracy: 0.8524 - val_loss: 0.5726 - val_accuracy: 0.7909\n",
      "Epoch 61/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4163 - accuracy: 0.8546 - val_loss: 0.5720 - val_accuracy: 0.7932\n",
      "Epoch 62/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4133 - accuracy: 0.8560 - val_loss: 0.5716 - val_accuracy: 0.7936\n",
      "Epoch 63/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4105 - accuracy: 0.8568 - val_loss: 0.5714 - val_accuracy: 0.7913\n",
      "Epoch 64/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4074 - accuracy: 0.8579 - val_loss: 0.5722 - val_accuracy: 0.7931\n",
      "Epoch 65/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4049 - accuracy: 0.8591 - val_loss: 0.5704 - val_accuracy: 0.7935\n",
      "Epoch 66/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.4018 - accuracy: 0.8609 - val_loss: 0.5706 - val_accuracy: 0.7940\n",
      "Epoch 67/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3993 - accuracy: 0.8610 - val_loss: 0.5714 - val_accuracy: 0.7917\n",
      "Epoch 68/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3972 - accuracy: 0.8616 - val_loss: 0.5711 - val_accuracy: 0.7948\n",
      "Epoch 69/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3941 - accuracy: 0.8640 - val_loss: 0.5719 - val_accuracy: 0.7952\n",
      "Epoch 70/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3920 - accuracy: 0.8640 - val_loss: 0.5726 - val_accuracy: 0.7943\n",
      "Epoch 71/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3891 - accuracy: 0.8650 - val_loss: 0.5717 - val_accuracy: 0.7944\n",
      "Epoch 72/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3868 - accuracy: 0.8657 - val_loss: 0.5707 - val_accuracy: 0.7956\n",
      "Epoch 73/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3846 - accuracy: 0.8676 - val_loss: 0.5730 - val_accuracy: 0.7949\n",
      "Epoch 74/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3816 - accuracy: 0.8674 - val_loss: 0.5725 - val_accuracy: 0.7947\n",
      "Epoch 75/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.3794 - accuracy: 0.8696 - val_loss: 0.5771 - val_accuracy: 0.7941\n",
      "Epoch 76/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3768 - accuracy: 0.8701 - val_loss: 0.5759 - val_accuracy: 0.7949\n",
      "Epoch 77/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3747 - accuracy: 0.8711 - val_loss: 0.5720 - val_accuracy: 0.7955\n",
      "Epoch 78/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3725 - accuracy: 0.8727 - val_loss: 0.5734 - val_accuracy: 0.7951\n",
      "Epoch 79/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3700 - accuracy: 0.8724 - val_loss: 0.5728 - val_accuracy: 0.7959\n",
      "Epoch 80/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3682 - accuracy: 0.8734 - val_loss: 0.5734 - val_accuracy: 0.7959\n",
      "Epoch 81/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3661 - accuracy: 0.8736 - val_loss: 0.5740 - val_accuracy: 0.7959\n",
      "Epoch 82/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3638 - accuracy: 0.8754 - val_loss: 0.5744 - val_accuracy: 0.7961\n",
      "Epoch 83/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3615 - accuracy: 0.8759 - val_loss: 0.5761 - val_accuracy: 0.7960\n",
      "Epoch 84/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3596 - accuracy: 0.8762 - val_loss: 0.5760 - val_accuracy: 0.7959\n",
      "Epoch 85/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3573 - accuracy: 0.8776 - val_loss: 0.5777 - val_accuracy: 0.7959\n",
      "Epoch 86/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3552 - accuracy: 0.8775 - val_loss: 0.5780 - val_accuracy: 0.7973\n",
      "Epoch 87/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3532 - accuracy: 0.8785 - val_loss: 0.5798 - val_accuracy: 0.7967\n",
      "Epoch 88/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3513 - accuracy: 0.8798 - val_loss: 0.5772 - val_accuracy: 0.7975\n",
      "Epoch 89/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3495 - accuracy: 0.8796 - val_loss: 0.5777 - val_accuracy: 0.7969\n",
      "Epoch 90/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3474 - accuracy: 0.8821 - val_loss: 0.5796 - val_accuracy: 0.7980\n",
      "Epoch 91/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3454 - accuracy: 0.8818 - val_loss: 0.5815 - val_accuracy: 0.7987\n",
      "Epoch 92/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3433 - accuracy: 0.8836 - val_loss: 0.5798 - val_accuracy: 0.7973\n",
      "Epoch 93/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3417 - accuracy: 0.8844 - val_loss: 0.5810 - val_accuracy: 0.7983\n",
      "Epoch 94/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3400 - accuracy: 0.8840 - val_loss: 0.5838 - val_accuracy: 0.7991\n",
      "Epoch 95/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3379 - accuracy: 0.8850 - val_loss: 0.5826 - val_accuracy: 0.7983\n",
      "Epoch 96/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3360 - accuracy: 0.8866 - val_loss: 0.5841 - val_accuracy: 0.7997\n",
      "Epoch 97/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3341 - accuracy: 0.8874 - val_loss: 0.5848 - val_accuracy: 0.7987\n",
      "Epoch 98/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3324 - accuracy: 0.8875 - val_loss: 0.5855 - val_accuracy: 0.7996\n",
      "Epoch 99/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3305 - accuracy: 0.8890 - val_loss: 0.5902 - val_accuracy: 0.7963\n",
      "Epoch 100/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3290 - accuracy: 0.8888 - val_loss: 0.5888 - val_accuracy: 0.7980\n",
      "Epoch 101/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.3271 - accuracy: 0.8899 - val_loss: 0.5886 - val_accuracy: 0.7997\n",
      "Epoch 102/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3251 - accuracy: 0.8911 - val_loss: 0.5879 - val_accuracy: 0.7995\n",
      "Epoch 103/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3235 - accuracy: 0.8919 - val_loss: 0.5903 - val_accuracy: 0.7993\n",
      "Epoch 104/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3222 - accuracy: 0.8923 - val_loss: 0.5896 - val_accuracy: 0.7995\n",
      "Epoch 105/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.3202 - accuracy: 0.8923 - val_loss: 0.5916 - val_accuracy: 0.7989\n",
      "Epoch 106/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3180 - accuracy: 0.8941 - val_loss: 0.5937 - val_accuracy: 0.7972\n",
      "Epoch 107/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3172 - accuracy: 0.8939 - val_loss: 0.5928 - val_accuracy: 0.7985\n",
      "Epoch 108/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3152 - accuracy: 0.8946 - val_loss: 0.5960 - val_accuracy: 0.7983\n",
      "Epoch 109/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3136 - accuracy: 0.8956 - val_loss: 0.5957 - val_accuracy: 0.7988\n",
      "Epoch 110/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3119 - accuracy: 0.8960 - val_loss: 0.5978 - val_accuracy: 0.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3103 - accuracy: 0.8968 - val_loss: 0.5969 - val_accuracy: 0.7984\n",
      "Epoch 112/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3086 - accuracy: 0.8980 - val_loss: 0.5977 - val_accuracy: 0.7996\n",
      "Epoch 113/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3074 - accuracy: 0.8981 - val_loss: 0.5989 - val_accuracy: 0.7979\n",
      "Epoch 114/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3056 - accuracy: 0.8987 - val_loss: 0.5999 - val_accuracy: 0.7976\n",
      "Epoch 115/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.3037 - accuracy: 0.8996 - val_loss: 0.6049 - val_accuracy: 0.7969\n",
      "Epoch 116/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3026 - accuracy: 0.8998 - val_loss: 0.6014 - val_accuracy: 0.7991\n",
      "Epoch 117/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.3007 - accuracy: 0.9003 - val_loss: 0.6024 - val_accuracy: 0.7992\n",
      "Epoch 118/120\n",
      "22500/22500 [==============================] - 1s 27us/step - loss: 0.2991 - accuracy: 0.9009 - val_loss: 0.6049 - val_accuracy: 0.7995\n",
      "Epoch 119/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.2978 - accuracy: 0.9016 - val_loss: 0.6062 - val_accuracy: 0.7971\n",
      "Epoch 120/120\n",
      "22500/22500 [==============================] - 1s 26us/step - loss: 0.2964 - accuracy: 0.9028 - val_loss: 0.6086 - val_accuracy: 0.7973\n"
     ]
    }
   ],
   "source": [
    "# â° This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(X_train_tok_lrg,\n",
    "                    y_train_lb_lrg,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_lrg, y_val_lrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 0s 19us/step\n",
      "Training Loss: 0.293 Training Accuracy: 0.902\n",
      "10000/10000 [==============================] - 0s 20us/step\n",
      "Testing Loss: 0.615 Testing Accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok_lrg, y_train_lb_lrg)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_lrg, y_test_lrg)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.45 in obtained in the first model in this lab). Your test set accuracy went up from 75.8 to 79.2% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
